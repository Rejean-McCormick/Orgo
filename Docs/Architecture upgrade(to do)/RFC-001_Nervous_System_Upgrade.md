RFC-001: The Nervous System Upgrade (SenTient & Architect Integration)Meta FieldValueStatusPROPOSEDAuthorSenior ArchitectDate2025-12-17Target Componentsapps/api, apps/worker, databaseKey PatternsHexagonal Architecture, Transactional Outbox, Anti-Corruption Layer, Circuit Breaker, Bulkhead1. Executive SummaryOrgo is currently a reactive "Operating System"â€”it waits for explicit, structured user input to create tasks. This RFC proposes evolving Orgo into a proactive "Nervous System" by integrating two AI subsystems: SenTient (Perception) and Architect (Expression).This upgrade allows the system to:Sense: Ingest unstructured human signals (emails, voice logs) and normalize them into structured Tasks via SenTient.Think: Process these tasks using the existing, deterministic Core logic.Act: Generate context-aware, human-readable notifications via Architect, tailored to specific scopes (e.g., "The Safety Team" vs. "The Site Manager").To ensure stability, we will strictly adhere to Hexagonal Architecture, treating these AI components as "Adapters" that never pollute the "Core" domain logic.2. Motivation & Problem Statement2.1 The "Fragile Input" ProblemCurrently, data entry requires strict form filling. In reality, users send free-text emails describing complex incidents. Manually converting these into Tasks is slow and error-prone.Solution: Automate ingestion using SenTient to parse unstructured text into Orgo's schema.2.2 The "Robot Voice" ProblemSystem notifications are rigid static templates (e.g., "TASK #123 UPDATED"). They lack context, tone, and empathy. A generic alert sent to a "Grieving Family Profile" or a "High Anxiety" medical ward is inappropriate.Solution: Use Architect to dynamically generate notification text based on the recipient's context and the event's severity.2.3 The "Distributed Monolith" RiskDirectly calling AI APIs (OpenAI, SenTient) from our Core TaskService introduces significant risks:Latency: AI calls can take 10-30 seconds, holding open database transactions and blocking threads.Coupling: Our internal schema becomes tied to the external AI model's ontology (Wikidata).Instability: If the AI provider goes down, the entire Orgo platform becomes unresponsive.3. High-Level ArchitectureWe will implement a Hexagonal Architecture (Ports & Adapters) to isolate the AI volatility from the Core stability.3.1 The TopologyThe Core (Inner Hexagon):Responsibility: Pure Business Logic (Task, Case, Workflow).Constraint: Zero dependencies on AI libraries. It defines interfaces (Ports) like ISignalIngestor and INotifier.Tech: NestJS, pure TypeScript.SenTient Adapter (Input Port):Responsibility: Implements ISignalIngestor. Calls SenTient API, handles retries, and maps external Wikidata to internal DTOs.Pattern: Anti-Corruption Layer (ACL).Architect Adapter (Output Port):Responsibility: Implements INotifier. Calls Architect API (LLM) to generate text.Pattern: Transactional Outbox.4. Detailed Design: Perception (SenTient)4.1 Anti-Corruption Layer (ACL)Concept:SenTient outputs Wikidata-based JSON (e.g., P921 for "Main Subject"). We must prevent this ontology from leaking into our Prisma Schema.The SenTientTranslationService Logic:Input: WikidataObject { P921: "Q123 (Plumbing)", P580: "2025-12-17" }ACL Action:Map Category: Lookup Category table where wikidataId == Q123. Result: Maintenance.Map Priority: Analyze sentiment score. If score < 0.2 (Negative/Panic), set Priority = HIGH.Map Dates: Parse P580 to ISO Date.Output: Returns a clean CreateTaskDTO to the Core.4.2 Resilience: Dead Letter Queue (DLQ)Concept:AI parsing is probabilistic. A specific "poison pill" email might crash the parser repeatedly. We cannot let one bad email block the ingestion queue.Workflow:Attempt 1-3: Try to parse. If JSON.parse or ACL.translate fails, retry with exponential backoff.Failure: On the 4th failure, catch the exception.Quarantine: Insert the raw payload into a new Postgres table Parsing_DLQ.Recovery: An Admin View allows a human to see the raw text, manually map it to a Task form, and "Redrive" it.5. Detailed Design: Expression (Architect)5.1 Reliability: Transactional OutboxConcept:We must avoid the "Dual Write Problem" where a Task is created in the DB, but the notification fails to send due to a network error.Schema Change (Prisma):Extrait de codemodel Outbox {
  id          String   @id @default(uuid())
  aggregateId String   // e.g., Task ID
  type        String   // "TASK_CREATED", "SAFETY_ALERT"
  payload     Json     // Full context needed for the LLM prompt
  status      String   // PENDING, PROCESSING, SENT, FAILED
  createdAt   DateTime @default(now())
  
  @@index([status, createdAt])
}
Process:Atomic Write: Inside the prisma.$transaction() that creates the Task, we also perform prisma.outbox.create().Guaranteed: If the DB commit succeeds, the notification event is durably stored on disk.Async Worker: A separate BullMQ worker polls the Outbox table, picks up PENDING items, and hands them to the Architect Adapter.5.2 Context-Aware Scoping & Pub/SubConcept:The Core emits what happened. The Routing Layer decides who cares and how they should be told.Event Flow:Event: SafetyIncident { location: "Zone B", severity: "HIGH" }Scope Resolution (Pub/Sub):Find "Zone B Manager" -> User: Alice.Find "Safety Team" -> Group: [Bob, Charlie].Fan-Out (Architect Generation): We generate distinct prompts for each recipient type.Alice (Manager): "Architect, write a formal incident report summary..."Bob (Field Team): "Architect, write a short, urgent SMS alert..."6. Operational Resilience6.1 Circuit BreakersConcept:We will wrap the HTTP clients for SenTient and Architect.Threshold: 5 failures in 10 seconds.Open State: If the AI provider is down/slow, we stop calling it to save system resources.Fallback Strategy:SenTient: Mark input as "Manual Review Needed" (Fallback to Human).Architect: Send a static, pre-written template (Legacy behavior).6.2 Bulkhead PatternConcept:We must isolate the "Thinking" (Core) from the "Dreaming" (AI Generation).Infrastructure: Use separate Redis queues for Ingestion and Notifications.Concurrency Limits:IngestionQueue: High concurrency (50 workers) - I/O bound.NotificationQueue: Low concurrency (5 workers) - Rate-limit bound (OpenAI limits).7. Migration Strategy (Strangler Fig)Concept:We will not rewrite the existing Email Service immediately.Phase 1 (Shadow Mode): Build SenTientAdapter alongside the existing parser. It parses emails but only logs the result (does not create tasks). Verify accuracy.Phase 2 (Canary): Route 5% of "Low Priority" emails to SenTient. Monitor DLQ rates.Phase 3 (Expansion): Slowly increase traffic to 100%.Phase 4 (Cleanup): Decommission the legacy regex parser.8. Security & PrivacyPII Redaction: Before sending any data to Architect (an external LLM), we run a local regex pass to mask obvious PII (SSN, Phone Numbers) if the organization's profile is set to RESTRICTED.Audit Log: Every text generated by Architect is stored in SystemLog for compliance review. We must be able to prove why the system said what it said.9. ConclusionThis architecture transforms Orgo from a passive database wrapper into an active, intelligent partner. By decoupling the AI components using Hexagonal Architecture and ensuring data consistency with Transactional Outboxes, we achieve "Intelligence" without sacrificing the "Reliability" required of an Operating System.