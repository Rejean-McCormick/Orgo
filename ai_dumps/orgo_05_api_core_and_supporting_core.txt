=== FILE 1/48: apps/api/src/orgo/core/alerts/alerting.service.ts ===

import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

import { LogService } from '../logging/log.service';
import {
  FN_ALERT_ESCALATION_DELAY,
  FN_ALERT_ERROR_RATE,
} from '../functional-ids';

/**
 * Canonical log levels for Core Services (Doc 2 / Doc 5).
 */
export type LogLevel = 'DEBUG' | 'INFO' | 'WARNING' | 'ERROR' | 'CRITICAL';

/**
 * Canonical log categories for Core Services (Doc 2 / Doc 5).
 */
export type LogCategory = 'WORKFLOW' | 'TASK' | 'SYSTEM' | 'SECURITY' | 'EMAIL';

/**
 * Canonical environment values (Doc 2).
 */
export type Environment = 'dev' | 'staging' | 'prod' | 'offline';

/**
 * Standard result error shape (Doc 5 §2.4).
 */
export interface StandardError {
  code: string;
  message: string;
  details?: unknown;
}

/**
 * Standard result shape (ok / data / error) used across Core Services (Doc 5 §2.4).
 */
export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardError | null;
}

/**
 * Alert types handled by AlertingService.
 */
export type AlertType = 'ESCALATION_DELAY' | 'ERROR_RATE';

/**
 * Result payload describing whether an alert was emitted.
 */
export interface AlertTriggerResult {
  alertType: AlertType;
  triggered: boolean;
  reason: string;
  metadata?: Record<string, unknown>;
}

/**
 * Input payload for escalation-delay alerts.
 *
 * The job `orgo.alerts.escalation-delay` is expected to compute these metrics
 * using SLA rules derived from profiles/config (Docs 2, 5, 7, 8) and pass them here.
 */
export interface EscalationDelayAlertInput {
  /**
   * Organization the metrics apply to (tenant).
   */
  organizationId: string;

  /**
   * Profile key used for SLA expectations (e.g. "hospital", "default").
   * See Doc 7 – profiles YAML.
   */
  profileKey: string;

  /**
   * Environment in which the alert is being evaluated.
   */
  environment: Environment;

  /**
   * Number of unresolved Tasks whose `reactivity_deadline_at` has passed
   * (as per Doc 8 §8.7.2).
   */
  overdueUnresolvedCount: number;

  /**
   * Number of those overdue Tasks that are `CRITICAL` severity.
   */
  overdueCriticalCount: number;

  /**
   * Maximum delay in seconds beyond `reactivity_deadline_at`
   * among the overdue Tasks.
   */
  maxDelaySeconds: number;

  /**
   * Optional threshold overrides already resolved by the caller.
   * If omitted, defaults derived from config are used.
   */
  thresholds?: {
    /**
     * Minimum overdue Task count required before an alert is emitted.
     */
    minOverdueCount?: number;

    /**
     * Minimum maximum delay (in seconds) beyond SLA before emitting an alert.
     */
    minMaxDelaySeconds?: number;
  };
}

/**
 * Input payload for error-rate alerts.
 *
 * The job `orgo.alerts.error-rate` is expected to compute these metrics from
 * observability data (e.g. Prometheus / logs) and pass them here.
 */
export interface ErrorRateAlertInput {
  /**
   * Identifier of the service / worker being monitored (e.g. "task_handler").
   */
  serviceId: string;

  /**
   * Environment in which the alert is being evaluated.
   */
  environment: Environment;

  /**
   * Rolling window size (in minutes) used to compute the error rate.
   */
  windowMinutes: number;

  /**
   * Error rate in the window, expressed as a fraction between 0 and 1.
   * Example: 0.02 = 2% error rate.
   */
  errorRate: number;

  /**
   * Total request count in the window; used for sanity checks and logging.
   */
  requestCount: number;

  /**
   * Optional threshold override already resolved by the caller.
   * If omitted, defaults derived from config are used.
   */
  thresholdErrorRate?: number;
}

/**
 * AlertingService
 *
 * Infrastructure & Monitoring sub-module responsible for emitting alerts
 * when SLA- and error-related conditions are breached (Doc 4 §3.8).
 *
 * Code names (Doc 4 §3.8):
 * - Trigger escalation delay alert → AlertingService.triggerEscalationDelayAlert,
 *   job `orgo.alerts.escalation-delay`.
 * - Trigger error-rate alert → AlertingService.triggerErrorRateAlert,
 *   job `orgo.alerts.error-rate`.
 */
@Injectable()
export class AlertingService {
  /**
   * Default thresholds used when no explicit values are provided via config
   * or method parameters. These values are conservative and intended to be
   * overridden per-environment via configuration.
   */
  private readonly defaultEscalationMinOverdueCount: number;
  private readonly defaultEscalationMinMaxDelaySeconds: number;
  private readonly defaultErrorRateThreshold: number;

  constructor(
    private readonly logService: LogService,
    private readonly configService: ConfigService,
  ) {
    // Escalation-delay thresholds (may be overridden by config).
    this.defaultEscalationMinOverdueCount =
      Number(
        this.configService.get(
          'alerts.escalationDelay.min_overdue_count',
        ) as number | string,
      ) || 1;

    this.defaultEscalationMinMaxDelaySeconds =
      Number(
        this.configService.get(
          'alerts.escalationDelay.min_max_delay_seconds',
        ) as number | string,
      ) || 60;

    // Error-rate threshold (may be overridden by config).
    // Default: 1% error rate.
    this.defaultErrorRateThreshold =
      Number(
        this.configService.get('alerts.errorRate.threshold') as number | string,
      ) || 0.01;
  }

  /**
   * Emits an alert when escalations fall behind SLAs derived from profiles/config.
   *
   * This method is typically called by the background job
   * `orgo.alerts.escalation-delay`, which aggregates metrics across Tasks and
   * passes them in the `input` payload.
   */
  async triggerEscalationDelayAlert(
    input: EscalationDelayAlertInput,
  ): Promise<StandardResult<AlertTriggerResult>> {
    try {
      const minOverdueCount =
        input.thresholds?.minOverdueCount ??
        this.defaultEscalationMinOverdueCount;
      const minMaxDelaySeconds =
        input.thresholds?.minMaxDelaySeconds ??
        this.defaultEscalationMinMaxDelaySeconds;

      const breached =
        input.overdueUnresolvedCount >= minOverdueCount &&
        input.maxDelaySeconds >= minMaxDelaySeconds;

      const reason = breached
        ? `Escalation delay thresholds breached: overdue_unresolved=${input.overdueUnresolvedCount}, overdue_critical=${input.overdueCriticalCount}, max_delay_seconds=${input.maxDelaySeconds}, min_overdue_count=${minOverdueCount}, min_max_delay_seconds=${minMaxDelaySeconds}.`
        : `Escalation delay thresholds not breached: overdue_unresolved=${input.overdueUnresolvedCount}, overdue_critical=${input.overdueCriticalCount}, max_delay_seconds=${input.maxDelaySeconds}, min_overdue_count=${minOverdueCount}, min_max_delay_seconds=${minMaxDelaySeconds}.`;

      await this.logService.logEvent({
        category: 'SYSTEM' as LogCategory,
        level: (breached ? 'WARNING' : 'INFO') as LogLevel,
        message: breached
          ? 'Escalation delay alert evaluated: thresholds breached.'
          : 'Escalation delay alert evaluated: thresholds not breached.',
        identifier: `org_id:${input.organizationId}`,
        functionId: FN_ALERT_ESCALATION_DELAY,
        metadata: {
          environment: input.environment,
          profileKey: input.profileKey,
          overdueUnresolvedCount: input.overdueUnresolvedCount,
          overdueCriticalCount: input.overdueCriticalCount,
          maxDelaySeconds: input.maxDelaySeconds,
          minOverdueCount,
          minMaxDelaySeconds,
          breached,
        },
      });

      return {
        ok: true,
        data: {
          alertType: 'ESCALATION_DELAY',
          triggered: breached,
          reason,
          metadata: {
            organizationId: input.organizationId,
            profileKey: input.profileKey,
            environment: input.environment,
          },
        },
        error: null,
      };
    } catch (error) {
      const err =
        error instanceof Error
          ? error
          : new Error('Unknown error in triggerEscalationDelayAlert');

      await this.logService.logEvent({
        category: 'SYSTEM' as LogCategory,
        level: 'ERROR' as LogLevel,
        message: 'Failed to evaluate escalation delay alert.',
        identifier: `org_id:${input.organizationId}`,
        functionId: FN_ALERT_ESCALATION_DELAY,
        metadata: {
          error: err.message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'ALERT_EVALUATION_ERROR',
          message: err.message,
          details: {
            alertType: 'ESCALATION_DELAY',
          },
        },
      };
    }
  }

  /**
   * Emits an alert when error rates across services exceed configured thresholds.
   *
   * This method is typically called by the background job
   * `orgo.alerts.error-rate`, which aggregates error-rate metrics from the
   * observability stack (Prometheus/Grafana, logs, etc.) and passes them here.
   */
  async triggerErrorRateAlert(
    input: ErrorRateAlertInput,
  ): Promise<StandardResult<AlertTriggerResult>> {
    try {
      const threshold =
        input.thresholdErrorRate ?? this.defaultErrorRateThreshold;

      const breached =
        input.errorRate >= threshold && input.requestCount > 0 && threshold > 0;

      const reason = breached
        ? `Error-rate threshold breached for service "${input.serviceId}" in ${input.environment}: error_rate=${input.errorRate}, threshold=${threshold}, window_minutes=${input.windowMinutes}, request_count=${input.requestCount}.`
        : `Error-rate threshold not breached for service "${input.serviceId}" in ${input.environment}: error_rate=${input.errorRate}, threshold=${threshold}, window_minutes=${input.windowMinutes}, request_count=${input.requestCount}.`;

      await this.logService.logEvent({
        category: 'SYSTEM' as LogCategory,
        level: (breached ? 'WARNING' : 'INFO') as LogLevel,
        message: breached
          ? 'Error-rate alert evaluated: thresholds breached.'
          : 'Error-rate alert evaluated: thresholds not breached.',
        identifier: `service_id:${input.serviceId}`,
        functionId: FN_ALERT_ERROR_RATE,
        metadata: {
          environment: input.environment,
          serviceId: input.serviceId,
          errorRate: input.errorRate,
          requestCount: input.requestCount,
          threshold,
          windowMinutes: input.windowMinutes,
          breached,
        },
      });

      return {
        ok: true,
        data: {
          alertType: 'ERROR_RATE',
          triggered: breached,
          reason,
          metadata: {
            serviceId: input.serviceId,
            environment: input.environment,
          },
        },
        error: null,
      };
    } catch (error) {
      const err =
        error instanceof Error
          ? error
          : new Error('Unknown error in triggerErrorRateAlert');

      await this.logService.logEvent({
        category: 'SYSTEM' as LogCategory,
        level: 'ERROR' as LogLevel,
        message: 'Failed to evaluate error-rate alert.',
        identifier: `service_id:${input.serviceId}`,
        functionId: FN_ALERT_ERROR_RATE,
        metadata: {
          error: err.message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'ALERT_EVALUATION_ERROR',
          message: err.message,
          details: {
            alertType: 'ERROR_RATE',
          },
        },
      };
    }
  }
}


=== FILE 2/48: apps/api/src/orgo/core/cases/case.controller.ts ===

import {
  BadRequestException,
  Controller,
  Get,
  Logger,
  NotFoundException,
  Param,
  Query,
  Req,
} from '@nestjs/common';
import {
  ApiExtraModels,
  ApiOkResponse,
  ApiOperation,
  ApiParam,
  ApiProperty,
  ApiPropertyOptional,
  ApiTags,
} from '@nestjs/swagger';
import { Request } from 'express';
import { CaseService } from './case.service';

// -----------------------------------------------------------------------------
// Canonical enums (mirroring Docs 2 & 8 JSON shapes for Cases / Tasks)
// -----------------------------------------------------------------------------

export const CASE_STATUS_VALUES = ['open', 'in_progress', 'resolved', 'archived'] as const;
export type CaseStatus = (typeof CASE_STATUS_VALUES)[number];

export const CASE_SEVERITY_VALUES = ['minor', 'moderate', 'major', 'critical'] as const;
export type CaseSeverity = (typeof CASE_SEVERITY_VALUES)[number];

export const VISIBILITY_VALUES = ['PUBLIC', 'INTERNAL', 'RESTRICTED', 'ANONYMISED'] as const;
export type Visibility = (typeof VISIBILITY_VALUES)[number];

export const TASK_STATUS_VALUES = [
  'PENDING',
  'IN_PROGRESS',
  'ON_HOLD',
  'COMPLETED',
  'FAILED',
  'ESCALATED',
  'CANCELLED',
] as const;
export type TaskStatus = (typeof TASK_STATUS_VALUES)[number];

export const TASK_PRIORITY_VALUES = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'] as const;
export type TaskPriority = (typeof TASK_PRIORITY_VALUES)[number];

export const TASK_SEVERITY_VALUES = ['MINOR', 'MODERATE', 'MAJOR', 'CRITICAL'] as const;
export type TaskSeverity = (typeof TASK_SEVERITY_VALUES)[number];

export const TASK_CATEGORY_VALUES = [
  'request',
  'incident',
  'update',
  'report',
  'distribution',
] as const;
export type TaskCategory = (typeof TASK_CATEGORY_VALUES)[number];

export type CaseSortBy = 'created_at' | 'updated_at';
export type SortDirection = 'asc' | 'desc';

// -----------------------------------------------------------------------------
// DTOs
// -----------------------------------------------------------------------------

export class ListCasesQueryDto {
  @ApiPropertyOptional({ enum: CASE_STATUS_VALUES, description: 'Filter by Case status' })
  status?: CaseStatus;

  @ApiPropertyOptional({
    enum: CASE_SEVERITY_VALUES,
    description: 'Filter by Case severity (JSON form)',
  })
  severity?: CaseSeverity;

  @ApiPropertyOptional({
    enum: VISIBILITY_VALUES,
    description: 'Filter by visibility; maps to VISIBILITY enum',
  })
  visibility?: Visibility;

  @ApiPropertyOptional({
    description:
      'Filter by canonical label "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE>"',
    example: '100.94.Operations.Safety',
  })
  label?: string;

  @ApiPropertyOptional({
    description: 'Free-text search over title/description/metadata (implementation-specific)',
  })
  search?: string;

  @ApiPropertyOptional({
    minimum: 1,
    default: 1,
    description: '1-based page number for pagination',
  })
  page?: number;

  @ApiPropertyOptional({
    minimum: 1,
    maximum: 200,
    default: 25,
    description: 'Page size for pagination (max 200)',
  })
  pageSize?: number;

  @ApiPropertyOptional({
    enum: ['created_at', 'updated_at'],
    default: 'updated_at',
    description: 'Field to sort by',
  })
  sortBy?: CaseSortBy;

  @ApiPropertyOptional({
    enum: ['asc', 'desc'],
    default: 'desc',
    description: 'Sort direction',
  })
  sortDirection?: SortDirection;
}

/**
 * Canonical Case JSON DTO (aligned with Doc 8 §8.4.1).
 */
export class CaseDto {
  @ApiProperty({ format: 'uuid', description: 'Case identifier (maps from cases.id)' })
  case_id!: string;

  @ApiProperty({ format: 'uuid', description: 'Owning organization (tenant) id' })
  organization_id!: string;

  @ApiProperty({
    enum: ['email', 'api', 'manual', 'sync'],
    description: 'Origin channel for this Case',
  })
  source_type!: 'email' | 'api' | 'manual' | 'sync';

  @ApiPropertyOptional({
    nullable: true,
    description: 'Channel-specific reference (e.g., email message-id, external URI)',
  })
  source_reference?: string | null;

  @ApiProperty({
    description: 'Canonical label "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE>"',
  })
  label!: string;

  @ApiProperty({ description: 'Short human-readable title' })
  title!: string;

  @ApiProperty({ description: 'Free-text description/body' })
  description!: string;

  @ApiProperty({
    enum: CASE_STATUS_VALUES,
    description: 'Case lifecycle status (CASE_STATUS; JSON form)',
  })
  status!: CaseStatus;

  @ApiProperty({
    enum: CASE_SEVERITY_VALUES,
    description: 'Severity (JSON form mapping to TASK_SEVERITY enum)',
  })
  severity!: CaseSeverity;

  @ApiPropertyOptional({
    nullable: true,
    description: 'ISO-8601 duration; SLA window for Case handling (e.g. "PT2H")',
  })
  reactivity_time?: string | null;

  @ApiPropertyOptional({
    nullable: true,
    description: 'Vertical base of the originating label (e.g. 100, 1000)',
  })
  origin_vertical_level?: number | null;

  @ApiPropertyOptional({
    nullable: true,
    description: 'Horizontal role of origin (e.g. "Ops.Maintenance")',
  })
  origin_role?: string | null;

  @ApiPropertyOptional({
    type: [String],
    nullable: true,
    description: 'Optional tag list attached to the Case',
  })
  tags?: string[] | null;

  @ApiPropertyOptional({
    type: Object,
    nullable: true,
    description: 'Structured location payload (site/building/geo, etc.)',
  })
  location?: Record<string, unknown> | null;

  @ApiPropertyOptional({
    type: Object,
    description:
      'Case-level metadata (pattern_sensitivity, review settings, domain-specific fields, etc.)',
  })
  metadata?: Record<string, unknown>;

  @ApiProperty({
    description: 'Creation timestamp (ISO-8601 UTC)',
  })
  created_at!: string;

  @ApiProperty({
    description: 'Last update timestamp (ISO-8601 UTC)',
  })
  updated_at!: string;
}

/**
 * Summary view of a Task for inclusion under a Case.
 * Uses canonical Task enums from Docs 2 & 8.
 */
export class TaskSummaryDto {
  @ApiProperty({ format: 'uuid', description: 'Task identifier (maps from tasks.id)' })
  task_id!: string;

  @ApiProperty({
    enum: TASK_STATUS_VALUES,
    description: 'Task lifecycle status (TASK_STATUS)',
  })
  status!: TaskStatus;

  @ApiProperty({
    enum: TASK_PRIORITY_VALUES,
    description: 'Task priority (TASK_PRIORITY)',
  })
  priority!: TaskPriority;

  @ApiProperty({
    enum: TASK_SEVERITY_VALUES,
    description: 'Task severity (TASK_SEVERITY)',
  })
  severity!: TaskSeverity;

  @ApiProperty({
    enum: TASK_CATEGORY_VALUES,
    description: 'Global Task category',
  })
  category!: TaskCategory;

  @ApiPropertyOptional({
    nullable: true,
    description: 'Domain-specific subtype (e.g. "plumbing", "harassment")',
  })
  subtype?: string | null;

  @ApiProperty({
    description: 'Canonical Task label',
  })
  label!: string;

  @ApiProperty({ description: 'Short Task title' })
  title!: string;

  @ApiPropertyOptional({
    nullable: true,
    description: 'Current owning routing role label (e.g. "Ops.Maintenance")',
  })
  assignee_role?: string | null;

  @ApiPropertyOptional({
    nullable: true,
    description: 'Due date (ISO-8601 UTC), if any',
  })
  due_at?: string | null;

  @ApiPropertyOptional({
    nullable: true,
    description:
      'First-response SLA deadline (ISO-8601 UTC; derived from created_at + reactivity_time)',
  })
  reactivity_deadline_at?: string | null;
}

/**
 * Shape returned by GET /v3/cases/:caseId – Case plus linked Tasks.
 */
export class CaseWithTasksDto {
  @ApiProperty({ type: () => CaseDto })
  case!: CaseDto;

  @ApiProperty({ type: () => [TaskSummaryDto] })
  tasks!: TaskSummaryDto[];
}

/**
 * Paginated Case list response for GET /v3/cases.
 */
export class PaginatedCaseSummaryDto {
  @ApiProperty({ type: () => [CaseDto] })
  items!: CaseDto[];

  @ApiProperty({
    description: 'Total number of Cases matching the filter (across all pages)',
  })
  total!: number;

  @ApiProperty({
    description: 'Current page index (1-based)',
    example: 1,
  })
  page!: number;

  @ApiProperty({
    description: 'Page size used for this response',
    example: 25,
  })
  pageSize!: number;
}

// Internal normalized query representation used between controller and service.
interface NormalizedCaseListQuery {
  status?: CaseStatus;
  severity?: CaseSeverity;
  visibility?: Visibility;
  label?: string;
  search?: string;
  page: number;
  pageSize: number;
  sortBy: CaseSortBy;
  sortDirection: SortDirection;
}

// -----------------------------------------------------------------------------
// Controller
// -----------------------------------------------------------------------------

@ApiTags('cases')
@ApiExtraModels(CaseDto, TaskSummaryDto, CaseWithTasksDto, PaginatedCaseSummaryDto)
@Controller('v3/cases')
export class CaseController {
  private readonly logger = new Logger(CaseController.name);

  constructor(private readonly caseService: CaseService) {}

  /**
   * List Cases for the current organization, with basic filtering and pagination.
   *
   * External path (via reverse proxy): GET /api/v3/cases
   */
  @Get()
  @ApiOperation({
    summary: 'List Cases',
    description:
      'Returns a paginated list of Cases for the current organization, filtered by status, severity, visibility, label, and/or search text.',
  })
  @ApiOkResponse({ type: PaginatedCaseSummaryDto })
  async listCases(
    @Req() req: Request,
    @Query() query: ListCasesQueryDto,
  ): Promise<PaginatedCaseSummaryDto> {
    const organizationId = this.getOrganizationIdFromRequest(req);
    const normalizedQuery = this.normalizeListQuery(query);

    this.logger.debug(
      `Listing cases for org ${organizationId} (page=${normalizedQuery.page}, pageSize=${normalizedQuery.pageSize})`,
    );

    // Implementation of listCases is provided by CaseService.
    return this.caseService.listCases(organizationId, normalizedQuery);
  }

  /**
   * Fetch a single Case and its linked Tasks for the current organization.
   *
   * External path (via reverse proxy): GET /api/v3/cases/:caseId
   */
  @Get(':caseId')
  @ApiOperation({
    summary: 'Get Case details',
    description: 'Returns a Case and its linked Tasks for the current organization.',
  })
  @ApiParam({
    name: 'caseId',
    description: 'Case identifier (UUID)',
  })
  @ApiOkResponse({ type: CaseWithTasksDto })
  async getCaseById(
    @Req() req: Request,
    @Param('caseId') caseId: string,
  ): Promise<CaseWithTasksDto> {
    const organizationId = this.getOrganizationIdFromRequest(req);

    const result = await this.caseService.getCaseWithTasks(organizationId, caseId);

    if (!result) {
      throw new NotFoundException(
        `Case ${caseId} not found for current organization or access is not permitted.`,
      );
    }

    return result;
  }

  // ---------------------------------------------------------------------------
  // Helpers
  // ---------------------------------------------------------------------------

  /**
   * Extracts the current organization id from the HTTP request.
   *
   * In a real deployment this is typically injected by an Auth/RBAC guard
   * (e.g. from a JWT). For now we expect X-Org-Id or X-Organization-Id headers.
   */
  private getOrganizationIdFromRequest(req: Request): string {
    const headerValue =
      (req.headers['x-org-id'] as string | undefined) ||
      (req.headers['x-organization-id'] as string | undefined);

    if (!headerValue) {
      throw new BadRequestException(
        'Missing organization identifier (expected X-Org-Id or X-Organization-Id header).',
      );
    }

    return headerValue;
  }

  /**
   * Normalizes list query parameters, validates enums, and applies defaults.
   */
  private normalizeListQuery(query: ListCasesQueryDto): NormalizedCaseListQuery {
    const pageRaw = query.page ?? 1;
    const page = Number.isFinite(+pageRaw) && +pageRaw > 0 ? Number(pageRaw) : 1;

    const pageSizeRaw = query.pageSize ?? 25;
    const rawPageSize = Number.isFinite(+pageSizeRaw) && +pageSizeRaw > 0 ? Number(pageSizeRaw) : 25;
    const pageSize = Math.min(rawPageSize, 200);

    let status: CaseStatus | undefined;
    if (query.status !== undefined) {
      if (!CASE_STATUS_VALUES.includes(query.status)) {
        throw new BadRequestException(
          `Invalid status "${query.status}". Expected one of: ${CASE_STATUS_VALUES.join(', ')}`,
        );
      }
      status = query.status;
    }

    let severity: CaseSeverity | undefined;
    if (query.severity !== undefined) {
      if (!CASE_SEVERITY_VALUES.includes(query.severity)) {
        throw new BadRequestException(
          `Invalid severity "${query.severity}". Expected one of: ${CASE_SEVERITY_VALUES.join(', ')}`,
        );
      }
      severity = query.severity;
    }

    let visibility: Visibility | undefined;
    if (query.visibility !== undefined) {
      if (!VISIBILITY_VALUES.includes(query.visibility)) {
        throw new BadRequestException(
          `Invalid visibility "${query.visibility}". Expected one of: ${VISIBILITY_VALUES.join(', ')}`,
        );
      }
      visibility = query.visibility;
    }

    const sortBy: CaseSortBy = (query.sortBy ?? 'updated_at') as CaseSortBy;
    if (!['created_at', 'updated_at'].includes(sortBy)) {
      throw new BadRequestException('sortBy must be one of: "created_at", "updated_at".');
    }

    const sortDirection: SortDirection = (query.sortDirection ?? 'desc') as SortDirection;
    if (!['asc', 'desc'].includes(sortDirection)) {
      throw new BadRequestException('sortDirection must be one of: "asc", "desc".');
    }

    const label = query.label?.trim() || undefined;
    const search = query.search?.trim() || undefined;

    return {
      status,
      severity,
      visibility,
      label,
      search,
      page,
      pageSize,
      sortBy,
      sortDirection,
    };
  }
}


=== FILE 3/48: apps/api/src/orgo/core/cases/case.module.ts ===

import { Module } from '@nestjs/common';
import { CaseService } from './case.service';
import { CaseController } from './case.controller';
import { CaseReviewService } from './case-review.service';
import { DatabaseModule } from '../database/database.module';

/**
 * CaseModule
 *
 * Core Services – Case Management
 * Wires up:
 *  - CaseService (create/fetch cases, link to tasks)
 *  - CaseReviewService (cyclic case review passes)
 *  - CaseController (HTTP API surface for cases)
 *
 * Depends on:
 *  - DatabaseModule (DatabaseService + RepositoryFactory)
 */
@Module({
  imports: [DatabaseModule],
  controllers: [CaseController],
  providers: [CaseService, CaseReviewService],
  exports: [CaseService, CaseReviewService],
})
export class CaseModule {}


=== FILE 4/48: apps/api/src/orgo/core/cases/case.service.ts ===

import { Injectable } from '@nestjs/common';
import { Prisma, Case, Task } from '@prisma/client';
import { PrismaService } from '../../../persistence/prisma/prisma.service';
import { LogService } from '../logging/log.service';

export type CaseStatus = 'open' | 'in_progress' | 'resolved' | 'archived';

export type CaseSeverity = 'MINOR' | 'MODERATE' | 'MAJOR' | 'CRITICAL';

export interface ServiceError {
  code: string;
  message: string;
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  details?: any;
}

export interface ServiceResult<T> {
  ok: boolean;
  data: T | null;
  error: ServiceError | null;
}

export interface CreateCaseFromSignalInput {
  organizationId: string;
  sourceType: string; // email | api | manual | sync (or historical ui/import/insight)
  sourceReference?: string | null;

  label: string; // "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE>"
  title: string;
  description: string;

  severity: string; // MINOR|MODERATE|MAJOR|CRITICAL or lower-case/json variant

  // Optional context
  originVerticalLevel?: number | null;
  originRole?: string | null;
  tags?: string[];
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  location?: Record<string, any> | null;
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  metadata?: Record<string, any> | null;

  /**
   * Optional SLA for this case, in seconds.
   * If provided, will be stored as an ISO-8601 duration string (e.g. "PT3600S").
   * Profiles / workflows may override or refine this later.
   */
  reactivityTimeSeconds?: number | null;
}

export interface GetCaseWithTasksOptions {
  organizationId: string;
  caseId: string;
  /**
   * If false, only unresolved tasks are returned (PENDING, IN_PROGRESS, ON_HOLD, ESCALATED).
   * Defaults to true = include all tasks.
   */
  includeClosedTasks?: boolean;
}

export interface CaseWithTasks {
  case: Case;
  tasks: Task[];
}

export interface ListCasesParams {
  organizationId: string;
  status?: CaseStatus | CaseStatus[];
  severity?: CaseSeverity | CaseSeverity[];
  /**
   * Filter by label prefix (e.g. "100.94." to get all safety-related cases at base 100).
   */
  labelPrefix?: string;
  /**
   * Free-text search in title/description.
   */
  search?: string;
  /**
   * Pagination (offset/limit).
   */
  offset?: number;
  limit?: number;
}

export interface PaginatedResult<T> {
  items: T[];
  total: number;
  offset: number;
  limit: number;
}

/**
 * CaseService implements the generic Case management logic:
 * - createCaseFromSignal: create a Case from an incoming signal/pattern
 * - getCaseWithTasks: fetch a Case and its linked Tasks
 * - listCases: list Cases per organization with filters
 * - updateCaseStatus: enforce the Case status lifecycle
 *
 * It follows the Orgo v3 specs (Docs 1, 2, 5, 8) for schema and lifecycle.
 */
@Injectable()
export class CaseService {
  constructor(
    private readonly prisma: PrismaService,
    private readonly logService: LogService,
  ) {}

  /**
   * Creates a Case row from an incoming signal (email/API/offline) or pattern.
   *
   * Responsibilities:
   * - Validate required fields.
   * - Normalize sourceType and severity to canonical tokens.
   * - Set initial status = "open".
   * - Store profile/workflow-driven fields in metadata/reactivityTime where applicable.
   */
  async createCaseFromSignal(
    input: CreateCaseFromSignalInput,
  ): Promise<ServiceResult<Case>> {
    const validationError = this.validateCreateCaseInput(input);
    if (validationError) {
      return {
        ok: false,
        data: null,
        error: validationError,
      };
    }

    let severity: CaseSeverity;
    let sourceType: 'email' | 'api' | 'manual' | 'sync';
    try {
      severity = this.normalizeSeverity(input.severity);
      sourceType = this.normalizeSourceType(input.sourceType);
    } catch (err) {
      return this.failure<Case>(
        'CASE_VALIDATION_ERROR',
        (err as Error).message,
      );
    }

    const reactivityTime =
      input.reactivityTimeSeconds != null
        ? this.secondsToIsoDuration(input.reactivityTimeSeconds)
        : null;

    try {
      const created = await this.prisma.case.create({
        data: {
          organizationId: input.organizationId,
          sourceType,
          sourceReference: input.sourceReference ?? null,
          label: input.label,
          title: input.title,
          description: input.description,
          status: 'open',
          severity,
          reactivityTime,
          originVerticalLevel: input.originVerticalLevel ?? null,
          originRole: input.originRole ?? null,
          tags: input.tags ?? [],
          location: (input.location ?? {}) as Prisma.JsonValue,
          metadata: (input.metadata ?? {}) as Prisma.JsonValue,
        },
      });

      // Best-effort logging; failures here should not break the main flow.
      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'INFO',
        message: 'Case created from signal',
        identifier: `case_id:${created.id}`,
        metadata: {
          organizationId: created.organizationId,
          sourceType,
          label: created.label,
          severity: created.severity,
          functionId: 'FN_CASE_CREATE',
        },
      });

      return this.success(created);
    } catch (error) {
      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'ERROR',
        message: 'Failed to create case from signal',
        metadata: {
          organizationId: input.organizationId,
          label: input.label,
          error: this.safeErrorToString(error),
          functionId: 'FN_CASE_CREATE',
        },
      });

      return this.failure<Case>(
        'CASE_CREATE_ERROR',
        'Failed to create case',
        error,
      );
    }
  }

  /**
   * Fetch a Case and its linked Tasks (via tasks.caseId).
   *
   * This is used by generic Case detail UIs and domain-specific views.
   */
  async getCaseWithTasks(
    options: GetCaseWithTasksOptions,
  ): Promise<ServiceResult<CaseWithTasks>> {
    const { organizationId, caseId } = options;

    try {
      const caseRecord = await this.prisma.case.findFirst({
        where: {
          id: caseId,
          organizationId,
        },
      });

      if (!caseRecord) {
        return this.failure<CaseWithTasks>(
          'CASE_NOT_FOUND',
          'Case not found for this organization',
          { organizationId, caseId },
        );
      }

      const tasksWhere: Prisma.TaskWhereInput = {
        organizationId,
        caseId: caseRecord.id,
      };

      if (options.includeClosedTasks === false) {
        tasksWhere.status = {
          in: ['PENDING', 'IN_PROGRESS', 'ON_HOLD', 'ESCALATED'],
        };
      }

      const tasks = await this.prisma.task.findMany({
        where: tasksWhere,
        orderBy: { createdAt: 'asc' },
      });

      return this.success<CaseWithTasks>({
        case: caseRecord,
        tasks,
      });
    } catch (error) {
      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'ERROR',
        message: 'Failed to fetch case with tasks',
        metadata: {
          organizationId,
          caseId,
          error: this.safeErrorToString(error),
          functionId: 'FN_CASE_GET_WITH_TASKS',
        },
      });

      return this.failure<CaseWithTasks>(
        'CASE_FETCH_ERROR',
        'Failed to fetch case with tasks',
        error,
      );
    }
  }

  /**
   * List Cases for an organization with basic filters and pagination.
   */
  async listCases(
    params: ListCasesParams,
  ): Promise<ServiceResult<PaginatedResult<Case>>> {
    const {
      organizationId,
      status,
      severity,
      labelPrefix,
      search,
      offset = 0,
      limit = 50,
    } = params;

    const where: Prisma.CaseWhereInput = {
      organizationId,
    };

    if (status) {
      if (Array.isArray(status)) {
        where.status = { in: status };
      } else {
        where.status = status;
      }
    }

    if (severity) {
      if (Array.isArray(severity)) {
        where.severity = { in: severity };
      } else {
        where.severity = severity;
      }
    }

    if (labelPrefix) {
      where.label = { startsWith: labelPrefix };
    }

    if (search) {
      where.OR = [
        { title: { contains: search, mode: 'insensitive' } },
        { description: { contains: search, mode: 'insensitive' } },
      ];
    }

    try {
      const [items, total] = await this.prisma.$transaction([
        this.prisma.case.findMany({
          where,
          orderBy: { createdAt: 'desc' },
          skip: offset,
          take: limit,
        }),
        this.prisma.case.count({ where }),
      ]);

      return this.success<PaginatedResult<Case>>({
        items,
        total,
        offset,
        limit,
      });
    } catch (error) {
      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'ERROR',
        message: 'Failed to list cases',
        metadata: {
          organizationId,
          error: this.safeErrorToString(error),
          functionId: 'FN_CASE_LIST',
        },
      });

      return this.failure<PaginatedResult<Case>>(
        'CASE_LIST_ERROR',
        'Failed to list cases',
        error,
      );
    }
  }

  /**
   * Update Case status, enforcing the canonical Case lifecycle:
   *
   * Allowed transitions:
   * - open        -> in_progress, resolved, archived
   * - in_progress -> resolved, archived
   * - resolved    -> archived, in_progress (re-open)
   * - archived    -> (terminal)
   */
  async updateCaseStatus(
    organizationId: string,
    caseId: string,
    newStatus: CaseStatus,
  ): Promise<ServiceResult<Case>> {
    try {
      const caseRecord = await this.prisma.case.findFirst({
        where: {
          id: caseId,
          organizationId,
        },
      });

      if (!caseRecord) {
        return this.failure<Case>(
          'CASE_NOT_FOUND',
          'Case not found for this organization',
          { organizationId, caseId },
        );
      }

      const currentStatus = caseRecord.status as CaseStatus;

      if (!this.isValidStatusTransition(currentStatus, newStatus)) {
        return this.failure<Case>(
          'INVALID_CASE_STATE_TRANSITION',
          `Transition ${currentStatus} → ${newStatus} is not allowed`,
          { organizationId, caseId },
        );
      }

      const updated = await this.prisma.case.update({
        where: { id: caseRecord.id },
        data: {
          status: newStatus,
        },
      });

      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'INFO',
        message: 'Case status updated',
        identifier: `case_id:${updated.id}`,
        metadata: {
          organizationId: updated.organizationId,
          oldStatus: currentStatus,
          newStatus,
          functionId: 'FN_CASE_UPDATE_STATUS',
        },
      });

      return this.success(updated);
    } catch (error) {
      void this.logService.logEvent({
        category: 'SYSTEM',
        level: 'ERROR',
        message: 'Failed to update case status',
        metadata: {
          organizationId,
          caseId,
          newStatus,
          error: this.safeErrorToString(error),
          functionId: 'FN_CASE_UPDATE_STATUS',
        },
      });

      return this.failure<Case>(
        'CASE_UPDATE_STATUS_ERROR',
        'Failed to update case status',
        error,
      );
    }
  }

  // ---------------------------------------------------------------------------
  // Helpers
  // ---------------------------------------------------------------------------

  private validateCreateCaseInput(
    input: CreateCaseFromSignalInput,
  ): ServiceError | null {
    const missing: string[] = [];

    if (!input.organizationId) missing.push('organizationId');
    if (!input.sourceType) missing.push('sourceType');
    if (!input.label) missing.push('label');
    if (!input.title) missing.push('title');
    if (!input.description) missing.push('description');
    if (!input.severity) missing.push('severity');

    if (missing.length > 0) {
      return {
        code: 'CASE_VALIDATION_ERROR',
        message: `Missing required fields: ${missing.join(', ')}`,
        details: { missingFields: missing },
      };
    }

    return null;
  }

  private normalizeSeverity(severity: string): CaseSeverity {
    const value = severity.trim();

    if (!value) {
      throw new Error('Severity must not be empty');
    }

    const lower = value.toLowerCase();

    // Historical mapping: "info" -> MINOR (Doc 1/2).
    if (lower === 'info') {
      return 'MINOR';
    }

    const upper = lower.toUpperCase() as CaseSeverity;

    if (upper === 'MINOR' || upper === 'MODERATE' || upper === 'MAJOR' || upper === 'CRITICAL') {
      return upper;
    }

    throw new Error(`Invalid case severity: ${severity}`);
  }

  private normalizeSourceType(
    sourceType: string,
  ): 'email' | 'api' | 'manual' | 'sync' {
    const value = sourceType.trim();

    if (!value) {
      throw new Error('sourceType must not be empty');
    }

    const lower = value.toLowerCase();

    // Historical mappings (Doc 1 §Enum implementation notes).
    if (lower === 'ui') return 'manual';
    if (lower === 'import') return 'sync';
    if (lower === 'insight') return 'api';

    if (lower === 'email' || lower === 'api' || lower === 'manual' || lower === 'sync') {
      return lower;
    }

    throw new Error(`Invalid case sourceType: ${sourceType}`);
  }

  /**
   * Convert seconds to an ISO-8601 duration string (e.g. 3600 -> "PT3600S").
   * DB stores reactivityTime as an interval; the exact mapping is handled at schema level.
   */
  private secondsToIsoDuration(seconds: number): string {
    const s = Math.max(0, Math.floor(seconds));
    return `PT${s}S`;
  }

  private isValidStatusTransition(
    from: CaseStatus,
    to: CaseStatus,
  ): boolean {
    if (from === to) {
      // No-op transitions are allowed but usually pointless; treat as valid.
      return true;
    }

    switch (from) {
      case 'open':
        return to === 'in_progress' || to === 'resolved' || to === 'archived';
      case 'in_progress':
        return to === 'resolved' || to === 'archived';
      case 'resolved':
        return to === 'archived' || to === 'in_progress';
      case 'archived':
        // archived is terminal in normal flows
        return false;
      default:
        return false;
    }
  }

  private success<T>(data: T): ServiceResult<T> {
    return {
      ok: true,
      data,
      error: null,
    };
  }

  private failure<T>(
    code: string,
    message: string,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    details?: any,
  ): ServiceResult<T> {
    return {
      ok: false,
      data: null,
      error: { code, message, details },
    };
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private safeErrorToString(error: any): string {
    if (!error) return 'Unknown error';
    if (error instanceof Error) return error.message;
    if (typeof error === 'string') return error;
    try {
      return JSON.stringify(error);
    } catch {
      return 'Unserializable error';
    }
  }
}


=== FILE 5/48: apps/api/src/orgo/core/cases/dto/create-case.dto.ts ===

// apps/api/src/orgo/core/cases/dto/create-case.dto.ts

import { ApiProperty, ApiPropertyOptional } from '@nestjs/swagger';
import { Transform } from 'class-transformer';
import {
  IsArray,
  IsIn,
  IsInt,
  IsNotEmpty,
  IsObject,
  IsOptional,
  IsString,
  IsUUID,
  MaxLength,
  Min,
  Matches,
} from 'class-validator';

// Canonical enums for Cases (JSON-facing, aligned with Docs 1/2/8)
export const CASE_SOURCE_TYPES = ['email', 'api', 'manual', 'sync'] as const;
export type CaseSourceType = (typeof CASE_SOURCE_TYPES)[number];

export const CASE_SEVERITIES = ['minor', 'moderate', 'major', 'critical'] as const;
export type CaseSeverity = (typeof CASE_SEVERITIES)[number];

// Canonical label shape: "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE?>"
// BASE: integer (e.g. 1, 11, 100, 1000)
// CATEGORY: 1–9, SUBCATEGORY: 1–5  → encoded as two digits [1-9][1-5]
// HORIZONTAL_ROLE: dot‑separated segments like "Ops.Maintenance"
export const LABEL_CODE_REGEX =
  /^\d+\.[1-9][1-5](?:\.[A-Za-z0-9]+(?:\.[A-Za-z0-9]+)*)?$/;

export class CreateCaseDto {
  @ApiProperty({
    description: 'Tenant organization identifier (UUID; maps to organizations.id).',
    format: 'uuid',
  })
  @IsUUID()
  organization_id!: string;

  @ApiProperty({
    description:
      'Origin channel for the Case (maps to cases.source_type / task_source_enum).',
    enum: CASE_SOURCE_TYPES,
    example: 'email',
  })
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toLowerCase().trim() : value,
  )
  @IsIn(CASE_SOURCE_TYPES)
  source_type!: CaseSourceType;

  @ApiPropertyOptional({
    description:
      'Channel-specific reference (e.g. email message-id, external URI).',
    nullable: true,
    example: '<message-id@example.org>',
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsString()
  @IsOptional()
  source_reference?: string;

  @ApiProperty({
    description:
      'Canonical information label "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE?>".',
    example: '100.94.Operations.Safety',
  })
  @Transform(({ value }) => (typeof value === 'string' ? value.trim() : value))
  @IsString()
  @IsNotEmpty()
  @Matches(LABEL_CODE_REGEX, {
    message:
      'label must match "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE?>" (e.g. "100.94.Operations.Safety")',
  })
  label!: string;

  @ApiProperty({
    description: 'Short human-readable title for the Case.',
    maxLength: 512,
    example: 'Wet floor in main hallway near gym entrance',
  })
  @Transform(({ value }) => (typeof value === 'string' ? value.trim() : value))
  @IsString()
  @IsNotEmpty()
  @MaxLength(512)
  title!: string;

  @ApiProperty({
    description: 'Detailed description or narrative for the Case.',
    example:
      'Student slipped on wet floor near the gym entrance. No serious injury, but repeated incidents reported over the past month.',
  })
  @Transform(({ value }) => (typeof value === 'string' ? value.trim() : value))
  @IsString()
  @IsNotEmpty()
  description!: string;

  @ApiProperty({
    description:
      'Case severity (JSON form of TASK_SEVERITY; lower-case tokens map to DB enum).',
    enum: CASE_SEVERITIES,
    example: 'major',
  })
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toLowerCase().trim() : value,
  )
  @IsIn(CASE_SEVERITIES)
  severity!: CaseSeverity;

  @ApiPropertyOptional({
    description:
      'ISO‑8601 duration for expected responsiveness window (e.g. "PT2H").',
    nullable: true,
    example: 'PT2H',
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsString()
  @IsOptional()
  reactivity_time?: string;

  @ApiPropertyOptional({
    description:
      'Vertical base from the original label (e.g. 100, 1000); used for cyclic overview and broadcast semantics.',
    nullable: true,
    example: 1000,
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsInt()
  @Min(1)
  @IsOptional()
  origin_vertical_level?: number;

  @ApiPropertyOptional({
    description:
      'Horizontal role of origin (e.g. "Ops.Maintenance", "HR.CaseOfficer").',
    nullable: true,
    example: 'Ops.Maintenance',
  })
  @Transform(({ value }) =>
    typeof value === 'string' ? value.trim() : value === null ? undefined : value,
  )
  @IsString()
  @IsOptional()
  origin_role?: string;

  @ApiPropertyOptional({
    description:
      'High-level classification tags for the Case (e.g. ["safety","wet_floor"]).',
    nullable: true,
    type: [String],
    example: ['safety', 'facility', 'wet_floor'],
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsArray()
  @IsString({ each: true })
  @IsOptional()
  tags?: string[];

  @ApiPropertyOptional({
    description:
      'Structured location information (site, building, GPS, etc.). Shape is domain-specific.',
    nullable: true,
    example: {
      site: 'North Campus',
      building: 'Gym',
      floor: 1,
      area: 'Main entrance corridor',
    },
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsObject()
  @IsOptional()
  location?: Record<string, any>;

  @ApiPropertyOptional({
    description:
      'Case-level metadata (pattern_sensitivity, review settings, visibility, escalation path, profile hints, etc.).',
    nullable: true,
    example: {
      visibility: 'internal',
      pattern_sensitivity: 'high',
      review_frequency: 'monthly',
    },
  })
  @Transform(({ value }) => (value === null ? undefined : value))
  @IsObject()
  @IsOptional()
  metadata?: Record<string, any>;
}


=== FILE 6/48: apps/api/src/orgo/core/cases/dto/update-case-status.dto.ts ===

import { ApiProperty } from '@nestjs/swagger';
import { IsIn, IsOptional, IsString, MaxLength } from 'class-validator';

export const CASE_STATUS_VALUES = [
  'open',
  'in_progress',
  'resolved',
  'archived',
] as const;

export type CaseStatus = (typeof CASE_STATUS_VALUES)[number];

export class UpdateCaseStatusDto {
  @ApiProperty({
    description: 'New status for the Case.',
    enum: CASE_STATUS_VALUES,
    example: 'resolved',
  })
  @IsString()
  @IsIn(CASE_STATUS_VALUES, {
    message: `status must be one of: ${CASE_STATUS_VALUES.join(', ')}`,
  })
  status!: CaseStatus;

  @ApiProperty({
    description:
      'Optional human-readable reason explaining why the status is changing. ' +
      'For example, reasons for archiving as out-of-scope, duplicate, or spam.',
    required: false,
    maxLength: 2000,
  })
  @IsOptional()
  @IsString()
  @MaxLength(2000)
  reason?: string;
}


=== FILE 7/48: apps/api/src/orgo/core/database/database.service.ts ===

import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { PrismaClient } from '@prisma/client';
import { PrismaService } from '../../../persistence/prisma/prisma.service';

export type DatabaseMode = 'ONLINE' | 'OFFLINE';

export type OrgoErrorCode =
  | 'DB_CONFIG_ERROR'
  | 'DB_UNKNOWN_TABLE'
  | 'DB_QUERY_FAILED'
  | 'UNSUPPORTED_DB_MODE';

export interface OrgoError {
  code: OrgoErrorCode;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Standard Orgo result shape (Doc 5 §2.4).
 * ok: true  -> data is set, error is null
 * ok: false -> data is null, error is set
 *
 * Implemented as a discriminated union so TypeScript can narrow correctly.
 */
export interface OrgoSuccess<T> {
  ok: true;
  data: T;
  error: null;
}

export interface OrgoFailure {
  ok: false;
  data: null;
  error: OrgoError;
}

export type OrgoResult<T> = OrgoSuccess<T> | OrgoFailure;

/**
 * Core Database Service for Orgo v3.
 *
 * Responsibilities (Doc 4 & Doc 5):
 * - Provide a single, central entry point to the Prisma client:
 *     DatabaseService.getPrismaClient()
 * - Implement logical persistence helpers:
 *     connectToDatabase, fetchRecords, insertRecord, updateRecord
 * - Align with the standard Orgo result shape for all operations.
 *
 * Notes:
 * - ONLINE mode uses Postgres via Prisma and DATABASE_URL (validated by ConfigModule).
 * - OFFLINE mode (SQLite) is not implemented in this starter and returns UNSUPPORTED_DB_MODE.
 */
@Injectable()
export class DatabaseService {
  private readonly logger = new Logger(DatabaseService.name);

  /**
   * Underlying Prisma client.
   * PrismaService is already configured to connect using DATABASE_URL and
   * calls $connect() in its own onModuleInit hook.
   */
  private readonly prisma: PrismaService;

  /**
   * Cached database URL, primarily for diagnostics and downstream utilities.
   */
  private readonly databaseUrl: string;

  private hasConnected = false;

  constructor(
    prismaService: PrismaService,
    private readonly configService: ConfigService,
  ) {
    this.prisma = prismaService;

    // DATABASE_URL is validated at startup by ConfigModule (environment-variables.ts),
    // but we defensively re-check here for clarity.
    const url = this.configService.get<string>('DATABASE_URL');
    if (!url) {
      this.logger.error(
        'DATABASE_URL is not set. Check your environment (.env) configuration.',
      );
      // In bootstrap, a hard failure here is acceptable; downstream OrgoResult
      // codes (DB_CONFIG_ERROR) are used for runtime connection issues.
      throw new Error('DATABASE_URL is required but was not provided.');
    }

    this.databaseUrl = url;
  }

  /**
   * Canonical entry point for anything that needs direct Prisma access.
   *
   * Functional inventory reference:
   *   Core Services / Database Ops → DatabaseService.getPrismaClient
   *   (Doc 4 – Functional Code‑Name Inventory)
   */
  getPrismaClient(): PrismaClient {
    return this.prisma;
  }

  /**
   * Returns the DATABASE_URL used by Prisma, for diagnostics / health checks.
   */
  getDatabaseUrl(): string {
    return this.databaseUrl;
  }

  /**
   * Connect to the database in the requested mode.
   *
   * Logical contract from Doc 5 §8.3 (connect_to_database).
   *
   * In this starter:
   * - Only ONLINE (Postgres via Prisma) is supported.
   * - OFFLINE (SQLite) is not implemented yet and returns UNSUPPORTED_DB_MODE.
   */
  async connectToDatabase(
    mode: DatabaseMode = 'ONLINE',
  ): Promise<OrgoResult<PrismaClient>> {
    if (mode === 'OFFLINE') {
      this.logger.error(
        "Database mode 'OFFLINE' requested, but offline/SQLite support is not implemented in this build.",
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'UNSUPPORTED_DB_MODE',
          message:
            "Database mode 'OFFLINE' is not supported in this deployment.",
          details: { mode },
        },
      };
    }

    try {
      if (!this.hasConnected) {
        await this.prisma.$connect();
        this.hasConnected = true;
        this.logger.log(
          'Successfully connected to the primary database (ONLINE).',
        );
      }

      return {
        ok: true,
        data: this.prisma,
        error: null,
      };
    } catch (err) {
      const error = err as Error;

      this.logger.error(
        `Failed to connect to database in mode '${mode}': ${error.message}`,
        error.stack,
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'DB_CONFIG_ERROR',
          message: 'Failed to connect to the database.',
          details: {
            mode,
            error: error.message,
          },
        },
      };
    }
  }

  /**
   * Fetch records from a logical table / Prisma model.
   *
   * Logical contract from Doc 5 §8.3 (fetch_records).
   *
   * This uses Prisma delegates dynamically:
   *   const delegate = (prisma as any)[table];
   *   delegate.findMany({ where })
   *
   * @param table Prisma model name (e.g. "user", "tasks", "cases").
   * @param where Optional filter object (Prisma "where" clause).
   * @param mode  ONLINE / OFFLINE (ONLINE only in this build).
   */
  async fetchRecords<T = unknown>(
    table: string,
    where?: Record<string, unknown>,
    mode: DatabaseMode = 'ONLINE',
  ): Promise<OrgoResult<T[]>> {
    const connection = await this.connectToDatabase(mode);
    if (!connection.ok) {
      return {
        ok: false,
        data: null,
        error: connection.error,
      };
    }

    const prisma = connection.data;

    try {
      const delegate = (prisma as any)[table];
      if (!delegate || typeof delegate.findMany !== 'function') {
        return {
          ok: false,
          data: null,
          error: {
            code: 'DB_UNKNOWN_TABLE',
            message: `Prisma model '${table}' does not exist on the Prisma client.`,
            details: { table },
          },
        };
      }

      const rows = await delegate.findMany({
        // Prisma treats undefined as "not provided"; passing an empty object is also fine.
        where: where ?? {},
      });

      return {
        ok: true,
        data: rows as T[],
        error: null,
      };
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Failed to fetch records from table '${table}': ${error.message}`,
        error.stack,
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'DB_QUERY_FAILED',
          message: 'Failed to fetch records from the database.',
          details: {
            table,
            where,
            error: error.message,
          },
        },
      };
    }
  }

  /**
   * Insert a record into a logical table / Prisma model.
   *
   * Logical contract from Doc 5 §8.3 (insert_record).
   *
   * @param table Prisma model name.
   * @param data  Data object matching the Prisma model "create" input.
   * @param mode  ONLINE / OFFLINE (ONLINE only in this build).
   */
  async insertRecord<T = unknown>(
    table: string,
    data: Record<string, unknown>,
    mode: DatabaseMode = 'ONLINE',
  ): Promise<OrgoResult<T>> {
    const connection = await this.connectToDatabase(mode);
    if (!connection.ok) {
      return {
        ok: false,
        data: null,
        error: connection.error,
      };
    }

    const prisma = connection.data;

    try {
      const delegate = (prisma as any)[table];
      if (!delegate || typeof delegate.create !== 'function') {
        return {
          ok: false,
          data: null,
          error: {
            code: 'DB_UNKNOWN_TABLE',
            message: `Prisma model '${table}' does not exist on the Prisma client.`,
            details: { table },
          },
        };
      }

      const created = await delegate.create({ data });

      return {
        ok: true,
        data: created as T,
        error: null,
      };
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Failed to insert record into table '${table}': ${error.message}`,
        error.stack,
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'DB_QUERY_FAILED',
          message: 'Failed to insert record into the database.',
          details: {
            table,
            data,
            error: error.message,
          },
        },
      };
    }
  }

  /**
   * Update a record in a logical table / Prisma model.
   *
   * Logical contract from Doc 5 §8.3 (update_record).
   *
   * @param table   Prisma model name.
   * @param key     Primary key / unique key filter (Prisma "where" clause).
   * @param updates Partial data to update (Prisma "data" clause).
   * @param mode    ONLINE / OFFLINE (ONLINE only in this build).
   */
  async updateRecord<T = unknown>(
    table: string,
    key: Record<string, unknown>,
    updates: Record<string, unknown>,
    mode: DatabaseMode = 'ONLINE',
  ): Promise<OrgoResult<T>> {
    const connection = await this.connectToDatabase(mode);
    if (!connection.ok) {
      return {
        ok: false,
        data: null,
        error: connection.error,
      };
    }

    const prisma = connection.data;

    try {
      const delegate = (prisma as any)[table];
      if (!delegate || typeof delegate.update !== 'function') {
        return {
          ok: false,
          data: null,
          error: {
            code: 'DB_UNKNOWN_TABLE',
            message: `Prisma model '${table}' does not exist on the Prisma client.`,
            details: { table },
          },
        };
      }

      const updated = await delegate.update({
        where: key,
        data: updates,
      });

      return {
        ok: true,
        data: updated as T,
        error: null,
      };
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Failed to update record in table '${table}': ${error.message}`,
        error.stack,
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'DB_QUERY_FAILED',
          message: 'Failed to update record in the database.',
          details: {
            table,
            key,
            updates,
            error: error.message,
          },
        },
      };
    }
  }
}


=== FILE 8/48: apps/api/src/orgo/core/database/repository-factory.service.ts ===

import { Injectable, Logger } from '@nestjs/common';
import { Prisma } from '@prisma/client';
import { PrismaService } from '../../../persistence/prisma/prisma.service';

export type OrgoEntity = Prisma.ModelName;

export interface OrgoRepository<TRecord = any> {
  /**
   * Generic passthrough to Prisma `<model>.findMany` with optional tenant enforcement.
   */
  findMany(args?: any, organizationIdOverride?: string): Promise<TRecord[]>;

  /**
   * Generic passthrough to Prisma `<model>.findFirst` with optional tenant enforcement.
   */
  findFirst(args?: any, organizationIdOverride?: string): Promise<TRecord | null>;

  /**
   * Generic passthrough to Prisma `<model>.findUnique` with optional tenant enforcement.
   */
  findUnique(args: any, organizationIdOverride?: string): Promise<TRecord | null>;

  /**
   * Convenience helper for the common `id` + `organization_id` pattern.
   */
  findById(
    id: string,
    options?: {
      organizationId?: string;
      select?: any;
      include?: any;
    },
  ): Promise<TRecord | null>;

  /**
   * Generic passthrough to Prisma `<model>.create` with tenant enforcement on `data.organization_id`.
   */
  create(args: any, organizationIdOverride?: string): Promise<TRecord>;

  /**
   * Generic passthrough to Prisma `<model>.createMany` with tenant enforcement on each item in `data`.
   */
  createMany(
    args: any,
    organizationIdOverride?: string,
  ): Promise<Prisma.BatchPayload>;

  /**
   * Generic passthrough to Prisma `<model>.update` with optional tenant enforcement on `where` + `data`.
   */
  update(args: any, organizationIdOverride?: string): Promise<TRecord>;

  /**
   * Generic passthrough to Prisma `<model>.updateMany` with optional tenant enforcement on `where` + `data`.
   */
  updateMany(
    args: any,
    organizationIdOverride?: string,
  ): Promise<Prisma.BatchPayload>;

  /**
   * Generic passthrough to Prisma `<model>.delete` with optional tenant enforcement on `where`.
   */
  delete(args: any, organizationIdOverride?: string): Promise<TRecord>;

  /**
   * Generic passthrough to Prisma `<model>.deleteMany` with optional tenant enforcement on `where`.
   */
  deleteMany(
    args: any,
    organizationIdOverride?: string,
  ): Promise<Prisma.BatchPayload>;
}

/**
 * RepositoryFactoryService
 *
 * Central factory for Orgo repositories. It wraps Prisma model delegates and:
 * - Provides a consistent `.getRepository(entity)` entry point.
 * - Enforces multi‑tenant scoping by injecting `organization_id` where requested.
 * - Adds simple helpers like `findById`.
 *
 * It is intentionally light on TypeScript generics so it can work across all
 * Orgo entities without needing to update this file when new Prisma models
 * are added.
 */
@Injectable()
export class RepositoryFactoryService {
  private readonly logger = new Logger(RepositoryFactoryService.name);

  constructor(private readonly prisma: PrismaService) {}

  /**
   * Returns a repository wrapper for the given Prisma model name.
   *
   * Example usage:
   *
   *   const tasksRepo = repositoryFactory.getRepository('Task', orgId);
   *   const tasks = await tasksRepo.findMany({ where: { status: 'PENDING' } });
   */
  getRepository<TRecord = any>(
    entity: OrgoEntity,
    organizationId?: string,
  ): OrgoRepository<TRecord> {
    const delegate = this.getDelegate(entity);
    const baseOrgId = organizationId;

    const applyOrgFilter = (where: any, orgOverride?: string) =>
      this.applyOrganizationFilter(where, orgOverride ?? baseOrgId);

    const applyOrgToCreateArgs = (args: any, orgOverride?: string) =>
      this.applyOrganizationToCreateArgs(args, orgOverride ?? baseOrgId);

    const applyOrgToUpdateArgs = (args: any, orgOverride?: string) =>
      this.applyOrganizationToUpdateArgs(args, orgOverride ?? baseOrgId);

    const repo: OrgoRepository<TRecord> = {
      findMany: async (args: any = {}, orgOverride?: string) => {
        const prismaArgs = { ...(args || {}) };
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.findMany(prismaArgs);
      },

      findFirst: async (args: any = {}, orgOverride?: string) => {
        const prismaArgs = { ...(args || {}) };
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.findFirst(prismaArgs);
      },

      findUnique: async (args: any, orgOverride?: string) => {
        const prismaArgs = { ...(args || {}) };
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.findUnique(prismaArgs);
      },

      findById: async (
        id: string,
        options?: { organizationId?: string; select?: any; include?: any },
      ) => {
        const targetOrgId = options?.organizationId ?? baseOrgId;
        const where = applyOrgFilter({ id }, targetOrgId);
        const prismaArgs: any = {
          where,
          ...(options?.select ? { select: options.select } : {}),
          ...(options?.include ? { include: options.include } : {}),
        };
        return delegate.findUnique(prismaArgs);
      },

      create: async (args: any, orgOverride?: string) => {
        const prismaArgs = applyOrgToCreateArgs(args || {}, orgOverride);
        return delegate.create(prismaArgs);
      },

      createMany: async (args: any, orgOverride?: string) => {
        const prismaArgs = applyOrgToCreateArgs(args || {}, orgOverride);
        return delegate.createMany(prismaArgs);
      },

      update: async (args: any, orgOverride?: string) => {
        const prismaArgs = applyOrgToUpdateArgs(args || {}, orgOverride);
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.update(prismaArgs);
      },

      updateMany: async (args: any, orgOverride?: string) => {
        const prismaArgs = applyOrgToUpdateArgs(args || {}, orgOverride);
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.updateMany(prismaArgs);
      },

      delete: async (args: any, orgOverride?: string) => {
        const prismaArgs = { ...(args || {}) };
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.delete(prismaArgs);
      },

      deleteMany: async (args: any, orgOverride?: string) => {
        const prismaArgs = { ...(args || {}) };
        prismaArgs.where = applyOrgFilter(prismaArgs.where, orgOverride);
        return delegate.deleteMany(prismaArgs);
      },
    };

    return repo;
  }

  /**
   * Resolves a Prisma model delegate (e.g. `prisma.task`, `prisma.case`) from
   * a Prisma model name (e.g. `"Task"`, `"Case"`).
   */
  private getDelegate(entity: OrgoEntity): any {
    const delegatePropertyName =
      entity.charAt(0).toLowerCase() + entity.slice(1);

    const delegate = (this.prisma as any)[delegatePropertyName];

    if (!delegate) {
      const message = `No Prisma delegate found for entity "${entity}" (expected property "${delegatePropertyName}" on PrismaService)`;
      this.logger.error(message);
      throw new Error(message);
    }

    return delegate;
  }

  /**
   * Injects `organization_id` into `where` clauses when an organizationId is
   * provided. If `organization_id` is already present with a different value,
   * it throws to prevent cross‑tenant leakage.
   */
  private applyOrganizationFilter(
    originalWhere: any | undefined,
    organizationId?: string,
  ): any | undefined {
    if (!organizationId) {
      return originalWhere;
    }

    if (originalWhere == null) {
      return { organization_id: organizationId };
    }

    if (typeof originalWhere !== 'object') {
      return originalWhere;
    }

    if ('organization_id' in originalWhere) {
      const existing = (originalWhere as any).organization_id;

      if (existing && existing !== organizationId) {
        const message =
          'Cross-tenant query prevented: where.organization_id does not match requested organizationId.';
        this.logger.error(message);
        throw new Error(message);
      }

      return { ...originalWhere, organization_id: existing ?? organizationId };
    }

    return { ...originalWhere, organization_id: organizationId };
  }

  /**
   * Injects `organization_id` into `create` payloads (including createMany)
   * when an organizationId is provided. If `organization_id` is already set
   * to a different value on any item, it throws.
   */
  private applyOrganizationToCreateArgs(
    args: any,
    organizationId?: string,
  ): any {
    if (!organizationId || !args || typeof args !== 'object') {
      return args;
    }

    if (!('data' in args)) {
      return args;
    }

    const originalData = (args as any).data;

    if (Array.isArray(originalData)) {
      const data = originalData.map((item) =>
        this.applyOrganizationToData(item, organizationId),
      );
      return { ...args, data };
    }

    const data = this.applyOrganizationToData(originalData, organizationId);
    return { ...args, data };
  }

  /**
   * Injects `organization_id` into `update` payloads where a row is org‑scoped.
   * This primarily ensures we don't accidentally move a record between tenants.
   */
  private applyOrganizationToUpdateArgs(
    args: any,
    organizationId?: string,
  ): any {
    if (!organizationId || !args || typeof args !== 'object') {
      return args;
    }

    if (!('data' in args)) {
      return args;
    }

    const originalData = (args as any).data;
    const data = this.applyOrganizationToData(originalData, organizationId);
    return { ...args, data };
  }

  /**
   * Helper to apply `organization_id` to a single data object.
   */
  private applyOrganizationToData(
    originalData: any,
    organizationId: string,
  ): any {
    if (!originalData || typeof originalData !== 'object') {
      return originalData;
    }

    if ('organization_id' in originalData) {
      const existing = (originalData as any).organization_id;

      if (existing && existing !== organizationId) {
        const message =
          'Cross-tenant write prevented: data.organization_id does not match requested organizationId.';
        this.logger.error(message);
        throw new Error(message);
      }

      return {
        ...originalData,
        organization_id: existing ?? organizationId,
      };
    }

    return {
      ...originalData,
      organization_id: organizationId,
    };
  }
}


=== FILE 9/48: apps/api/src/orgo/core/email/email-ingest.service.ts ===

import {
  Inject,
  Injectable,
  Logger,
  Optional,
} from '@nestjs/common';
import * as crypto from 'crypto';

import { PersistenceService } from '../persistence/persistence.service';
import { EmailParserService } from './email-parser.service';
import { EmailValidatorService } from './email-validator.service';
import { EmailRouterService } from './email-router.service';
import { LogService } from '../logging/log.service';

/**
 * Injection token for the low‑level mailbox client (IMAP/POP/etc.).
 * A concrete implementation should be registered against this token.
 */
export const EMAIL_MAILBOX_CLIENT = Symbol('EMAIL_MAILBOX_CLIENT');

/**
 * Injection token for attachment storage (e.g. S3, GCS, local FS).
 */
export const EMAIL_ATTACHMENT_STORAGE = Symbol('EMAIL_ATTACHMENT_STORAGE');

/**
 * Standard error shape used across Core Services.
 */
export interface StandardError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Standard result shape (`ok` / `data` / `error`) – locked for v3 Core Services.
 */
export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardError | null;
}

/**
 * Connection information for an IMAP/POP mailbox.
 * Concrete mailbox clients can extend this via intersection types if needed.
 */
export interface MailboxConnectionOptions {
  host: string;
  port: number;
  useSsl: boolean;
  username: string;
  password: string;
  folder: string;
}

/**
 * Raw email as returned by the mailbox client before parsing.
 */
export interface MailboxRawEmail {
  remoteId: string;
  raw: Buffer | string;
  receivedAt?: Date;
  sizeBytes?: number;
}

/**
 * Raw email with multi‑tenant context attached (org + config).
 * This is what we pass into the EmailParserService.
 */
export interface RawEmail extends MailboxRawEmail {
  organizationId: string;
  emailAccountConfigId: string;
}

/**
 * Canonical parsed email payload compatible with the `email_messages` /
 * `email_threads` tables and the EMAIL_MESSAGE logical view.
 */
export interface ParsedEmail {
  organizationId: string;
  emailAccountConfigId: string;

  externalThreadKey?: string | null;
  messageIdHeader?: string | null;
  direction: 'inbound' | 'outbound';

  fromAddress: string;
  toAddresses: string[];
  ccAddresses?: string[];
  bccAddresses?: string[];

  subject: string;
  receivedAt?: Date | null;
  sentAt?: Date | null;

  rawHeaders?: string | null;
  textBody?: string | null;
  htmlBody?: string | null;

  sensitivity?: 'normal' | 'sensitive' | 'highly_sensitive';

  attachments?: ParsedEmailAttachment[];
}

/**
 * Parsed attachment; the storage backend will receive `content` and return
 * a storage key that we store in `email_attachments`.
 */
export interface ParsedEmailAttachment {
  fileName: string;
  mimeType: string;
  sizeBytes: number;
  content: Buffer;
  checksum?: string;
}

/**
 * Low‑level mailbox client abstraction. A concrete implementation should hide
 * IMAP/POP details and return MailboxRawEmail objects.
 */
export interface MailboxClient {
  fetchUnreadMessages(
    connection: MailboxConnectionOptions,
    maxMessages: number,
  ): Promise<MailboxRawEmail[]>;

  /**
   * Optional hook to mark messages as processed on the remote server.
   * Implementations may no‑op if they rely on server‑side flags already.
   */
  markMessagesAsProcessed?(
    connection: MailboxConnectionOptions,
    remoteIds: string[],
  ): Promise<void>;
}

/**
 * Attachment storage abstraction; concrete implementations can use S3, GCS, etc.
 */
export interface EmailAttachmentStorage {
  saveAttachment(
    storageKey: string,
    content: Buffer,
    metadata: { mimeType: string; sizeBytes: number },
  ): Promise<void>;
}

/**
 * Allowed event types in `email_processing_events`.
 */
export type EmailProcessingEventType =
  | 'parsed'
  | 'classification_succeeded'
  | 'classification_failed'
  | 'task_created'
  | 'linked_to_existing_task'
  | 'dropped';

/**
 * Shape of an `email_account_configs` row as used by this service.
 * Field names match the DB schema.
 */
export interface EmailAccountConfigRecord {
  id: string;
  organization_id: string;
  label: string;
  imap_host: string;
  imap_port: number;
  imap_use_ssl: boolean;
  smtp_host: string;
  smtp_port: number;
  smtp_use_ssl: boolean;
  username: string;
  encrypted_password: string;
  polling_interval_seconds: number;
  last_successful_poll_at: Date | null;
  is_active: boolean;
}

/**
 * Per‑batch ingestion summary – mirrors what we track in `email_ingestion_batches`.
 */
export interface EmailIngestionBatchResult {
  batchId: string;
  emailAccountConfigId: string;
  organizationId: string;
  totalFetched: number;
  persistedMessages: number;
  failedMessages: number;
  status: 'completed' | 'failed';
  errorSummary?: string;
}

/**
 * Options for polling mailboxes.
 *
 * If `emailAccountConfigId` is provided, only that account is polled.
 * If `organizationId` is provided, all active accounts for that org are polled.
 * If neither is provided, all active accounts are polled (multi‑tenant).
 */
export interface PollMailboxOptions {
  organizationId?: string;
  emailAccountConfigId?: string;
  maxMessages?: number;
}

@Injectable()
export class EmailIngestService {
  private readonly logger = new Logger(EmailIngestService.name);

  constructor(
    private readonly persistence: PersistenceService,
    private readonly emailParser: EmailParserService,
    private readonly emailValidator: EmailValidatorService,
    private readonly emailRouter: EmailRouterService,
    private readonly logService: LogService,
    @Inject(EMAIL_MAILBOX_CLIENT)
    private readonly mailboxClient: MailboxClient,
    @Optional()
    @Inject(EMAIL_ATTACHMENT_STORAGE)
    private readonly attachmentStorage?: EmailAttachmentStorage,
  ) {}

  /**
   * Polls one or more mailboxes based on the provided options and ingests new
   * messages into `email_messages` / `email_attachments`, recording a row in
   * `email_ingestion_batches` for each polled account.
   */
  async pollMailbox(
    options: PollMailboxOptions = {},
  ): Promise<StandardResult<EmailIngestionBatchResult[]>> {
    const maxMessages = options.maxMessages ?? 50;

    try {
      const where: Record<string, unknown> = {
        is_active: true,
      };

      if (options.emailAccountConfigId) {
        where.id = options.emailAccountConfigId;
      }

      if (options.organizationId) {
        where.organization_id = options.organizationId;
      }

      const configsResult = await this.persistence.fetchRecords(
        'email_account_configs',
        where,
      );

      if (!configsResult.ok || !configsResult.data) {
        const error: StandardError = {
          code: 'EMAIL_INGEST_CONFIG_FETCH_FAILED',
          message: 'Failed to load email account configurations for polling',
          details: configsResult.error ?? undefined,
        };

        this.logService.logEvent({
          category: 'EMAIL',
          logLevel: 'ERROR',
          message: error.message,
          identifier: 'email_ingest:pollMailbox',
          metadata: { where, error },
        });

        return {
          ok: false,
          data: null,
          error,
        };
      }

      const configs = configsResult.data as EmailAccountConfigRecord[];

      if (!configs.length) {
        // Nothing to do – treat as success with an empty result set.
        return {
          ok: true,
          data: [],
          error: null,
        };
      }

      // Process accounts in parallel; each account is isolated at the mailbox
      // and DB level, so this is safe and lowers end‑to‑end latency.
      const batchResults = await Promise.all(
        configs.map((config) =>
          this.ingestForAccountConfig(config, maxMessages),
        ),
      );

      const anyFailed = batchResults.some(
        (result) => result.status === 'failed',
      );

      return {
        ok: !anyFailed,
        data: batchResults,
        error: anyFailed
          ? {
              code: 'EMAIL_INGEST_PARTIAL_FAILURE',
              message: 'One or more email ingestion batches failed',
              details: {
                failedBatchIds: batchResults
                  .filter((r) => r.status === 'failed')
                  .map((r) => r.batchId),
              },
            }
          : null,
      };
    } catch (err: unknown) {
      const error: StandardError = {
        code: 'EMAIL_INGEST_ERROR',
        message: 'Unhandled error while polling mailboxes',
        details: {
          error:
            err instanceof Error ? err.message : (err as string | unknown),
        },
      };

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: error.message,
        identifier: 'email_ingest:pollMailbox',
        metadata: error.details,
      });

      this.logger.error(
        `Unhandled error while polling mailboxes: ${
          err instanceof Error ? err.stack ?? err.message : String(err)
        }`,
      );

      return {
        ok: false,
        data: null,
        error,
      };
    }
  }

  /**
   * Ingests emails for a single `email_account_configs` record.
   * Creates an `email_ingestion_batches` row and updates it as messages
   * are processed.
   */
  private async ingestForAccountConfig(
    config: EmailAccountConfigRecord,
    maxMessages: number,
  ): Promise<EmailIngestionBatchResult> {
    const startedAt = new Date();

    const batchInsert = await this.persistence.insertRecord(
      'email_ingestion_batches',
      {
        email_account_config_id: config.id,
        started_at: startedAt,
        finished_at: null,
        message_count: 0,
        status: 'running',
        error_summary: null,
      },
    );

    const batchId =
      batchInsert.ok && batchInsert.data
        ? (batchInsert.data as { id: string }).id
        : undefined;

    if (!batchId) {
      const errorSummary = 'Failed to create email_ingestion_batches row';

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: errorSummary,
        identifier: `email_ingest:batch:${config.id}`,
        metadata: { configId: config.id, error: batchInsert.error },
      });

      return {
        batchId: 'unknown',
        emailAccountConfigId: config.id,
        organizationId: config.organization_id,
        totalFetched: 0,
        persistedMessages: 0,
        failedMessages: 0,
        status: 'failed',
        errorSummary,
      };
    }

    let totalFetched = 0;
    let persistedMessages = 0;
    let failedMessages = 0;
    const errors: string[] = [];

    const connection: MailboxConnectionOptions = {
      host: config.imap_host,
      port: config.imap_port,
      useSsl: config.imap_use_ssl,
      username: config.username,
      password: this.decryptPassword(config.encrypted_password),
      folder: 'INBOX',
    };

    try {
      const rawMessages = await this.mailboxClient.fetchUnreadMessages(
        connection,
        maxMessages,
      );

      totalFetched = rawMessages.length;

      for (const mail of rawMessages) {
        const rawEmail: RawEmail = {
          ...mail,
          organizationId: config.organization_id,
          emailAccountConfigId: config.id,
        };

        const success = await this.ingestSingleEmail(batchId, config, rawEmail);

        if (success) {
          persistedMessages += 1;
        } else {
          failedMessages += 1;
        }
      }

      // Mark messages as processed on the remote server, if supported.
      if (this.mailboxClient.markMessagesAsProcessed && rawMessages.length) {
        const remoteIds = rawMessages.map((m) => m.remoteId);
        try {
          await this.mailboxClient.markMessagesAsProcessed(
            connection,
            remoteIds,
          );
        } catch (err: unknown) {
          const message =
            'Failed to mark messages as processed on remote mailbox';
          errors.push(
            err instanceof Error ? err.message : String(err ?? 'unknown'),
          );

          this.logService.logEvent({
            category: 'EMAIL',
            logLevel: 'WARNING',
            message,
            identifier: `email_ingest:markProcessed:${batchId}`,
            metadata: { configId: config.id, error: errors[errors.length - 1] },
          });

          this.logger.warn(
            `${message}: ${
              err instanceof Error ? err.stack ?? err.message : String(err)
            }`,
          );
        }
      }

      const status: 'completed' | 'failed' =
        failedMessages > 0 && persistedMessages === 0 ? 'failed' : 'completed';
      const errorSummary =
        errors.length > 0 ? errors.join('; ').slice(0, 1024) : null;

      await this.persistence.updateRecord(
        'email_ingestion_batches',
        { id: batchId },
        {
          finished_at: new Date(),
          message_count: totalFetched,
          status,
          error_summary: errorSummary,
        },
      );

      if (status === 'completed') {
        await this.persistence.updateRecord(
          'email_account_configs',
          { id: config.id },
          {
            last_successful_poll_at: new Date(),
          },
        );
      }

      return {
        batchId,
        emailAccountConfigId: config.id,
        organizationId: config.organization_id,
        totalFetched,
        persistedMessages,
        failedMessages,
        status,
        errorSummary: errorSummary ?? undefined,
      };
    } catch (err: unknown) {
      const message =
        'Unhandled error while ingesting emails for account config';
      const errorText =
        err instanceof Error ? err.message : String(err ?? 'unknown');

      errors.push(errorText);

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message,
        identifier: `email_ingest:batch:${batchId}`,
        metadata: { configId: config.id, error: errorText },
      });

      this.logger.error(
        `${message} (config=${config.id}, batch=${batchId}): ${
          err instanceof Error ? err.stack ?? err.message : String(err)
        }`,
      );

      await this.persistence.updateRecord(
        'email_ingestion_batches',
        { id: batchId },
        {
          finished_at: new Date(),
          message_count: totalFetched,
          status: 'failed',
          error_summary: errors.join('; ').slice(0, 1024),
        },
      );

      return {
        batchId,
        emailAccountConfigId: config.id,
        organizationId: config.organization_id,
        totalFetched,
        persistedMessages,
        failedMessages,
        status: 'failed',
        errorSummary: errors.join('; ').slice(0, 1024),
      };
    }
  }

  /**
   * Ingests a single raw email: parse → validate → persist → route to workflow.
   * Returns `true` if the email was successfully persisted to `email_messages`,
   * regardless of downstream routing outcome.
   */
  private async ingestSingleEmail(
    batchId: string,
    config: EmailAccountConfigRecord,
    rawEmail: RawEmail,
  ): Promise<boolean> {
    try {
      const parseResult = await this.emailParser.parseIncoming(rawEmail);

      if (!parseResult || !parseResult.ok || !parseResult.data) {
        const message = 'Failed to parse incoming email';

        this.logService.logEvent({
          category: 'EMAIL',
          logLevel: 'ERROR',
          message,
          identifier: `email_ingest:parse:${batchId}`,
          metadata: {
            configId: config.id,
            remoteId: rawEmail.remoteId,
            error: parseResult?.error ?? null,
          },
        });

        this.logger.error(
          `${message} (config=${config.id}, remoteId=${rawEmail.remoteId})`,
        );

        return false;
      }

      const parsed = parseResult.data as ParsedEmail;

      const validateResult = await this.emailValidator.validateEmailPayload(
        parsed,
      );

      if (!validateResult || !validateResult.ok) {
        const message = 'Incoming email failed validation';

        this.logService.logEvent({
          category: 'EMAIL',
          logLevel: 'ERROR',
          message,
          identifier: `email_ingest:validate:${batchId}`,
          metadata: {
            configId: config.id,
            remoteId: rawEmail.remoteId,
            error: validateResult?.error ?? null,
          },
        });

        this.logger.error(
          `${message} (config=${config.id}, remoteId=${rawEmail.remoteId})`,
        );

        return false;
      }

      const { emailMessageId } = await this.persistParsedEmail(
        parsed,
        config.organization_id,
      );

      await this.createProcessingEvent(emailMessageId, 'parsed', {
        batchId,
        remoteId: rawEmail.remoteId,
      });

      // Route into workflows / tasks; failures here are logged and recorded as
      // classification failures but do not retroactively delete the message.
      try {
        await this.emailRouter.routeToWorkflow({
          emailMessageId,
          organizationId: config.organization_id,
          emailAccountConfigId: config.id,
        });

        await this.createProcessingEvent(
          emailMessageId,
          'classification_succeeded',
          {
            batchId,
            remoteId: rawEmail.remoteId,
          },
        );
      } catch (err: unknown) {
        const errorText =
          err instanceof Error ? err.message : String(err ?? 'unknown');

        await this.createProcessingEvent(
          emailMessageId,
          'classification_failed',
          {
            batchId,
            remoteId: rawEmail.remoteId,
            error: errorText,
          },
        );

        this.logService.logEvent({
          category: 'EMAIL',
          logLevel: 'ERROR',
          message:
            'Failed to route ingested email into workflow (classification_failed)',
          identifier: `email_ingest:route:${batchId}`,
          metadata: {
            configId: config.id,
            emailMessageId,
            error: errorText,
          },
        });

        this.logger.error(
          `Failed to route ingested email into workflow (emailMessageId=${emailMessageId}): ${
            err instanceof Error ? err.stack ?? err.message : String(err)
          }`,
        );
      }

      return true;
    } catch (err: unknown) {
      const message = 'Unhandled error while ingesting single email';
      const errorText =
        err instanceof Error ? err.message : String(err ?? 'unknown');

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message,
        identifier: `email_ingest:single:${batchId}`,
        metadata: {
          configId: config.id,
          remoteId: rawEmail.remoteId,
          error: errorText,
        },
      });

      this.logger.error(
        `${message} (config=${config.id}, remoteId=${rawEmail.remoteId}): ${
          err instanceof Error ? err.stack ?? err.message : String(err)
        }`,
      );

      return false;
    }
  }

  /**
   * Persists a parsed email into `email_threads`, `email_messages`, and
   * `email_attachments`. Returns the new `email_message_id`.
   */
  private async persistParsedEmail(
    parsed: ParsedEmail,
    organizationId: string,
  ): Promise<{ emailMessageId: string }> {
    const messageTimestamp =
      parsed.receivedAt ?? parsed.sentAt ?? new Date();

    const externalThreadKey =
      parsed.externalThreadKey ??
      parsed.messageIdHeader ??
      this.buildSyntheticThreadKey(parsed);

    // Find or create the email_thread for this conversation.
    let threadId: string | null = null;

    if (externalThreadKey) {
      const existingThreadsResult = await this.persistence.fetchRecords(
        'email_threads',
        {
          organization_id: organizationId,
          external_thread_key: externalThreadKey,
        },
      );

      const existingThreads =
        (existingThreadsResult.ok && existingThreadsResult.data) || [];

      if (existingThreads.length > 0) {
        const existing = existingThreads[0] as { id: string };

        threadId = existing.id;

        // Update last_message_at on the existing thread.
        await this.persistence.updateRecord(
          'email_threads',
          { id: threadId },
          {
            last_message_at: messageTimestamp,
            subject_snapshot: parsed.subject,
          },
        );
      } else {
        const createdThread = await this.persistence.insertRecord(
          'email_threads',
          {
            organization_id: organizationId,
            external_thread_key: externalThreadKey,
            subject_snapshot: parsed.subject,
            primary_task_id: null,
            last_message_at: messageTimestamp,
          },
        );

        if (createdThread.ok && createdThread.data) {
          threadId = (createdThread.data as { id: string }).id;
        }
      }
    }

    const messageInsert = await this.persistence.insertRecord(
      'email_messages',
      {
        organization_id: organizationId,
        email_account_config_id: parsed.emailAccountConfigId,
        thread_id: threadId,
        message_id_header: parsed.messageIdHeader ?? null,
        direction: parsed.direction,
        from_address: parsed.fromAddress,
        to_addresses: parsed.toAddresses,
        cc_addresses: parsed.ccAddresses ?? null,
        bcc_addresses: parsed.bccAddresses ?? null,
        subject: parsed.subject,
        received_at: parsed.receivedAt ?? null,
        sent_at: parsed.sentAt ?? null,
        raw_headers: parsed.rawHeaders ?? null,
        text_body: parsed.textBody ?? null,
        html_body: parsed.htmlBody ?? null,
        related_task_id: null,
        sensitivity: parsed.sensitivity ?? 'normal',
      },
    );

    if (!messageInsert.ok || !messageInsert.data) {
      throw new Error('Failed to insert email_messages row');
    }

    const emailMessage = messageInsert.data as { id: string };
    const emailMessageId = emailMessage.id;

    // Persist attachments if we have a storage backend and any attachments.
    if (parsed.attachments && parsed.attachments.length > 0) {
      await this.persistAttachments(emailMessageId, parsed.attachments);
    }

    return { emailMessageId };
  }

  /**
   * Persists `email_attachments` rows and optionally writes attachment content
   * to the configured storage backend (S3/GCS/local).
   */
  private async persistAttachments(
    emailMessageId: string,
    attachments: ParsedEmailAttachment[],
  ): Promise<void> {
    if (!attachments.length) {
      return;
    }

    if (!this.attachmentStorage) {
      // If we have no storage backend, we log a warning and skip attachments.
      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'WARNING',
        message:
          'Skipping attachment persistence because no attachment storage backend is configured',
        identifier: `email_ingest:attachments:${emailMessageId}`,
        metadata: { attachmentsCount: attachments.length },
      });
      return;
    }

    let index = 0;

    for (const attachment of attachments) {
      index += 1;

      const storageKey = this.buildAttachmentStorageKey(
        emailMessageId,
        index,
        attachment.fileName,
      );
      const checksum =
        attachment.checksum ?? this.computeChecksum(attachment.content);

      await this.attachmentStorage.saveAttachment(
        storageKey,
        attachment.content,
        {
          mimeType: attachment.mimeType,
          sizeBytes: attachment.sizeBytes,
        },
      );

      await this.persistence.insertRecord('email_attachments', {
        email_message_id: emailMessageId,
        file_name: attachment.fileName,
        mime_type: attachment.mimeType,
        size_bytes: attachment.sizeBytes,
        storage_key: storageKey,
        checksum,
      });
    }
  }

  /**
   * Writes an `email_processing_events` row for the given message.
   * Failures here are logged but do not fail the caller.
   */
  private async createProcessingEvent(
    emailMessageId: string,
    eventType: EmailProcessingEventType,
    details: Record<string, unknown>,
  ): Promise<void> {
    try {
      await this.persistence.insertRecord('email_processing_events', {
        email_message_id: emailMessageId,
        event_type: eventType,
        details,
        created_at: new Date(),
      });
    } catch (err: unknown) {
      const errorText =
        err instanceof Error ? err.message : String(err ?? 'unknown');

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: 'Failed to record email_processing_event',
        identifier: `email_ingest:event:${emailMessageId}`,
        metadata: {
          emailMessageId,
          eventType,
          error: errorText,
        },
      });

      this.logger.error(
        `Failed to record email_processing_event (emailMessageId=${emailMessageId}, eventType=${eventType}): ${
          err instanceof Error ? err.stack ?? err.message : String(err)
        }`,
      );
    }
  }

  /**
   * Placeholder decryptor for `email_account_configs.encrypted_password`.
   * In production, this should delegate to a KMS/secret manager and never
   * expose plaintext secrets in logs.
   */
  private decryptPassword(encrypted: string): string {
    // TODO: Replace with real decryption using KMS/secret management.
    return encrypted;
  }

  /**
   * Builds a synthetic thread key when no provider‑native thread identifier
   * is available. This is best‑effort and primarily used for grouping
   * messages that share the same subject and sender.
   */
  private buildSyntheticThreadKey(parsed: ParsedEmail): string {
    const subject = parsed.subject?.trim().toLowerCase() ?? '';
    const from = parsed.fromAddress?.trim().toLowerCase() ?? '';
    const hash = crypto
      .createHash('sha256')
      .update(`${from}::${subject}`)
      .digest('hex')
      .slice(0, 16);

    return `synthetic:${hash}`;
  }

  /**
   * Builds an attachment storage key under a simple, deterministic path.
   */
  private buildAttachmentStorageKey(
    emailMessageId: string,
    index: number,
    fileName: string,
  ): string {
    const safeName = fileName.replace(/[^a-zA-Z0-9._-]/g, '_');
    return `email/${emailMessageId}/${index}-${safeName}`;
  }

  /**
   * Computes a SHA‑256 checksum for attachment content.
   */
  private computeChecksum(buffer: Buffer): string {
    return crypto.createHash('sha256').update(buffer).digest('hex');
  }
}


=== FILE 10/48: apps/api/src/orgo/core/email/email-parser.service.ts ===

import { Injectable, Logger } from '@nestjs/common';
import { randomUUID } from 'crypto';

/**
 * Direction of the email relative to Orgo.
 * Maps to email_direction_enum ('inbound' | 'outbound').
 */
export type EmailDirection = 'inbound' | 'outbound';

/**
 * Sensitivity classification for email_message.sensitivity.
 */
export type EmailSensitivity = 'normal' | 'sensitive' | 'highly_sensitive';

/**
 * Generic address shape from common IMAP/SMTP/mailparser libraries.
 */
export interface RawEmailAddressLike {
  address: string;
  name?: string | null;
}

export type RawEmailAddressInput =
  | string
  | RawEmailAddressLike
  | Array<string | RawEmailAddressLike>;

/**
 * Raw email payload as handed off by the Email Gateway / IMAP client.
 * This is intentionally generic and library‑agnostic.
 */
export interface RawEmailPayload {
  subject?: string | null;
  from?: RawEmailAddressInput | null;
  to?: RawEmailAddressInput | null;
  cc?: RawEmailAddressInput | null;
  bcc?: RawEmailAddressInput | null;

  text?: string | null;
  html?: string | null;

  headers?: Record<string, string | string[] | undefined>;
  messageId?: string | null;

  /**
   * Optional size in bytes reported by the mail server/client.
   * If not present, the parser will estimate the size.
   */
  sizeInBytes?: number | null;

  /**
   * Attachments as emitted by the mail client / library.
   * Only metadata fields used by Orgo are required here.
   */
  attachments?: RawEmailAttachment[];

  /**
   * When the message was received by the mailbox (inbound).
   */
  receivedAt?: Date | string | null;

  /**
   * When the message was sent (outbound).
   */
  sentAt?: Date | string | null;

  /**
   * Direction hint; if omitted, parser defaults to 'inbound'.
   */
  direction?: EmailDirection;
}

/**
 * Raw attachment payload from the mail client.
 * This is intentionally minimal and may be extended later.
 */
export interface RawEmailAttachment {
  filename?: string | null;
  contentType?: string | null;
  mimeType?: string | null; // some libraries use mimeType instead of contentType
  size?: number | null; // bytes, if available
  contentId?: string | null;
  cid?: string | null; // alias for contentId
  inline?: boolean | null;
}

/**
 * Normalised attachment metadata stored alongside EMAIL_MESSAGE.
 * Aligns with the logical EMAIL_MESSAGE schema (Doc 5 §3.2). :contentReference[oaicite:0]{index=0}
 */
export interface EmailAttachmentMeta {
  filename: string | null;
  contentType: string | null;
  sizeBytes: number;
  inline: boolean;
  contentId: string | null;
  /**
   * True if the attachment's MIME type is in the allowed list
   * configured for the deployment (email_config.yaml limits). :contentReference[oaicite:1]{index=1}
   */
  allowed: boolean;
}

/**
 * Logical EMAIL_MESSAGE envelope as produced by the parser.
 * Maps 1:1 to the EMAIL_MESSAGE logical view in Doc 5 §3.2. :contentReference[oaicite:2]{index=2}
 */
export interface EmailMessageEnvelope {
  emailMessageId: string;
  organizationId: string;
  emailAccountConfigId: string | null;
  threadId: string | null;

  messageIdHeader: string | null;

  direction: EmailDirection;

  fromAddress: string;
  toAddresses: string[];
  ccAddresses: string[];
  bccAddresses: string[];

  subject: string;
  receivedAt: Date | null;
  sentAt: Date | null;

  rawHeaders: Record<string, string | string[]>;
  textBody: string | null;
  htmlBody: string | null;

  relatedTaskId: string | null;
  sensitivity: EmailSensitivity;

  parsedMetadata: Record<string, unknown>;
  attachmentsMeta: EmailAttachmentMeta[];
  securityFlags: Record<string, unknown>;
}

/**
 * Context supplied by the Email Gateway when parsing a message.
 * Orgo‑specific fields (organization_id, linkage, config ids). 
 */
export interface EmailParserContext {
  organizationId: string;
  emailAccountConfigId?: string | null;
  threadId?: string | null;
  relatedTaskId?: string | null;
  direction?: EmailDirection;
  /**
   * Optional override for sensitivity; if omitted, parser will derive
   * a conservative default based on headers/content.
   */
  sensitivityOverride?: EmailSensitivity;
}

/**
 * Limits and policy flags taken (eventually) from email_config.yaml. :contentReference[oaicite:4]{index=4}
 */
export interface EmailParserLimits {
  /**
   * Maximum email size (in bytes). Defaults to 10 MB if not provided.
   */
  maxEmailSizeBytes?: number;
  /**
   * Allowed MIME types for attachments; if empty/omitted, all attachment
   * types are accepted and simply marked as allowed=true.
   */
  allowedAttachmentMimeTypes?: string[];
  /**
   * If true (default), disallow emails that exceed the size limit.
   */
  enforceSizeLimit?: boolean;
}

/**
 * Standard result shape for Core Services (ok / data / error). :contentReference[oaicite:5]{index=5}
 */
export interface EmailParserResult<T> {
  ok: boolean;
  data: T | null;
  error: {
    code: EmailParserErrorCode;
    message: string;
    details?: Record<string, unknown>;
  } | null;
}

export type EmailParserErrorCode =
  | 'EMAIL_PARSING_ERROR'
  | 'EMAIL_VALIDATION_ERROR'
  | 'EMAIL_TOO_LARGE'
  | 'EMAIL_ATTACHMENT_TYPE_NOT_ALLOWED';

const DEFAULT_MAX_EMAIL_SIZE_BYTES = 10 * 1024 * 1024; // 10 MB, matches email_config.yaml default. :contentReference[oaicite:6]{index=6}

@Injectable()
export class EmailParserService {
  private readonly logger = new Logger(EmailParserService.name);

  /**
   * Parse and normalise a raw email payload into an EmailMessageEnvelope.
   *
   * This method:
   *  - normalises addresses (from/to/cc/bcc),
   *  - parses / sanitises text & HTML bodies,
   *  - computes size and enforces max size limits (if configured),
   *  - normalises attachments metadata and flags disallowed MIME types,
   *  - extracts selected headers into parsedMetadata/securityFlags,
   *  - returns the standard Core Services result shape.
   */
  parseIncoming(
    raw: RawEmailPayload,
    context: EmailParserContext,
    limits: EmailParserLimits = {},
  ): EmailParserResult<EmailMessageEnvelope> {
    try {
      const normalized = this.toEnvelope(raw, context, limits);

      const validationError = this.validateEnvelope(normalized, limits);
      if (validationError) {
        return {
          ok: false,
          data: null,
          error: validationError,
        };
      }

      return {
        ok: true,
        data: normalized,
        error: null,
      };
    } catch (err: unknown) {
      this.logger.error('Unexpected error while parsing email', err as Error);

      return {
        ok: false,
        data: null,
        error: {
          code: 'EMAIL_PARSING_ERROR',
          message:
            err instanceof Error ? err.message : 'Unexpected email parsing error',
        },
      };
    }
  }

  /**
   * Convert the raw payload and context into an EmailMessageEnvelope.
   * This method is pure and throws only on truly unexpected conditions;
   * policy validation is handled separately in validateEnvelope().
   */
  private toEnvelope(
    raw: RawEmailPayload,
    context: EmailParserContext,
    limits: EmailParserLimits,
  ): EmailMessageEnvelope {
    const direction: EmailDirection = context.direction ?? raw.direction ?? 'inbound';
    const rawHeaders = this.normaliseHeaders(raw.headers ?? {});
    const subject = (raw.subject ?? '').trim();

    const fromList = this.normaliseAddressList(raw.from);
    const fromAddress = fromList[0] ?? '';

    const toAddresses = this.normaliseAddressList(raw.to);
    const ccAddresses = this.normaliseAddressList(raw.cc);
    const bccAddresses = this.normaliseAddressList(raw.bcc);

    const { textBody, htmlBody } = this.normaliseBodies(raw.text, raw.html);

    const { attachmentsMeta, hadDisallowedAttachments } =
      this.normaliseAttachments(raw.attachments ?? [], limits);

    const estimatedSizeBytes = this.estimateEmailSize(
      raw,
      textBody,
      htmlBody,
      attachmentsMeta,
    );

    const messageIdHeader =
      raw.messageId ??
      (rawHeaders['message-id'] as string | undefined) ??
      null;

    const receivedAt = this.normaliseDate(raw.receivedAt);
    const sentAt = this.normaliseDate(raw.sentAt);

    const sensitivity =
      context.sensitivityOverride ??
      this.deriveSensitivity(subject, textBody, rawHeaders);

    const securityFlags = this.deriveSecurityFlags(rawHeaders);

    const parsedMetadata: Record<string, unknown> = {
      rawSizeBytes: raw.sizeInBytes ?? null,
      estimatedSizeBytes,
      hadDisallowedAttachments,
      attachmentCount: attachmentsMeta.length,
      hasHtmlBody: htmlBody !== null,
      hasTextBody: textBody !== null,
      messageIdHeader,
      direction,
    };

    return {
      emailMessageId: randomUUID(),
      organizationId: context.organizationId,
      emailAccountConfigId: context.emailAccountConfigId ?? null,
      threadId: context.threadId ?? null,
      messageIdHeader,
      direction,
      fromAddress,
      toAddresses,
      ccAddresses,
      bccAddresses,
      subject,
      receivedAt,
      sentAt,
      rawHeaders,
      textBody,
      htmlBody,
      relatedTaskId: context.relatedTaskId ?? null,
      sensitivity,
      parsedMetadata,
      attachmentsMeta,
      securityFlags,
    };
  }

  /**
   * Validate a normalised EmailMessageEnvelope against hard requirements
   * (required fields, size limit, attachment policy).
   */
  private validateEnvelope(
    envelope: EmailMessageEnvelope,
    limits: EmailParserLimits,
  ): EmailParserResult<EmailMessageEnvelope>['error'] {
    // Required fields: subject, from, at least one recipient, and some body.
    if (!envelope.subject) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: "Missing required field 'subject'",
        details: { field: 'subject' },
      };
    }

    if (!envelope.fromAddress) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: "Missing required field 'fromAddress'",
        details: { field: 'fromAddress' },
      };
    }

    if (
      envelope.toAddresses.length === 0 &&
      envelope.ccAddresses.length === 0 &&
      envelope.bccAddresses.length === 0
    ) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: 'Email must have at least one recipient',
        details: { field: 'to/cc/bcc' },
      };
    }

    if (!envelope.textBody && !envelope.htmlBody) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: 'Email must have a text or HTML body',
        details: { field: 'textBody/htmlBody' },
      };
    }

    // Size limit enforcement (if enabled).
    const enforceSizeLimit = limits.enforceSizeLimit ?? true;
    const maxBytes =
      typeof limits.maxEmailSizeBytes === 'number'
        ? limits.maxEmailSizeBytes
        : DEFAULT_MAX_EMAIL_SIZE_BYTES;

    if (enforceSizeLimit) {
      const estimatedSize = envelope.parsedMetadata.estimatedSizeBytes;
      if (typeof estimatedSize === 'number' && estimatedSize > maxBytes) {
        return {
          code: 'EMAIL_TOO_LARGE',
          message: `Email exceeds maximum size: ${estimatedSize} bytes > ${maxBytes} bytes`,
          details: { estimatedSizeBytes: estimatedSize, maxEmailSizeBytes: maxBytes },
        };
      }
    }

    // Attachment policy: if allowedAttachmentMimeTypes is non‑empty,
    // disallow attachments whose contentType is not in the list.
    const allowedTypes = limits.allowedAttachmentMimeTypes ?? [];
    if (allowedTypes.length > 0) {
      const hasForbidden = envelope.attachmentsMeta.some(
        (a) => a.contentType && !allowedTypes.includes(a.contentType),
      );

      if (hasForbidden) {
        return {
          code: 'EMAIL_ATTACHMENT_TYPE_NOT_ALLOWED',
          message: 'One or more attachments have disallowed MIME types',
          details: {
            allowedAttachmentMimeTypes: allowedTypes,
          },
        };
      }
    }

    return null;
  }

  // ---------------------------------------------------------------------------
  // Normalisation helpers
  // ---------------------------------------------------------------------------

  private normaliseHeaders(
    headers: Record<string, string | string[] | undefined>,
  ): Record<string, string | string[]> {
    const out: Record<string, string | string[]> = {};

    for (const [key, value] of Object.entries(headers)) {
      if (typeof value === 'undefined') {
        continue;
      }
      const canonicalKey = key.toLowerCase();
      out[canonicalKey] = value;
    }

    return out;
  }

  private normaliseAddressList(
    value?: RawEmailAddressInput | null,
  ): string[] {
    if (!value) {
      return [];
    }

    const items = Array.isArray(value) ? value : [value];
    const result: string[] = [];

    for (const item of items) {
      if (typeof item === 'string') {
        result.push(...this.extractEmailAddressesFromString(item));
      } else if (item && typeof item.address === 'string') {
        const parsed = this.extractEmailAddressesFromString(item.address);
        result.push(...parsed);
      }
    }

    return result.filter(Boolean);
  }

  private extractEmailAddressesFromString(raw: string): string[] {
    if (!raw) {
      return [];
    }

    // Handle comma‑separated lists like "A <a@example.org>, b@example.org"
    const parts = raw.split(',').map((p) => p.trim());
    const result: string[] = [];

    for (const part of parts) {
      if (!part) continue;

      const angleMatch = part.match(/<([^>]+)>/);
      if (angleMatch && angleMatch[1]) {
        result.push(angleMatch[1].trim());
      } else {
        result.push(part.trim());
      }
    }

    return result;
  }

  private normaliseBodies(
    text?: string | null,
    html?: string | null,
  ): { textBody: string | null; htmlBody: string | null } {
    const rawText = text?.trim() ?? '';
    const rawHtml = html?.trim() ?? '';

    let textBody: string | null = rawText || null;
    let htmlBody: string | null = rawHtml || null;

    if (!textBody && htmlBody) {
      textBody = this.extractPlainTextFromHtml(htmlBody) || null;
    }

    if (htmlBody) {
      htmlBody = this.sanitiseHtml(htmlBody);
    }

    return { textBody, htmlBody };
  }

  private extractPlainTextFromHtml(html: string): string {
    // Remove script/style blocks.
    let text = html.replace(
      /<(script|style)[^>]*>[\s\S]*?<\/\1>/gi,
      '',
    );
    // Strip tags.
    text = text.replace(/<[^>]+>/g, ' ');
    // Collapse whitespace.
    text = text.replace(/\s+/g, ' ').trim();
    return text;
  }

  private sanitiseHtml(html: string): string {
    let out = html;

    // Remove script/style tags completely.
    out = out.replace(/<(script|style)[^>]*>[\s\S]*?<\/\1>/gi, '');

    // Basic sanitisation for inline event handlers and javascript: URLs.
    out = out.replace(/\son[a-z]+\s*=\s*(['"]).*?\1/gi, '');
    out = out.replace(/javascript:/gi, '');

    return out;
  }

  private normaliseAttachments(
    rawAttachments: RawEmailAttachment[],
    limits: EmailParserLimits,
  ): { attachmentsMeta: EmailAttachmentMeta[]; hadDisallowedAttachments: boolean } {
    const allowedTypes = limits.allowedAttachmentMimeTypes ?? [];
    const attachmentsMeta: EmailAttachmentMeta[] = [];
    let hadDisallowed = false;

    for (const raw of rawAttachments) {
      const filename = raw.filename ?? null;
      const contentType = (raw.contentType ?? raw.mimeType ?? null)?.toLowerCase() ?? null;
      const sizeBytes = typeof raw.size === 'number' && raw.size > 0 ? raw.size : 0;
      const contentId = (raw.contentId ?? raw.cid ?? null) || null;
      const inline = Boolean(raw.inline);

      let allowed = true;
      if (allowedTypes.length > 0 && contentType) {
        allowed = allowedTypes.includes(contentType);
        if (!allowed) {
          hadDisallowed = true;
        }
      }

      attachmentsMeta.push({
        filename,
        contentType,
        sizeBytes,
        inline,
        contentId,
        allowed,
      });
    }

    return { attachmentsMeta, hadDisallowedAttachments: hadDisallowed };
  }

  private estimateEmailSize(
    raw: RawEmailPayload,
    textBody: string | null,
    htmlBody: string | null,
    attachments: EmailAttachmentMeta[],
  ): number {
    if (typeof raw.sizeInBytes === 'number' && raw.sizeInBytes > 0) {
      return raw.sizeInBytes;
    }

    let total = 0;

    const accumulate = (value: string | null | undefined) => {
      if (!value) return;
      // Approximate: 1 char ≈ 1 byte (good enough for limit checks).
      total += value.length;
    };

    accumulate(raw.subject ?? null);
    accumulate(textBody);
    accumulate(htmlBody);

    for (const attachment of attachments) {
      total += attachment.sizeBytes;
    }

    return total;
  }

  private normaliseDate(value?: Date | string | null): Date | null {
    if (!value) return null;
    if (value instanceof Date) return value;

    const parsed = new Date(value);
    if (Number.isNaN(parsed.getTime())) {
      return null;
    }
    return parsed;
  }

  private deriveSensitivity(
    subject: string,
    textBody: string | null,
    headers: Record<string, string | string[]>,
  ): EmailSensitivity {
    // Very conservative and generic heuristic:
    //  - if headers mark content as confidential, treat as 'sensitive'
    //  - otherwise, look for common sensitivity hints in subject/body.
    const classificationHeader =
      (headers['sensitivity'] as string | undefined) ??
      (headers['x-classification'] as string | undefined) ??
      '';

    const lcClassification = classificationHeader.toLowerCase();
    if (
      lcClassification.includes('confidential') ||
      lcClassification.includes('restricted')
    ) {
      return 'sensitive';
    }

    const text = `${subject} ${textBody ?? ''}`.toLowerCase();
    if (
      text.includes('confidential') ||
      text.includes('harassment') ||
      text.includes('medical') ||
      text.includes('patient') ||
      text.includes('complaint')
    ) {
      return 'sensitive';
    }

    return 'normal';
  }

  private deriveSecurityFlags(
    headers: Record<string, string | string[]>,
  ): Record<string, unknown> {
    const result: Record<string, unknown> = {};

    const contentType = (headers['content-type'] as string | undefined) ?? '';
    const lcContentType = contentType.toLowerCase();

    result.pgpEncrypted =
      lcContentType.includes('multipart/encrypted') ||
      lcContentType.includes('application/pgp-encrypted') ||
      this.headerContains(headers, 'x-pgp-encrypted', 'yes');

    result.spamScore = this.parseFloatHeader(headers, 'x-spam-score');
    result.spamStatus = (headers['x-spam-status'] as string | undefined) ?? null;

    return result;
  }

  private headerContains(
    headers: Record<string, string | string[]>,
    key: string,
    needle: string,
  ): boolean {
    const value = headers[key.toLowerCase()];
    if (!value) return false;

    if (Array.isArray(value)) {
      return value.some((v) => v.toLowerCase().includes(needle.toLowerCase()));
    }

    return value.toLowerCase().includes(needle.toLowerCase());
  }

  private parseFloatHeader(
    headers: Record<string, string | string[]>,
    key: string,
  ): number | null {
    const value = headers[key.toLowerCase()];
    if (!value) return null;

    const s = Array.isArray(value) ? value[0] : value;
    const n = parseFloat(s);
    return Number.isFinite(n) ? n : null;
  }
}


=== FILE 11/48: apps/api/src/orgo/core/email/email-router.service.ts ===

// apps/api/src/orgo/core/email/email-router.service.ts

import { Injectable, Logger } from '@nestjs/common';

import {
  WorkflowEngineService,
  WorkflowContext,
  WorkflowExecutionResultData,
  WorkflowEngineResult,
  ResolvedWorkflowAction,
  WorkflowAction,
} from '../workflow/workflow-engine.service';

import {
  TaskService,
  TaskDto,
  CreateTaskInput,
  TaskCategory,
  TaskPriority,
  TaskSeverity,
  TaskVisibility,
  TaskSource,
  AssignTaskInput,
  EscalateTaskInput,
} from '../tasks/task.service';

import {
  NotificationService,
  TaskNotificationEventType,
} from '../notifications/notification.service';

import { PersistenceService } from '../persistence/persistence.service';
import { LogService } from '../logging/log.service';
import { TaskEventsService } from '../tasks/task-events.service';
import { FN_EMAIL_ROUTE_TO_WORKFLOW } from '../functional-ids';

/**
 * Standard error / result envelopes (aligned with Docs 2, 4, 5).
 */
export interface OrgoError<TDetails = unknown> {
  code: string;
  message: string;
  details?: TDetails;
}

export interface OrgoResult<TData, TDetails = unknown> {
  ok: boolean;
  data: TData | null;
  error: OrgoError<TDetails> | null;
}

function ok<T>(data: T): OrgoResult<T> {
  return {
    ok: true,
    data,
    error: null,
  };
}

function err<TData = unknown, TDetails = unknown>(
  code: string,
  message: string,
  details?: TDetails,
): OrgoResult<TData, TDetails> {
  return {
    ok: false,
    data: null,
    error: {
      code,
      message,
      details,
    },
  };
}

/**
 * Event types for email_processing_events (Doc 1 / Doc 5).
 */
export type EmailProcessingEventType =
  | 'parsed'
  | 'classification_succeeded'
  | 'classification_failed'
  | 'task_created'
  | 'linked_to_existing_task'
  | 'dropped';

/**
 * Logical EMAIL_MESSAGE envelope used by the email gateway and workflows.
 * This mirrors the email_messages + email_threads logical view in Doc 5.
 */
export interface EmailMessageEnvelope {
  id: string;
  organization_id: string;
  email_account_config_id: string | null;
  thread_id: string | null;
  message_id_header: string | null;
  direction: 'inbound' | 'outbound';
  from_address: string;
  to_addresses: string[];
  cc_addresses: string[];
  bcc_addresses: string[];
  subject: string;
  received_at: Date | null;
  sent_at: Date | null;
  raw_headers: Record<string, unknown>;
  text_body: string | null;
  html_body: string | null;
  related_task_id: string | null;
  sensitivity: 'normal' | 'sensitive' | 'highly_sensitive';
  parsed_metadata: Record<string, unknown>;
  attachments_meta: Array<{
    attachment_id: string;
    filename: string;
    content_type: string;
    size_bytes: number;
    download_url: string | null;
    checksum: string | null;
  }>;
  security_flags: Record<string, unknown>;
}

/**
 * Options for routing an email into workflows.
 */
export interface EmailRoutingOptions {
  /**
   * If true, run workflow classification but do not create/route tasks
   * or persist any side effects besides logs.
   */
  dryRun?: boolean;

  /**
   * Optional overrides merged into the WorkflowContext before execution.
   * This is primarily intended for tests and advanced integrations.
   */
  contextOverrides?: Partial<WorkflowContext>;

  /**
   * Optional ingestion batch id so processing events can be correlated
   * with the original mailbox poll.
   */
  ingestionBatchId?: string | null;
}

interface ApplyActionsResult {
  createdTasks: TaskDto[];
  /**
   * The task that this email ended up linked to (either an existing
   * primary task on the thread or the first task created by workflow).
   */
  linkedTaskId: string | null;
  notificationsSent: number;
}

/**
 * Result payload for EmailRouterService.routeToWorkflow.
 *
 * Aligned with the shape used by SignalIngestService (Docs 2, 4, 5).
 */
export interface EmailRoutingResult {
  emailId: string;
  organizationId: string;
  /**
   * Full workflow execution details (matched rules + resolved actions).
   * May be null if the email was short-circuited to an existing task.
   */
  workflowExecution: WorkflowExecutionResultData | null;
  /**
   * Tasks created as a consequence of workflow actions.
   */
  createdTasks: TaskDto[];
  /**
   * The task ultimately associated with this email (if any).
   */
  linkedTaskId: string | null;
  /**
   * Number of notifications sent as a consequence of workflow actions.
   */
  notificationsSent: number;
}

/**
 * EmailRouterService
 *
 * Bridges parsed emails into the workflow engine and Tasks:
 *  - Builds a WorkflowContext from EMAIL_MESSAGE envelopes.
 *  - Executes workflow rules (including email_patterns / domain mappings).
 *  - Decides whether to create a new Task or link to an existing one.
 *  - Logs classification success/failure and processing events.
 *  - Applies ROUTE / ESCALATE / NOTIFY actions via TaskService / NotificationService.
 */
@Injectable()
export class EmailRouterService {
  private readonly logger = new Logger(EmailRouterService.name);

  constructor(
    private readonly workflowEngine: WorkflowEngineService,
    private readonly taskService: TaskService,
    private readonly notificationService: NotificationService,
    private readonly persistence: PersistenceService,
    private readonly logService: LogService,
    private readonly taskEvents: TaskEventsService,
  ) {}

  /**
   * Core entry point for routing a parsed email into workflows.
   *
   * Responsibilities (aligned with Docs 2, 4, 5 and 8):
   *  - Build a WorkflowContext from the EMAIL_MESSAGE envelope.
   *  - Execute workflow rules via WorkflowEngineService.
   *  - Decide whether to create a new Task or link to an existing one.
   *  - Record email_processing_events for classification + task outcomes.
   *  - Return a standard { ok, data, error } envelope.
   */
  async routeToWorkflow(
    email: EmailMessageEnvelope,
    options: EmailRoutingOptions = {},
  ): Promise<OrgoResult<EmailRoutingResult>> {
    const { dryRun = false, contextOverrides = {}, ingestionBatchId = null } =
      options;

    if (!email) {
      return err<EmailRoutingResult>(
        'EMAIL_ROUTING_INVALID_INPUT',
        'Email payload is required.',
        { stage: 'validate_input' },
      );
    }

    if (!email.organization_id) {
      return err<EmailRoutingResult>(
        'EMAIL_ROUTING_INVALID_INPUT',
        'Email.organization_id is required for routing.',
        {
          stage: 'validate_input',
          emailId: email.id,
        },
      );
    }

    // 1. If the email is already explicitly linked to a Task, short‑circuit.
    if (email.related_task_id) {
      await this.recordProcessingEvent(
        email,
        'linked_to_existing_task',
        {
          taskId: email.related_task_id,
          reason: 'email.related_task_id already set',
        },
        ingestionBatchId,
      );

      await this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'INFO',
        message:
          'Email already linked to existing task; skipping workflow execution.',
        identifier: FN_EMAIL_ROUTE_TO_WORKFLOW,
        metadata: {
          functionId: FN_EMAIL_ROUTE_TO_WORKFLOW,
          stage: 'prelinked_short_circuit',
          organizationId: email.organization_id,
          emailMessageId: email.id,
          taskId: email.related_task_id,
        },
      });

      return ok<EmailRoutingResult>({
        emailId: email.id,
        organizationId: email.organization_id,
        workflowExecution: null,
        createdTasks: [],
        linkedTaskId: email.related_task_id,
        notificationsSent: 0,
      });
    }

    // 2. Thread‑level linking: if this thread already has a primary task,
    //    attach the email to that task and avoid re‑classifying.
    const threadLinkedTaskId = await this.tryLinkToExistingTaskByThread(
      email,
      ingestionBatchId,
    );

    if (threadLinkedTaskId) {
      return ok<EmailRoutingResult>({
        emailId: email.id,
        organizationId: email.organization_id,
        workflowExecution: null,
        createdTasks: [],
        linkedTaskId: threadLinkedTaskId,
        notificationsSent: 0,
      });
    }

    // 3. Build workflow context from the email envelope.
    const workflowContext: WorkflowContext = {
      // WorkflowEngineService expects camelCase organizationId + WorkflowEventSource.
      organizationId: email.organization_id,
      source: 'EMAIL',
      type:
        (email.parsed_metadata?.['type'] as string | undefined) ?? 'generic',
      category:
        (email.parsed_metadata?.['category'] as TaskCategory | undefined) ??
        undefined,
      severity:
        (email.parsed_metadata?.['severity'] as
          | TaskSeverity
          | Lowercase<TaskSeverity>
          | undefined) ?? undefined,
      label: email.parsed_metadata?.['label'] as string | undefined,
      title: email.subject,
      description:
        (email.parsed_metadata?.['summary'] as string | undefined) ??
        email.text_body ??
        email.html_body ??
        '',
      emailSubject: email.subject,
      emailTextBody: email.text_body ?? undefined,
      metadata: {
        ...(email.parsed_metadata ?? {}),
        organizationId: email.organization_id,
        emailMessageId: email.id,
        emailThreadId: email.thread_id ?? null,
        emailDirection: email.direction,
        emailFromAddress: email.from_address,
        emailToAddresses: email.to_addresses,
        emailCcAddresses: email.cc_addresses,
        emailBccAddresses: email.bcc_addresses,
        emailAccountConfigId: email.email_account_config_id ?? null,
        sensitivity: email.sensitivity,
      },
      payload: {
        email,
      },
      ...contextOverrides,
    };

    let workflowResult: WorkflowEngineResult<WorkflowExecutionResultData>;

    try {
      workflowResult = await this.workflowEngine.executeWorkflow(
        workflowContext,
      );
    } catch (err: unknown) {
      const error: OrgoError = {
        code: 'EMAIL_WORKFLOW_EXECUTION_ERROR',
        message: 'Failed to execute workflow for email.',
        details: {
          organizationId: email.organization_id,
          emailId: email.id,
          error: err instanceof Error ? err.message : String(err),
        },
      };

      await this.recordProcessingEvent(
        email,
        'classification_failed',
        error.details as Record<string, unknown>,
        ingestionBatchId,
      );

      await this.logService.logEvent({
        category: 'WORKFLOW',
        logLevel: 'ERROR',
        message: error.message,
        identifier: FN_EMAIL_ROUTE_TO_WORKFLOW,
        metadata: {
          functionId: FN_EMAIL_ROUTE_TO_WORKFLOW,
          stage: 'workflow_execute_throw',
          organizationId: email.organization_id,
          emailMessageId: email.id,
          error: error.details,
        },
      });

      this.logger.error(
        `Workflow execution failed for email ${email.id} (org=${email.organization_id})`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );

      return {
        ok: false,
        data: null,
        error,
      };
    }

    if (!workflowResult.ok || !workflowResult.data) {
      const error: OrgoError = {
        code:
          workflowResult.error?.code ?? 'EMAIL_WORKFLOW_EXECUTION_FAILED',
        message:
          workflowResult.error?.message ??
          'Workflow execution failed for email.',
        details: {
          organizationId: email.organization_id,
          emailId: email.id,
          error: workflowResult.error?.details,
        },
      };

      await this.recordProcessingEvent(
        email,
        'classification_failed',
        error.details as Record<string, unknown>,
        ingestionBatchId,
      );

      await this.logService.logEvent({
        category: 'WORKFLOW',
        logLevel: 'ERROR',
        message: error.message,
        identifier: FN_EMAIL_ROUTE_TO_WORKFLOW,
        metadata: {
          functionId: FN_EMAIL_ROUTE_TO_WORKFLOW,
          stage: 'workflow_execute_result_error',
          organizationId: email.organization_id,
          emailMessageId: email.id,
          error: error.details,
        },
      });

      return {
        ok: false,
        data: null,
        error,
      };
    }

    const execution = workflowResult.data;

    await this.recordProcessingEvent(
      email,
      'classification_succeeded',
      {
        workflowId: execution.workflowId,
        matchedRuleIds: execution.matchedRules.map((r) => r.id),
        label: execution.context.label ?? null,
        type: execution.context.type ?? null,
        category: execution.context.category ?? null,
        severity: execution.context.severity ?? null,
      },
      ingestionBatchId,
    );

    await this.logService.logEvent({
      category: 'WORKFLOW',
      logLevel: 'INFO',
      message: 'Email classified via workflow engine.',
      identifier: FN_EMAIL_ROUTE_TO_WORKFLOW,
      metadata: {
        functionId: FN_EMAIL_ROUTE_TO_WORKFLOW,
        organizationId: email.organization_id,
        emailMessageId: email.id,
        workflowId: execution.workflowId,
        matchedRuleIds: execution.matchedRules.map((r) => r.id),
      },
    });

    if (dryRun) {
      return ok<EmailRoutingResult>({
        emailId: email.id,
        organizationId: email.organization_id,
        workflowExecution: execution,
        createdTasks: [],
        linkedTaskId: null,
        notificationsSent: 0,
      });
    }

    const applyResult = await this.applyActions(
      email,
      execution,
      ingestionBatchId,
    );

    if (!applyResult.ok || !applyResult.data) {
      return {
        ok: false,
        data: null,
        error:
          applyResult.error ?? {
            code: 'EMAIL_ROUTING_APPLY_FAILED',
            message:
              'Failed to apply workflow actions for email (no error payload).',
          },
      };
    }

    const { createdTasks, linkedTaskId, notificationsSent } =
      applyResult.data;

    if (createdTasks.length === 0 && !linkedTaskId) {
      await this.recordProcessingEvent(
        email,
        'dropped',
        {
          reason:
            'No actionable workflow actions (no tasks created or linked).',
          workflowId: execution.workflowId,
        },
        ingestionBatchId,
      );
    }

    return ok<EmailRoutingResult>({
      emailId: email.id,
      organizationId: email.organization_id,
      workflowExecution: execution,
      createdTasks,
      linkedTaskId,
      notificationsSent,
    });
  }

  /**
   * Apply resolved workflow actions for an email.
   *
   * Currently supports:
   *  - CREATE_TASK → TaskService.createTask + email/task linking.
   *  - ROUTE       → TaskService.assignTask.
   *  - ESCALATE    → TaskService.escalateTask.
   *  - NOTIFY      → NotificationService.sendTaskNotification.
   */
  private async applyActions(
    email: EmailMessageEnvelope,
    execution: WorkflowExecutionResultData,
    ingestionBatchId: string | null,
  ): Promise<OrgoResult<ApplyActionsResult>> {
    const createdTasks: TaskDto[] = [];
    let linkedTaskId: string | null = null;
    let notificationsSent = 0;

    for (const resolved of execution.actions) {
      const action = resolved.action as WorkflowAction;

      try {
        switch (action.type) {
          case 'CREATE_TASK': {
            const task = await this.handleCreateTaskAction(
              email,
              resolved,
              ingestionBatchId,
            );

            if (task) {
              createdTasks.push(task);
              if (!linkedTaskId) {
                linkedTaskId = task.taskId ?? null;
              }
            }
            break;
          }

          case 'ROUTE': {
            await this.handleRouteAction(email, action);
            break;
          }

          case 'ESCALATE': {
            await this.handleEscalateAction(email, action);
            break;
          }

          case 'NOTIFY': {
            const sent = await this.handleNotifyAction(email, action);
            notificationsSent += sent;
            break;
          }

          default: {
            this.logger.debug(
              `Ignoring unsupported workflow action type "${action.type}" for email ${email.id}`,
            );
          }
        }
      } catch (err) {
        this.logger.error(
          `Failed to apply action "${action.type}" for email ${email.id}`,
          err instanceof Error ? err.stack ?? err.message : String(err),
        );

        return err<ApplyActionsResult>(
          'EMAIL_ROUTING_APPLY_FAILED',
          'Failed to apply workflow action.',
          {
            emailId: email.id,
            actionType: action.type,
          },
        );
      }
    }

    return ok<ApplyActionsResult>({
      createdTasks,
      linkedTaskId,
      notificationsSent,
    });
  }

  /**
   * If the email belongs to a thread that already has a primary task,
   * link the email to that task and record a processing event.
   */
  private async tryLinkToExistingTaskByThread(
    email: EmailMessageEnvelope,
    ingestionBatchId: string | null,
  ): Promise<string | null> {
    if (!email.thread_id) {
      return null;
    }

    try {
      const threadResult = await this.persistence.fetchRecords<any>(
        'email_threads',
        {
          id: email.thread_id,
          organization_id: email.organization_id,
        },
      );

      if (!threadResult.ok || !threadResult.data || !threadResult.data[0]) {
        return null;
      }

      const thread = threadResult.data[0] as {
        id: string;
        primary_task_id: string | null;
      };

      if (!thread.primary_task_id) {
        return null;
      }

      const taskId = thread.primary_task_id;

      await this.linkEmailToExistingTask(
        email,
        taskId,
        ingestionBatchId,
        'thread_primary_task_id',
      );

      return taskId;
    } catch (err) {
      this.logger.error(
        `Failed to check thread-based linkage for email ${email.id}`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );
      // Best-effort only; do not block routing on thread lookup.
      return null;
    }
  }

  /**
   * Persist the relationship between an email and a task in email_messages /
   * email_threads tables. Best-effort: failures are logged but do not reject.
   */
  private async persistEmailTaskLink(
    email: EmailMessageEnvelope,
    taskId: string,
  ): Promise<void> {
    try {
      await this.persistence.updateRecord(
        'email_messages',
        { id: email.id },
        {
          related_task_id: taskId,
        },
      );
    } catch (err) {
      this.logger.error(
        `Failed to update email_messages.related_task_id for email ${email.id}`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );
    }

    if (!email.thread_id) {
      return;
    }

    try {
      const threadResult = await this.persistence.fetchRecords<any>(
        'email_threads',
        {
          id: email.thread_id,
          organization_id: email.organization_id,
        },
      );

      const thread =
        threadResult.ok && threadResult.data
          ? (threadResult.data[0] as {
              id: string;
              primary_task_id: string | null;
            } | null)
          : null;

      if (thread && !thread.primary_task_id) {
        await this.persistence.updateRecord(
          'email_threads',
          { id: email.thread_id },
          { primary_task_id: taskId },
        );
      }
    } catch (err) {
      this.logger.error(
        `Failed to update email_threads.primary_task_id for email ${email.id}`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );
    }
  }

  private async linkEmailToExistingTask(
    email: EmailMessageEnvelope,
    taskId: string,
    ingestionBatchId: string | null,
    reason: string,
  ): Promise<void> {
    await this.persistEmailTaskLink(email, taskId);

    await this.recordProcessingEvent(
      email,
      'linked_to_existing_task',
      {
        taskId,
        reason,
      },
      ingestionBatchId,
    );

    const eventResult = await this.taskEvents.recordEmailLinked({
      taskId,
      organizationId: email.organization_id,
      origin: 'email',
      emailMessageId: email.id,
    });

    if (!eventResult.ok) {
      this.logger.error(
        `Failed to record email_linked TaskEvent for email ${email.id} and task ${taskId}`,
        JSON.stringify(eventResult.error),
      );
    }
  }

  /**
   * Append a row to email_processing_events. Failures are logged but do not
   * block the main routing flow.
   */
  private async recordProcessingEvent(
    email: EmailMessageEnvelope,
    eventType: EmailProcessingEventType,
    details: Record<string, unknown> | null,
    ingestionBatchId: string | null,
  ): Promise<void> {
    try {
      await this.persistence.insertRecord('email_processing_events', {
        organization_id: email.organization_id,
        email_message_id: email.id,
        ingestion_batch_id: ingestionBatchId ?? null,
        event_type: eventType,
        details: details ?? null,
        occurred_at: new Date(),
        created_at: new Date(),
      });
    } catch (err) {
      this.logger.error(
        `Failed to record email_processing_event (${eventType}) for email ${email.id}`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );
    }
  }

  /**
   * Build the metadata object passed to TaskService.createTask, merging
   * existing email metadata with workflow/action-level context.
   */
  private buildTaskMetadataFromEmail(
    email: EmailMessageEnvelope,
    resolved: ResolvedWorkflowAction,
  ): Record<string, any> {
    const baseMetadata: Record<string, any> =
      email.parsed_metadata && typeof email.parsed_metadata === 'object'
        ? { ...email.parsed_metadata }
        : {};

    const workflowMeta: Record<string, any> = {
      workflowId: resolved.workflowId,
      ruleId: resolved.ruleId,
      actionId: resolved.id,
      actionType: resolved.action.type,
      origin: 'email_gateway',
    };

    const emailMeta: Record<string, any> = {
      organizationId: email.organization_id,
      emailMessageId: email.id,
      emailThreadId: email.thread_id ?? null,
      emailDirection: email.direction,
      emailFromAddress: email.from_address,
      emailToAddresses: email.to_addresses,
      emailCcAddresses: email.cc_addresses,
      emailBccAddresses: email.bcc_addresses,
      messageIdHeader: email.message_id_header,
      receivedAt: email.received_at ?? null,
      sentAt: email.sent_at ?? null,
      sensitivity: email.sensitivity,
    };

    return {
      ...baseMetadata,
      workflow: {
        ...(baseMetadata.workflow ?? {}),
        ...workflowMeta,
      },
      email: {
        ...(baseMetadata.email ?? {}),
        ...emailMeta,
      },
    };
  }

  /**
   * Apply a single CREATE_TASK workflow action by building a CreateTaskInput
   * from the email plus action.set overrides, then delegating to TaskService.
   */
  private async handleCreateTaskAction(
    email: EmailMessageEnvelope,
    resolved: ResolvedWorkflowAction,
    ingestionBatchId: string | null,
  ): Promise<TaskDto | null> {
    const action = resolved.action;
    const set = (action.set ?? {}) as Record<string, unknown>;

    const mergeString = (
      override: unknown,
      base: string | undefined | null,
      fallback: string,
    ): string =>
      typeof override === 'string' && override.trim()
        ? override.trim()
        : base && base.trim()
        ? base.trim()
        : fallback;

    const mergeOptionalString = (
      override: unknown,
      base?: string | null,
    ): string | null =>
      typeof override === 'string' && override.trim()
        ? override.trim()
        : base && base.trim()
        ? base.trim()
        : null;

    const mergedCategory =
      (set.category as TaskCategory | undefined) ?? ('request' as TaskCategory);

    const mergedPriority =
      (set.priority as TaskPriority | Lowercase<TaskPriority> | undefined) ??
      ('MEDIUM' as TaskPriority);

    const mergedSeverity =
      (set.severity as TaskSeverity | Lowercase<TaskSeverity> | undefined) ??
      ('MINOR' as TaskSeverity);

    const mergedVisibility =
      (set.visibility as TaskVisibility | Lowercase<TaskVisibility> | undefined) ??
      ('INTERNAL' as TaskVisibility);

    const mergedSource =
      (set.source as TaskSource | string | undefined) ?? 'email';

    const mergedLabel = mergeString(
      set.label,
      email.parsed_metadata?.['label'] as string | undefined,
      '000.00.Unclassified',
    );

    const mergedDescription = mergeString(
      set.description,
      email.text_body ?? email.html_body,
      'Email routed via workflow.',
    );

    const createInput: CreateTaskInput = {
      organizationId: email.organization_id,
      type: mergeString(
        set.type,
        email.parsed_metadata?.['type'] as string | undefined,
        'generic',
      ),
      category: mergedCategory,
      title: mergeString(
        set.title,
        email.subject,
        email.subject || 'Email',
      ),
      description: mergedDescription,
      priority: mergedPriority,
      severity: mergedSeverity,
      visibility: mergedVisibility,
      label: mergedLabel,
      source: mergedSource as TaskSource,

      caseId:
        (set.caseId as string | undefined) ??
        (email.parsed_metadata?.['case_id'] as string | undefined) ??
        null,
      subtype:
        mergeOptionalString(
          set.subtype,
          email.parsed_metadata?.['subtype'] as string | undefined,
        ) ?? null,
      createdByUserId:
        (set.createdByUserId as string | undefined) ??
        (email.parsed_metadata?.['created_by_user_id'] as string | undefined) ??
        null,
      requesterPersonId:
        (set.requesterPersonId as string | undefined) ??
        (email.parsed_metadata?.['requester_person_id'] as string | undefined) ??
        null,
      ownerRoleId: (set.ownerRoleId as string | undefined) ?? null,
      ownerUserId: (set.ownerUserId as string | undefined) ?? null,
      assigneeRole:
        (set.assigneeRole as string | undefined) ??
        (action.to_role as string | undefined) ??
        null,
      dueAt: (set.dueAt as string | Date | undefined) ?? null,

      metadata: this.buildTaskMetadataFromEmail(email, resolved),

      reactivitySeconds:
        (set.reactivitySeconds as number | undefined) ?? null,
      reactivityTimeIso:
        (set.reactivityTimeIso as string | undefined) ?? null,
      reactivityDeadlineAt:
        (set.reactivityDeadlineAt as string | Date | undefined) ?? null,
    };

    try {
      const result = await this.taskService.createTask(createInput);

      if (!result.ok || !result.data) {
        this.logger.error(
          `TaskService.createTask returned error for email ${email.id}`,
          JSON.stringify(result.error),
        );

        return null;
      }

      const task = result.data;
      const taskId = task.taskId ?? (task as any).id;

      if (!taskId) {
        this.logger.warn(
          'TaskService.createTask succeeded but returned task without taskId / id; task will not be linked to email.',
        );
        return task;
      }

      await this.recordProcessingEvent(
        email,
        'task_created',
        {
          taskId,
          workflowId: resolved.workflowId,
          ruleId: resolved.ruleId,
          actionId: resolved.id,
          actionType: resolved.action.type,
        },
        ingestionBatchId,
      );

      await this.persistEmailTaskLink(email, taskId);

      const eventResult = await this.taskEvents.recordEmailLinked({
        taskId,
        organizationId: email.organization_id,
        origin: 'email',
        emailMessageId: email.id,
      });

      if (!eventResult.ok) {
        this.logger.error(
          `Failed to record email_linked TaskEvent for email ${email.id} and task ${taskId}`,
          JSON.stringify(eventResult.error),
        );
      }

      return task;
    } catch (err) {
      this.logger.error(
        `Unhandled error while creating task from email ${email.id}`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );

      return null;
    }
  }

  private async handleRouteAction(
    email: EmailMessageEnvelope,
    action: WorkflowAction,
  ): Promise<void> {
    const payload = (action.payload ?? {}) as {
      taskId?: string;
      task_id?: string;
      assigneeRole?: string;
      assignee_role?: string;
      actorUserId?: string;
      actor_user_id?: string;
      assigneeUserId?: string;
      assignee_user_id?: string;
      [key: string]: unknown;
    };

    const taskId =
      (payload.taskId as string | undefined) ??
      (payload.task_id as string | undefined);

    if (!taskId) {
      this.logger.warn(
        'ROUTE action missing taskId/task_id; cannot perform routing.',
      );
      return;
    }

    const input: AssignTaskInput = {
      organizationId: email.organization_id,
      taskId,
      assigneeRole:
        (payload.assigneeRole as string | undefined) ??
        (payload.assignee_role as string | undefined) ??
        null,
      assigneeUserId:
        (payload.assigneeUserId as string | undefined) ??
        (payload.assignee_user_id as string | undefined) ??
        null,
      actorUserId:
        (payload.actorUserId as string | undefined) ??
        (payload.actor_user_id as string | undefined) ??
        null,
    };

    const result = await this.taskService.assignTask(input);

    if (!result.ok) {
      this.logger.error(
        `TaskService.assignTask returned error for email ${email.id} and task ${taskId}`,
        JSON.stringify(result.error),
      );
    }
  }

  private async handleEscalateAction(
    email: EmailMessageEnvelope,
    action: WorkflowAction,
  ): Promise<void> {
    const payload = (action.payload ?? {}) as {
      taskId?: string;
      task_id?: string;
      reason?: string;
      actorUserId?: string;
      actor_user_id?: string;
      [key: string]: unknown;
    };

    const taskId =
      (payload.taskId as string | undefined) ??
      (payload.task_id as string | undefined);

    if (!taskId) {
      this.logger.warn(
        'ESCALATE action missing taskId/task_id; cannot perform escalation.',
      );
      return;
    }

    const input: EscalateTaskInput = {
      organizationId: email.organization_id,
      taskId,
      reason:
        (payload.reason as string | undefined) ??
        'Escalated via email workflow.',
      actorUserId:
        (payload.actorUserId as string | undefined) ??
        (payload.actor_user_id as string | undefined) ??
        null,
    };

    const result = await this.taskService.escalateTask(input);

    if (!result.ok) {
      this.logger.error(
        `TaskService.escalateTask returned error for email ${email.id} and task ${taskId}`,
        JSON.stringify(result.error),
      );
    }
  }

  private async handleNotifyAction(
    email: EmailMessageEnvelope,
    action: WorkflowAction,
  ): Promise<number> {
    const payload = (action.payload ?? {}) as {
      taskId?: string;
      task_id?: string;
      eventType?: TaskNotificationEventType;
      event_type?: TaskNotificationEventType;
      [key: string]: unknown;
    };

    const taskId =
      (payload.taskId as string | undefined) ??
      (payload.task_id as string | undefined);

    if (!taskId) {
      this.logger.warn(
        'NOTIFY action missing taskId/task_id; cannot send notification.',
      );
      return 0;
    }

    const result = await this.taskService.getTaskById(
      email.organization_id,
      taskId,
    );

    if (!result.ok || !result.data) {
      this.logger.error(
        `TaskService.getTaskById returned error for email ${email.id} and task ${taskId}`,
        JSON.stringify(result.error),
      );
      return 0;
    }

    const eventType: TaskNotificationEventType =
      (payload.eventType as TaskNotificationEventType | undefined) ??
      (payload.event_type as TaskNotificationEventType | undefined) ??
      'UPDATED';

    await this.notificationService.sendTaskNotification(
      result.data,
      eventType,
    );

    return 1;
  }
}


=== FILE 12/48: apps/api/src/orgo/core/email/email-validator.service.ts ===

import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

/**
 * Shape of a single email attachment as seen by the email gateway.
 * This is a logical view over the underlying email_attachments table.
 */
export interface EmailAttachment {
  filename?: string | null;
  contentType?: string | null; // MIME type, e.g. "application/pdf"
  size?: number | null; // size in bytes, if known
}

/**
 * Parsed email payload shape expected by the validator.
 * Typically produced by an EmailParserService before validation.
 */
export interface ParsedEmailPayload {
  subject?: string | null;
  fromAddress?: string | null;
  toAddresses?: string[] | null;
  ccAddresses?: string[] | null;
  bccAddresses?: string[] | null;
  textBody?: string | null;
  htmlBody?: string | null;
  attachments?: EmailAttachment[] | null;

  /**
   * Optional raw size hint (in bytes). If provided, this will be used as an
   * upper bound when computing total message size.
   */
  rawSizeBytes?: number | null;
}

/**
 * Canonical service error shape for Core Services:
 * aligns with the `{ ok, data, error }` result contract.
 */
export interface ServiceError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Canonical service result wrapper used by core services.
 */
export interface ServiceResult<T> {
  ok: boolean;
  data: T | null;
  error: ServiceError | null;
}

/**
 * High‑level summary returned on successful validation.
 */
export interface EmailValidationSummary {
  totalSizeBytes: number;
  maxSizeBytes: number;
  attachmentCount: number;
}

/**
 * Email limits derived from configuration.
 * Mirrors the `limits` section of `email_config.yaml`.
 */
export interface EmailLimitsConfig {
  maxEmailSizeMb: number;
  allowedAttachmentMimetypes: string[];
}

/**
 * Email validator for the Email Gateway.
 *
 * Responsibilities:
 *  - Enforce required fields on parsed email payloads.
 *  - Enforce max total email size (default 10MB, configurable).
 *  - Enforce allowed attachment MIME types.
 *  - Return a standard `{ ok, data, error }` result shape.
 */
@Injectable()
export class EmailValidatorService {
  private readonly logger = new Logger(EmailValidatorService.name);

  private readonly maxEmailSizeBytes: number;
  private readonly allowedAttachmentMimetypes: Set<string>;

  // Defaults taken from the email config example in the Core Services spec.
  private static readonly DEFAULT_MAX_EMAIL_SIZE_MB = 10;
  private static readonly DEFAULT_ALLOWED_MIMETYPES: string[] = [
    'application/pdf',
    'image/png',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  ];

  constructor(private readonly configService: ConfigService) {
    const limits = this.loadLimitsFromConfig();

    this.maxEmailSizeBytes = limits.maxEmailSizeMb * 1024 * 1024;
    this.allowedAttachmentMimetypes = new Set(
      limits.allowedAttachmentMimetypes.map((mt) => mt.toLowerCase()),
    );
  }

  /**
   * Validate a parsed email payload against Orgo's email limits and invariants.
   *
   * On success:
   *   { ok: true, data: { totalSizeBytes, maxSizeBytes, attachmentCount }, error: null }
   *
   * On failure:
   *   { ok: false, data: null, error: { code, message, details: { issues: [...] } } }
   */
  validateEmailPayload(
    payload: ParsedEmailPayload,
  ): ServiceResult<EmailValidationSummary> {
    const issues: Array<{
      code: string;
      message: string;
      field?: string;
      attachmentName?: string | null;
    }> = [];

    // 1. Required fields: subject, from, to, and at least one body.
    if (!payload.subject || !payload.subject.trim()) {
      issues.push({
        code: 'MISSING_SUBJECT',
        message: 'Email subject is required.',
        field: 'subject',
      });
    }

    if (!payload.fromAddress || !payload.fromAddress.trim()) {
      issues.push({
        code: 'MISSING_FROM_ADDRESS',
        message: 'From address is required.',
        field: 'fromAddress',
      });
    } else if (!this.isValidEmailAddress(payload.fromAddress)) {
      issues.push({
        code: 'INVALID_FROM_ADDRESS',
        message: 'From address is not a valid email address.',
        field: 'fromAddress',
      });
    }

    const toAddresses = payload.toAddresses ?? [];
    if (!Array.isArray(toAddresses) || toAddresses.length === 0) {
      issues.push({
        code: 'MISSING_TO_ADDRESSES',
        message: 'At least one recipient (to) address is required.',
        field: 'toAddresses',
      });
    } else {
      for (const addr of toAddresses) {
        if (!this.isValidEmailAddress(addr)) {
          issues.push({
            code: 'INVALID_TO_ADDRESS',
            message: `Recipient address "${addr}" is not valid.`,
            field: 'toAddresses',
          });
        }
      }
    }

    const hasTextBody = !!(payload.textBody && payload.textBody.trim());
    const hasHtmlBody = !!(payload.htmlBody && payload.htmlBody.trim());
    if (!hasTextBody && !hasHtmlBody) {
      issues.push({
        code: 'MISSING_BODY',
        message:
          'Email body is required (either textBody or htmlBody must be non-empty).',
        field: 'textBody/htmlBody',
      });
    }

    // 2. Attachment MIME type validation against allowed list.
    const attachments = payload.attachments ?? [];
    for (const attachment of attachments) {
      const contentType = (attachment.contentType ?? '').toLowerCase().trim();
      // If content type is missing or not allowed, treat as invalid.
      if (!contentType || !this.allowedAttachmentMimetypes.has(contentType)) {
        issues.push({
          code: 'EMAIL_ATTACHMENT_TYPE_NOT_ALLOWED',
          message: `Attachment "${
            attachment.filename ?? 'unnamed'
          }" has disallowed or unknown MIME type "${
            attachment.contentType ?? 'unknown'
          }".`,
          field: 'attachments',
          attachmentName: attachment.filename ?? null,
        });
      }
    }

    // 3. Total size validation (payload + attachments) vs configured max.
    const totalSizeBytes = this.computeApproximateSize(payload);
    if (totalSizeBytes > this.maxEmailSizeBytes) {
      issues.push({
        code: 'EMAIL_SIZE_EXCEEDED',
        message: `Email exceeds maximum size of ${this.maxEmailSizeBytes} bytes.`,
        field: 'rawSizeBytes',
      });
    }

    if (issues.length > 0) {
      this.logger.warn(
        `Email validation failed with ${issues.length} issue(s). First: ${issues[0].code} – ${issues[0].message}`,
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'EMAIL_VALIDATION_ERROR',
          message: 'Parsed email payload failed validation.',
          details: { issues },
        },
      };
    }

    const summary: EmailValidationSummary = {
      totalSizeBytes,
      maxSizeBytes: this.maxEmailSizeBytes,
      attachmentCount: attachments.length,
    };

    return {
      ok: true,
      data: summary,
      error: null,
    };
  }

  /**
   * Load email limits from configuration.
   *
   * This implementation uses environment variables via Nest ConfigService:
   *   - EMAIL_MAX_SIZE_MB (number, defaults to 10)
   *   - EMAIL_ALLOWED_ATTACHMENT_MIMETYPES (comma‑separated list of MIME types)
   *
   * This is intentionally compatible with the `email_config.yaml` structure
   * described in the Core Services spec; a future Orgo config loader can hydrate
   * these into environment variables or ConfigService keys.
   */
  private loadLimitsFromConfig(): EmailLimitsConfig {
    const maxSizeFromEnv = this.configService.get<number | string>(
      'EMAIL_MAX_SIZE_MB',
    );
    const maxEmailSizeMb =
      typeof maxSizeFromEnv === 'number'
        ? maxSizeFromEnv
        : maxSizeFromEnv
        ? Number.parseInt(maxSizeFromEnv, 10)
        : EmailValidatorService.DEFAULT_MAX_EMAIL_SIZE_MB;

    const allowedFromEnv = this.configService.get<string>(
      'EMAIL_ALLOWED_ATTACHMENT_MIMETYPES',
    );

    const allowedAttachmentMimetypes =
      typeof allowedFromEnv === 'string' && allowedFromEnv.trim().length > 0
        ? allowedFromEnv
            .split(',')
            .map((s) => s.trim())
            .filter((s) => s.length > 0)
        : EmailValidatorService.DEFAULT_ALLOWED_MIMETYPES;

    return {
      maxEmailSizeMb:
        Number.isFinite(maxEmailSizeMb) && maxEmailSizeMb > 0
          ? maxEmailSizeMb
          : EmailValidatorService.DEFAULT_MAX_EMAIL_SIZE_MB,
      allowedAttachmentMimetypes,
    };
  }

  /**
   * Compute an approximate total size of the email (in bytes), using:
   *  - rawSizeBytes if provided (as an upper bound),
   *  - otherwise, the UTF‑8 byte length of key string fields plus attachment sizes.
   */
  private computeApproximateSize(payload: ParsedEmailPayload): number {
    // If a raw size hint is provided and positive, trust it.
    if (typeof payload.rawSizeBytes === 'number' && payload.rawSizeBytes > 0) {
      return payload.rawSizeBytes;
    }

    let total = 0;

    const addString = (value?: string | null) => {
      if (!value) return;
      total += Buffer.byteLength(value, 'utf8');
    };

    addString(payload.subject);
    addString(payload.fromAddress);

    (payload.toAddresses ?? []).forEach(addString);
    (payload.ccAddresses ?? []).forEach(addString);
    (payload.bccAddresses ?? []).forEach(addString);

    addString(payload.textBody);
    addString(payload.htmlBody);

    for (const attachment of payload.attachments ?? []) {
      if (typeof attachment.size === 'number' && attachment.size > 0) {
        total += attachment.size;
      }
      addString(attachment.filename ?? undefined);
      addString(attachment.contentType ?? undefined);
    }

    return total;
  }

  /**
   * Very conservative RFC‑2822‑style email address validator.
   * This is intentionally simple; higher‑fidelity validation can be added later.
   */
  private isValidEmailAddress(address: string): boolean {
    const trimmed = address.trim();
    if (!trimmed) {
      return false;
    }

    // Basic pattern: local@domain with at least one dot in the domain.
    const basicEmailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;

    return basicEmailRegex.test(trimmed);
  }
}


=== FILE 13/48: apps/api/src/orgo/core/email/email.controller.ts ===

import {
  Body,
  Controller,
  Get,
  HttpCode,
  HttpException,
  HttpStatus,
  Post,
  Query,
} from '@nestjs/common';
import { ApiOperation, ApiResponse, ApiTags } from '@nestjs/swagger';
import { EmailService } from './email.service';
import { LogService } from '../logging/log.service';
import {
  FN_EMAIL_SEND,
  FN_EMAIL_SEND_TEST,
  FN_EMAIL_POLL_MAILBOX,
  FN_EMAIL_CONFIG_STATUS,
} from '../functional-ids';

/**
 * Standard Orgo result shape for Core Services.
 * EmailService implementations should return this shape.
 */
interface OrgoResult<T> {
  ok: boolean;
  data: T | null;
  error: {
    code: string;
    message: string;
    details?: Record<string, unknown>;
  } | null;
}

/**
 * Request body for sending an email (transactional / notification style).
 * This mirrors the logical EMAIL_MESSAGE envelope in Doc 5.
 */
export class SendEmailRequestDto {
  /**
   * Optional organization context; if omitted, EmailService should
   * resolve a default org / config (e.g. "default").
   */
  organizationId?: string;

  /**
   * Primary recipients (RFC822 email addresses).
   */
  to!: string[];

  /**
   * Optional CC recipients.
   */
  cc?: string[];

  /**
   * Optional BCC recipients.
   */
  bcc?: string[];

  /**
   * Subject line (required, non‑empty).
   */
  subject!: string;

  /**
   * Email body as plain text or HTML (EmailService will normalize).
   */
  body!: string;

  /**
   * Optional idempotency key so callers can safely retry a send
   * without creating duplicate outbound messages.
   */
  idempotencyKey?: string;
}

/**
 * Request body for sending a test email to verify configuration.
 * Slimmer than SendEmailRequestDto on purpose.
 */
export class SendTestEmailRequestDto {
  /**
   * Optional organization context for multi‑tenant config lookup.
   */
  organizationId?: string;

  /**
   * Target address for the test email.
   */
  to!: string;

  /**
   * Optional human‑friendly label for the test.
   * Used only for logging / templates.
   */
  label?: string;
}

/**
 * Request body for manually polling an inbound mailbox.
 */
export class PollMailboxRequestDto {
  /**
   * Optional organization context; if omitted, service will decide
   * which default mailbox / org to poll.
   */
  organizationId?: string;

  /**
   * Maximum number of messages to fetch in this run.
   * If omitted, EmailService will use its default batch size.
   */
  maxCount?: number;

  /**
   * If true, run parsing/validation without committing
   * side‑effects (debug / diagnostics mode).
   */
  dryRun?: boolean;
}

/**
 * Minimal response for a successful send.
 */
export class EmailSendResponseDto {
  /**
   * Identifier of the stored outbound email message, if any.
   */
  emailMessageId?: string;

  /**
   * Underlying provider / SMTP message identifier, if available.
   */
  providerMessageId?: string;

  /**
   * Whether the message has been handed off to the provider.
   */
  accepted!: boolean;
}

/**
 * Status snapshot for the outbound / inbound email configuration.
 */
export class EmailStatusResponseDto {
  outboundConfigured!: boolean;
  inboundConfigured!: boolean;
  lastSuccessfulOutboundAt?: string | null;
  lastSuccessfulInboundAt?: string | null;
  issues!: string[];
}

/**
 * Result of a manual mailbox poll.
 */
export class PollMailboxResponseDto {
  /**
   * Number of raw messages fetched from the mailbox.
   */
  fetched!: number;

  /**
   * Number of messages successfully parsed into EMAIL_MESSAGE envelopes.
   */
  parsed!: number;

  /**
   * Number of messages rejected due to validation / limits.
   */
  rejected!: number;
}

@ApiTags('email')
@Controller('api/v3/email')
export class EmailController {
  constructor(
    private readonly emailService: EmailService,
    private readonly logService: LogService,
  ) {}

  /**
   * Send a transactional / notification email.
   *
   * This endpoint is primarily intended for internal Orgo modules
   * and admin tools, not for bulk marketing.
   */
  @Post('send')
  @HttpCode(HttpStatus.ACCEPTED)
  @ApiOperation({
    summary: 'Send email',
    description:
      'Send a transactional / notification email using the configured SMTP account for the organization.',
  })
  @ApiResponse({
    status: 202,
    description: 'Email accepted for delivery.',
    type: EmailSendResponseDto,
  })
  async sendEmail(
    @Body() body: SendEmailRequestDto,
  ): Promise<EmailSendResponseDto> {
    const result: OrgoResult<EmailSendResponseDto> =
      await this.emailService.sendEmail(body);

    return this.unwrapResult(result, {
      functionalId: FN_EMAIL_SEND,
      action: 'sendEmail',
      identifier: body.idempotencyKey,
      successMessage: 'Email accepted for delivery',
    });
  }

  /**
   * Send a simple test email to verify outbound configuration.
   */
  @Post('test')
  @HttpCode(HttpStatus.ACCEPTED)
  @ApiOperation({
    summary: 'Send test email',
    description:
      'Send a simple test email to verify SMTP configuration for an organization.',
  })
  @ApiResponse({
    status: 202,
    description: 'Test email accepted for delivery.',
    type: EmailSendResponseDto,
  })
  async sendTestEmail(
    @Body() body: SendTestEmailRequestDto,
  ): Promise<EmailSendResponseDto> {
    const result: OrgoResult<EmailSendResponseDto> =
      await this.emailService.sendTestEmail(body);

    return this.unwrapResult(result, {
      functionalId: FN_EMAIL_SEND_TEST,
      action: 'sendTestEmail',
      identifier: body.to,
      successMessage: 'Test email accepted for delivery',
    });
  }

  /**
   * Return a lightweight snapshot of email gateway health for the org.
   */
  @Get('status')
  @HttpCode(HttpStatus.OK)
  @ApiOperation({
    summary: 'Email gateway status',
    description:
      'Return a snapshot of inbound/outbound email configuration and recent health checks.',
  })
  @ApiResponse({
    status: 200,
    description: 'Status information for email gateway.',
    type: EmailStatusResponseDto,
  })
  async getStatus(
    @Query('organizationId') organizationId?: string,
  ): Promise<EmailStatusResponseDto> {
    const result: OrgoResult<EmailStatusResponseDto> =
      await this.emailService.getStatus({ organizationId });

    return this.unwrapResult(result, {
      functionalId: FN_EMAIL_CONFIG_STATUS,
      action: 'getStatus',
      identifier: organizationId,
      successMessage: 'Email gateway status fetched',
    });
  }

  /**
   * Manually trigger a mailbox poll.
   *
   * This is mainly for development, diagnostics, or controlled
   * backfills; normal ingestion should run via background workers.
   */
  @Post('poll')
  @HttpCode(HttpStatus.OK)
  @ApiOperation({
    summary: 'Poll inbound mailbox',
    description:
      'Manually poll the configured inbound mailbox and ingest up to `maxCount` messages.',
  })
  @ApiResponse({
    status: 200,
    description: 'Mailbox poll result.',
    type: PollMailboxResponseDto,
  })
  async pollMailbox(
    @Body() body: PollMailboxRequestDto,
  ): Promise<PollMailboxResponseDto> {
    const result: OrgoResult<PollMailboxResponseDto> =
      await this.emailService.pollMailbox(body);

    return this.unwrapResult(result, {
      functionalId: FN_EMAIL_POLL_MAILBOX,
      action: 'pollMailbox',
      identifier: body.organizationId,
      successMessage: 'Mailbox polled successfully',
    });
  }

  /**
   * Helper to unify handling of OrgoResult responses:
   *  - Logs success or failure.
   *  - Maps error codes to HTTP exceptions.
   *  - Returns the inner data on success.
   */
  private unwrapResult<T>(
    result: OrgoResult<T>,
    opts: {
      functionalId: string;
      action: string;
      identifier?: string | null;
      successMessage: string;
    },
  ): T {
    const { functionalId, action, identifier, successMessage } = opts;

    if (result.ok && result.data !== null) {
      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'INFO',
        message: successMessage,
        identifier: identifier ?? undefined,
        metadata: {
          fn: functionalId,
          action,
        },
      });

      return result.data;
    }

    const error = result.error ?? {
      code: 'UNKNOWN_ERROR',
      message: 'Unknown error in EmailService',
    };

    this.logService.logEvent({
      category: 'EMAIL',
      logLevel: 'ERROR',
      message: error.message,
      identifier: identifier ?? undefined,
      metadata: {
        fn: functionalId,
        action,
        errorCode: error.code,
        errorDetails: error.details ?? undefined,
      },
    });

    const status = this.mapErrorCodeToHttpStatus(error.code);

    throw new HttpException(
      {
        code: error.code,
        message: error.message,
        details: error.details,
      },
      status,
    );
  }

  /**
   * Map Orgo core error codes to HTTP status codes.
   */
  private mapErrorCodeToHttpStatus(code: string): HttpStatus {
    if (code.endsWith('_VALIDATION_ERROR')) {
      return HttpStatus.BAD_REQUEST;
    }

    if (
      code === 'EMAIL_SEND_FAILED' ||
      code === 'EMAIL_PARSING_ERROR' ||
      code === 'EMAIL_GATEWAY_UNAVAILABLE'
    ) {
      return HttpStatus.BAD_GATEWAY;
    }

    return HttpStatus.INTERNAL_SERVER_ERROR;
  }
}


=== FILE 14/48: apps/api/src/orgo/core/email/email.module.ts ===

// apps/api/src/orgo/core/email/email.module.ts

import { Module } from '@nestjs/common';

import { PersistenceModule } from '../../../persistence/persistence.module';
import { LoggerModule } from '../logging/logger.module';
import { WorkflowModule } from '../workflow/workflow.module';
import { TaskModule } from '../tasks/task.module';
import { OrgoConfigModule } from '../../config/config.module';

import { EmailService } from './email.service';
import { EmailParserService } from './email-parser.service';
import { EmailValidatorService } from './email-validator.service';
import { EmailIngestService } from './email-ingest.service';
import { EmailRouterService } from './email-router.service';

/**
 * EmailModule
 *
 * Wires up the Orgo email gateway (“email_gateway” core service):
 * - EmailIngestService: polling / fetching raw emails
 * - EmailParserService: normalisation into EMAIL_MESSAGE envelopes
 * - EmailValidatorService: size / attachment / field validation
 * - EmailRouterService: hand-off into the workflow engine
 * - EmailService: public façade used by other modules to send email
 *
 * Dependencies:
 * - PersistenceModule: access to the database (PrismaService)
 * - LoggerModule: structured logging for EMAIL / WORKFLOW categories
 * - WorkflowModule: to route parsed emails into workflows / tasks
 * - TaskModule: task creation / linkage when workflows produce tasks
 * - OrgoConfigModule: access to YAML-based email configuration
 */
@Module({
  imports: [
    PersistenceModule,
    LoggerModule,
    WorkflowModule,
    TaskModule,
    OrgoConfigModule,
  ],
  providers: [
    EmailService,
    EmailParserService,
    EmailValidatorService,
    EmailIngestService,
    EmailRouterService,
  ],
  exports: [
    EmailService,
    EmailParserService,
    EmailValidatorService,
    EmailIngestService,
    EmailRouterService,
  ],
})
export class EmailModule {}


=== FILE 15/48: apps/api/src/orgo/core/email/email.service.ts ===

import { Injectable } from '@nestjs/common';
import nodemailer, { Transporter } from 'nodemailer';

import { OrgoConfigService } from '../../config/config.service';
import { LogService } from '../logging/log.service';
import { FN_EMAIL_SEND } from '../functional-ids';

export interface ServiceError {
  code: string;
  message: string;
  // Free-form extra details; must be safe to log.
  details?: Record<string, unknown>;
}

export interface ServiceResult<T> {
  ok: boolean;
  data: T | null;
  error: ServiceError | null;
}

export interface EmailAttachment {
  filename: string;
  content: Buffer | string;
  contentType?: string;
}

export interface SendEmailOptions {
  to: string | string[];
  subject: string;
  text?: string;
  html?: string;
  cc?: string | string[];
  bcc?: string | string[];
  replyTo?: string;
  headers?: Record<string, string>;
  attachments?: EmailAttachment[];
  /**
   * Optional explicit from header, e.g. `"Orgo" <no-reply@example.org>`.
   * If omitted, a default from the email config (or a safe fallback) will be used.
   */
  fromOverride?: string;
}

/**
 * Shape of the email config as returned by OrgoConfigService.
 * This mirrors the core parts of /config/email/email_config.yaml (Doc 5).
 */
export interface EmailConfig {
  smtp: {
    host: string;
    port: number;
    use_tls?: boolean;
    use_ssl?: boolean;
    username_env?: string;
    password_env?: string;
    connection_timeout_secs?: number;
    send_timeout_secs?: number;
    max_retries?: number;
    retry_backoff_secs?: number;
  };
  limits?: {
    max_email_size_mb?: number;
    allowed_attachment_mimetypes?: string[];
  };
}

/**
 * Result payload for a successful sendEmail call.
 */
export interface EmailSendData {
  messageId: string;
  accepted: string[];
  rejected: string[];
}

/**
 * Core EmailService for Orgo.
 *
 * Responsibilities (aligned with Core Services spec, Doc 5):
 *  - Send outbound email via SMTP using configuration from OrgoConfigService.
 *  - Enforce basic validation and configured size limits.
 *  - Apply retry + backoff on transient failures.
 *  - Emit structured log events via LogService.
 *
 * It returns the standard `{ ok, data, error }` result shape.
 */
@Injectable()
export class EmailService {
  private transporter: Transporter | null = null;

  constructor(
    private readonly config: OrgoConfigService,
    private readonly logService: LogService,
  ) {}

  /**
   * Public entrypoint used by NotificationService and other core services.
   */
  async sendEmail(
    options: SendEmailOptions,
  ): Promise<ServiceResult<EmailSendData>> {
    const emailConfig = this.config.getEmailConfig?.() as EmailConfig | undefined;

    if (!emailConfig || !emailConfig.smtp) {
      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: 'Email config missing; cannot send email',
        identifier: FN_EMAIL_SEND,
        metadata: {
          reason: 'email_config_missing',
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'EMAIL_CONFIG_ERROR',
          message: 'Email configuration is missing or invalid',
        },
      };
    }

    const validationError = this.validateOutgoingEmail(options, emailConfig);
    if (validationError) {
      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'WARNING',
        message: 'Outgoing email validation failed',
        identifier: FN_EMAIL_SEND,
        metadata: {
          code: validationError.code,
          details: validationError.details,
        },
      });

      return {
        ok: false,
        data: null,
        error: validationError,
      };
    }

    try {
      const transporter = await this.ensureTransporter(emailConfig);
      const { to, cc, bcc } = this.normalizeRecipients(options);
      const from = this.resolveFrom(options, emailConfig);

      const mailOptions = {
        from,
        to,
        cc,
        bcc,
        subject: options.subject,
        text: options.text,
        html: options.html,
        replyTo: options.replyTo,
        headers: options.headers,
        attachments: options.attachments?.map((att) => ({
          filename: att.filename,
          content: att.content,
          contentType: att.contentType,
        })),
      };

      const maxRetries =
        emailConfig.smtp.max_retries !== undefined
          ? emailConfig.smtp.max_retries
          : 3;
      const retryBackoffSecs =
        emailConfig.smtp.retry_backoff_secs !== undefined
          ? emailConfig.smtp.retry_backoff_secs
          : 2;

      let lastError: unknown;

      for (let attempt = 1; attempt <= Math.max(1, maxRetries); attempt += 1) {
        try {
          const info = await transporter.sendMail(mailOptions);

          this.logService.logEvent({
            category: 'EMAIL',
            logLevel: 'INFO',
            message: 'Email sent',
            identifier: FN_EMAIL_SEND,
            metadata: {
              to,
              cc,
              bcc,
              messageId: info.messageId,
              attempt,
            },
          });

          return {
            ok: true,
            data: {
              messageId: info.messageId,
              accepted: Array.isArray(info.accepted)
                ? info.accepted.map(String)
                : [],
              rejected: Array.isArray(info.rejected)
                ? info.rejected.map(String)
                : [],
            },
            error: null,
          };
        } catch (err) {
          lastError = err;

          const transient = this.isTransientError(err);

          this.logService.logEvent({
            category: 'EMAIL',
            logLevel: transient ? 'WARNING' : 'ERROR',
            message: 'Email send attempt failed',
            identifier: FN_EMAIL_SEND,
            metadata: {
              to,
              attempt,
              transient,
              errorMessage:
                err instanceof Error ? err.message : 'Unknown error',
            },
          });

          const isLastAttempt =
            attempt === maxRetries || !transient || maxRetries <= 1;
          if (isLastAttempt) {
            break;
          }

          const backoffMs = retryBackoffSecs * 1000 * attempt;
          await this.sleep(backoffMs);
        }
      }

      const errorMessage =
        lastError instanceof Error
          ? lastError.message
          : 'Unknown error while sending email';

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: 'Email send failed after retries',
        identifier: FN_EMAIL_SEND,
        metadata: {
          to: this.normalizeRecipients(options).to,
          errorMessage,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'EMAIL_SEND_FAILED',
          message: errorMessage,
        },
      };
    } catch (err) {
      const message =
        err instanceof Error ? err.message : 'Unknown error in EmailService';

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: 'Unexpected error in EmailService.sendEmail',
        identifier: FN_EMAIL_SEND,
        metadata: {
          errorMessage: message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'EMAIL_UNEXPECTED_ERROR',
          message,
        },
      };
    }
  }

  /**
   * Validates the outgoing email against the minimal Orgo rules
   * and configured size limits.
   */
  private validateOutgoingEmail(
    options: SendEmailOptions,
    emailConfig: EmailConfig,
  ): ServiceError | null {
    const { to } = this.normalizeRecipients(options);

    if (!to.length) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: 'At least one recipient is required',
        details: { field: 'to' },
      };
    }

    if (!options.subject || !options.subject.trim()) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: 'Subject is required',
        details: { field: 'subject' },
      };
    }

    if (!options.text && !options.html) {
      return {
        code: 'EMAIL_VALIDATION_ERROR',
        message: 'Either text or html body is required',
        details: { field: 'text|html' },
      };
    }

    const maxMb = emailConfig.limits?.max_email_size_mb;
    if (maxMb && maxMb > 0) {
      const approxMb = this.approximateEmailSizeMb(options);
      if (approxMb > maxMb) {
        return {
          code: 'EMAIL_SIZE_EXCEEDED',
          message: `Email size ${approxMb.toFixed(
            2,
          )} MB exceeds configured maximum of ${maxMb} MB`,
          details: {
            approximateSizeMb: approxMb,
            maxAllowedMb: maxMb,
          },
        };
      }
    }

    const allowedTypes = emailConfig.limits?.allowed_attachment_mimetypes;
    if (allowedTypes && allowedTypes.length && options.attachments?.length) {
      const disallowed = new Set<string>();

      for (const att of options.attachments) {
        if (!att.contentType) {
          continue;
        }
        if (!allowedTypes.includes(att.contentType)) {
          disallowed.add(att.contentType);
        }
      }

      if (disallowed.size > 0) {
        return {
          code: 'EMAIL_ATTACHMENT_TYPE_NOT_ALLOWED',
          message: 'One or more attachment MIME types are not allowed',
          details: {
            disallowedTypes: Array.from(disallowed),
            allowedTypes,
          },
        };
      }
    }

    return null;
  }

  /**
   * Creates or returns a cached nodemailer transporter
   * based on the configured SMTP settings.
   */
  private async ensureTransporter(emailConfig: EmailConfig): Promise<Transporter> {
    if (this.transporter) {
      return this.transporter;
    }

    const { smtp } = emailConfig;

    if (!smtp.host || !smtp.port) {
      throw new Error('SMTP host and port must be configured');
    }

    const user =
      smtp.username_env && process.env[smtp.username_env]
        ? process.env[smtp.username_env]
        : undefined;
    const pass =
      smtp.password_env && process.env[smtp.password_env]
        ? process.env[smtp.password_env]
        : undefined;

    const secure =
      smtp.use_ssl !== undefined
        ? smtp.use_ssl
        : smtp.port === 465 || smtp.use_tls === true;

    const connectionTimeoutMs = (smtp.connection_timeout_secs ?? 10) * 1000;
    const socketTimeoutMs = (smtp.send_timeout_secs ?? 30) * 1000;

    const transporter = nodemailer.createTransport({
      host: smtp.host,
      port: smtp.port,
      secure,
      auth:
        user && pass
          ? {
              user,
              pass,
            }
          : undefined,
      connectionTimeout: connectionTimeoutMs,
      socketTimeout: socketTimeoutMs,
    });

    // Verify connection once at startup of the transporter.
    try {
      await transporter.verify();
      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'INFO',
        message: 'SMTP transport verified',
        identifier: FN_EMAIL_SEND,
        metadata: {
          host: smtp.host,
          port: smtp.port,
        },
      });
    } catch (err) {
      const message =
        err instanceof Error
          ? err.message
          : 'Failed to verify SMTP connection';

      this.logService.logEvent({
        category: 'EMAIL',
        logLevel: 'ERROR',
        message: 'SMTP verification failed',
        identifier: FN_EMAIL_SEND,
        metadata: {
          host: smtp.host,
          port: smtp.port,
          errorMessage: message,
        },
      });

      // Let callers see the failure as EMAIL_CONFIG_ERROR or EMAIL_SEND_FAILED.
      throw new Error(`SMTP verification failed: ${message}`);
    }

    this.transporter = transporter;
    return transporter;
  }

  private normalizeRecipients(options: SendEmailOptions): {
    to: string[];
    cc: string[];
    bcc: string[];
  } {
    const normalize = (value?: string | string[]): string[] => {
      if (!value) return [];
      if (Array.isArray(value)) {
        return value
          .map((v) => v.trim())
          .filter((v) => v.length > 0);
      }
      return value
        .split(',')
        .map((v) => v.trim())
        .filter((v) => v.length > 0);
    };

    return {
      to: normalize(options.to),
      cc: normalize(options.cc),
      bcc: normalize(options.bcc),
    };
  }

  /**
   * Resolve the "from" header from overrides or configuration.
   */
  private resolveFrom(
    options: SendEmailOptions,
    _emailConfig: EmailConfig,
  ): string {
    if (options.fromOverride && options.fromOverride.trim()) {
      return options.fromOverride.trim();
    }

    // Fallback; notification_config should typically provide a better sender.
    return 'Orgo System <no-reply@orgo.local>';
  }

  /**
   * Very rough approximation of email size in MB, used to enforce limits.
   * This is deliberately conservative and avoids buffering full MIME output.
   */
  private approximateEmailSizeMb(options: SendEmailOptions): number {
    let bytes = 0;

    const add = (value?: string) => {
      if (!value) return;
      bytes += Buffer.byteLength(value, 'utf8');
    };

    add(
      Array.isArray(options.to) ? options.to.join(',') : options.to ?? '',
    );
    add(
      Array.isArray(options.cc) ? options.cc.join(',') : options.cc ?? '',
    );
    add(
      Array.isArray(options.bcc)
        ? options.bcc.join(',')
        : options.bcc ?? '',
    );
    add(options.subject);
    add(options.text);
    add(options.html);

    if (options.attachments) {
      for (const att of options.attachments) {
        if (typeof att.content === 'string') {
          bytes += Buffer.byteLength(att.content, 'utf8');
        } else {
          bytes += att.content.length;
        }
        add(att.filename);
        if (att.contentType) add(att.contentType);
      }
    }

    return bytes / (1024 * 1024);
  }

  /**
   * Heuristic detection of transient SMTP / network errors.
   * Used to decide whether to retry.
   */
  private isTransientError(err: unknown): boolean {
    if (!err || typeof err !== 'object') {
      return false;
    }

    const anyErr = err as { code?: string; responseCode?: number };

    const transientNodeErrorCodes = new Set([
      'ETIMEDOUT',
      'ECONNRESET',
      'EAI_AGAIN',
      'ECONNREFUSED',
      'ENOTFOUND',
    ]);

    if (anyErr.code && transientNodeErrorCodes.has(anyErr.code)) {
      return true;
    }

    // For SMTP codes, treat typical resource/availability issues as transient.
    if (typeof anyErr.responseCode === 'number') {
      const code = anyErr.responseCode;
      if (
        code === 421 || // Service not available, closing transmission channel
        code === 450 || // Requested mail action not taken: mailbox unavailable
        code === 451 || // Local error in processing
        code === 452 // Insufficient system storage
      ) {
        return true;
      }
    }

    return false;
  }

  private sleep(ms: number): Promise<void> {
    return new Promise((resolve) => {
      setTimeout(resolve, ms);
    });
  }
}


=== FILE 16/48: apps/api/src/orgo/core/functional-ids.ts ===

/**
 * Stable functional identifiers for Orgo v3.
 *
 * Pattern: FN_<MODULE>_<ACTION>
 *
 * These IDs are used in:
 * - Structured logging (`identifier` field in LOG_EVENT)
 * - Analytics / Insights dimensions
 * - Configuration & feature flags (per-function overrides)
 *
 * This file must stay in sync with:
 * - apps/web/src/orgo/core/functional-ids.ts
 * - Doc 4 – Functional Code-Name Inventory
 */

/* ------------------------------------------------------------------------- */
/* Backbone: Organizations, Persons, Identity & RBAC                         */
/* ------------------------------------------------------------------------- */

export const FN_ORG_CREATE_ORGANIZATION = 'FN_ORG_CREATE_ORGANIZATION' as const;
export const FN_ORG_UPDATE_ORGANIZATION = 'FN_ORG_UPDATE_ORGANIZATION' as const;

export const FN_PERSON_UPSERT_PERSON_PROFILE =
  'FN_PERSON_UPSERT_PERSON_PROFILE' as const;

export const FN_RBAC_CREATE_ROLE = 'FN_RBAC_CREATE_ROLE' as const;
export const FN_RBAC_ASSIGN_PERMISSION = 'FN_RBAC_ASSIGN_PERMISSION' as const;
export const FN_RBAC_ASSIGN_USER_ROLE = 'FN_RBAC_ASSIGN_USER_ROLE' as const;

export const FN_IDENTITY_LINK_USER_TO_PERSON =
  'FN_IDENTITY_LINK_USER_TO_PERSON' as const;

/* ------------------------------------------------------------------------- */
/* Signals & Ingestion: Email, API, Offline                                  */
/* ------------------------------------------------------------------------- */

export const FN_EMAIL_SEND = 'FN_EMAIL_SEND' as const;
export const FN_EMAIL_PARSE_INCOMING = 'FN_EMAIL_PARSE_INCOMING' as const;
export const FN_EMAIL_VALIDATE_PAYLOAD = 'FN_EMAIL_VALIDATE_PAYLOAD' as const;
export const FN_EMAIL_POLL_MAILBOX = 'FN_EMAIL_POLL_MAILBOX' as const;
export const FN_EMAIL_ROUTE_TO_WORKFLOW = 'FN_EMAIL_ROUTE_TO_WORKFLOW' as const;

export const FN_SIGNAL_INGEST = 'FN_SIGNAL_INGEST' as const;

export const FN_EMAIL_IMPORT_ARCHIVE = 'FN_EMAIL_IMPORT_ARCHIVE' as const;

export const FN_SYNC_OFFLINE_NODE = 'FN_SYNC_OFFLINE_NODE' as const;
export const FN_SYNC_OFFLINE_TASKS = 'FN_SYNC_OFFLINE_TASKS' as const;

/* ------------------------------------------------------------------------- */
/* Core: Cases, Tasks, Workflow, Escalations & Labels                        */
/* ------------------------------------------------------------------------- */

/** Case management */
export const FN_CASE_CREATE_FROM_SIGNAL =
  'FN_CASE_CREATE_FROM_SIGNAL' as const;
export const FN_CASE_CREATE = 'FN_CASE_CREATE' as const;
export const FN_CASE_GET_WITH_TASKS = 'FN_CASE_GET_WITH_TASKS' as const;
export const FN_CASE_RUN_CYCLIC_REVIEW =
  'FN_CASE_RUN_CYCLIC_REVIEW' as const;

/** Task management */
export const FN_TASK_CREATE = 'FN_TASK_CREATE' as const;
export const FN_TASK_UPDATE_STATUS = 'FN_TASK_UPDATE_STATUS' as const;
export const FN_TASK_ESCALATE = 'FN_TASK_ESCALATE' as const;
export const FN_TASK_ASSIGN = 'FN_TASK_ASSIGN' as const;
export const FN_TASK_ADD_COMMENT = 'FN_TASK_ADD_COMMENT' as const;
export const FN_TASK_GET_BY_ID = 'FN_TASK_GET_BY_ID' as const;

/** Workflow engine & escalation */
export const FN_WORKFLOW_EXECUTE = 'FN_WORKFLOW_EXECUTE' as const;
export const FN_WORKFLOW_VALIDATE_RULES =
  'FN_WORKFLOW_VALIDATE_RULES' as const;
export const FN_WORKFLOW_SIMULATE = 'FN_WORKFLOW_SIMULATE' as const;

export const FN_ESCALATION_EVALUATE = 'FN_ESCALATION_EVALUATE' as const;

/** Labels & routing */
export const FN_LABEL_RESOLVE = 'FN_LABEL_RESOLVE' as const;
export const FN_ROUTING_APPLY_RULES = 'FN_ROUTING_APPLY_RULES' as const;
export const FN_LABEL_CREATE_DEFINITION =
  'FN_LABEL_CREATE_DEFINITION' as const;
export const FN_LABEL_APPLY_TO_ENTITY = 'FN_LABEL_APPLY_TO_ENTITY' as const;

/* ------------------------------------------------------------------------- */
/* Configuration, Profiles & Feature Flags                                   */
/* ------------------------------------------------------------------------- */

export const FN_PROFILE_LOAD = 'FN_PROFILE_LOAD' as const;
export const FN_PROFILE_APPLY_DEFAULTS =
  'FN_PROFILE_APPLY_DEFAULTS' as const;
export const FN_PROFILE_PREVIEW_DIFF = 'FN_PROFILE_PREVIEW_DIFF' as const;

export const FN_CONFIG_GET_GLOBAL = 'FN_CONFIG_GET_GLOBAL' as const;
export const FN_CONFIG_UPDATE_SERVICE_CONFIG =
  'FN_CONFIG_UPDATE_SERVICE_CONFIG' as const;
export const FN_CONFIG_IMPORT_BUNDLE = 'FN_CONFIG_IMPORT_BUNDLE' as const;

export const FN_FEATURE_FLAG_SET = 'FN_FEATURE_FLAG_SET' as const;
export const FN_FEATURE_FLAG_EVALUATE = 'FN_FEATURE_FLAG_EVALUATE' as const;

/* ------------------------------------------------------------------------- */
/* Interfaces: Public API, Admin UI, Live Updates                            */
/* ------------------------------------------------------------------------- */

/** Public REST API – Tasks */
export const FN_API_LIST_TASKS = 'FN_API_LIST_TASKS' as const;
export const FN_API_GET_TASK = 'FN_API_GET_TASK' as const;
export const FN_API_CREATE_TASK = 'FN_API_CREATE_TASK' as const;
export const FN_API_UPDATE_TASK_STATUS =
  'FN_API_UPDATE_TASK_STATUS' as const;

/** Public REST API – Cases */
export const FN_API_LIST_CASES = 'FN_API_LIST_CASES' as const;
export const FN_API_GET_CASE = 'FN_API_GET_CASE' as const;

/** Public REST API – Workflows */
export const FN_API_EXECUTE_WORKFLOW = 'FN_API_EXECUTE_WORKFLOW' as const;

/** Admin UI screens */
export const FN_UI_ADMIN_TASK_OVERVIEW =
  'FN_UI_ADMIN_TASK_OVERVIEW' as const;
export const FN_UI_ADMIN_CASE_OVERVIEW =
  'FN_UI_ADMIN_CASE_OVERVIEW' as const;
export const FN_UI_ORG_PROFILE_SETTINGS =
  'FN_UI_ORG_PROFILE_SETTINGS' as const;

/** Notifications & live updates */
export const FN_NOTIFICATION_SEND_IN_APP =
  'FN_NOTIFICATION_SEND_IN_APP' as const;
export const FN_NOTIFICATION_SEND_EMAIL =
  'FN_NOTIFICATION_SEND_EMAIL' as const;

export const FN_GATEWAY_TASK_EVENTS_STREAM =
  'FN_GATEWAY_TASK_EVENTS_STREAM' as const;

/* ------------------------------------------------------------------------- */
/* Domain Modules: Maintenance, HR, Education, Generic Domain API           */
/* ------------------------------------------------------------------------- */

/** Maintenance domain */
export const FN_DOMAIN_MAINTENANCE_REGISTER_INCIDENT =
  'FN_DOMAIN_MAINTENANCE_REGISTER_INCIDENT' as const;
export const FN_DOMAIN_MAINTENANCE_LIST_INCIDENTS =
  'FN_DOMAIN_MAINTENANCE_LIST_INCIDENTS' as const;

/** HR domain */
export const FN_DOMAIN_HR_REGISTER_REPORT =
  'FN_DOMAIN_HR_REGISTER_REPORT' as const;
export const FN_DOMAIN_HR_LIST_CASES = 'FN_DOMAIN_HR_LIST_CASES' as const;

/** Education domain */
export const FN_DOMAIN_EDUCATION_REGISTER_STUDENT_INCIDENT =
  'FN_DOMAIN_EDUCATION_REGISTER_STUDENT_INCIDENT' as const;
export const FN_DOMAIN_EDUCATION_LIST_INCIDENTS =
  'FN_DOMAIN_EDUCATION_LIST_INCIDENTS' as const;

/** Generic domain abstractions */
export const FN_DOMAIN_TASK_FACTORY_CREATE =
  'FN_DOMAIN_TASK_FACTORY_CREATE' as const;
export const FN_DOMAIN_WORKFLOW_APPLY_OVERRIDES =
  'FN_DOMAIN_WORKFLOW_APPLY_OVERRIDES' as const;

/* ------------------------------------------------------------------------- */
/* Insights, Analytics & Cyclic Overview                                     */
/* ------------------------------------------------------------------------- */

export const FN_REPORTS_GET_TASK_VOLUME =
  'FN_REPORTS_GET_TASK_VOLUME' as const;
export const FN_REPORTS_GET_SLA_BREACHES =
  'FN_REPORTS_GET_SLA_BREACHES' as const;
export const FN_REPORTS_GET_PROFILE_SCORE =
  'FN_REPORTS_GET_PROFILE_SCORE' as const;

export const FN_ANALYTICS_EXPORT_FACTS =
  'FN_ANALYTICS_EXPORT_FACTS' as const;
export const FN_ANALYTICS_REFRESH_MATERIALIZED_VIEWS =
  'FN_ANALYTICS_REFRESH_MATERIALIZED_VIEWS' as const;

export const FN_INSIGHTS_RUN_WEEKLY_PATTERNS =
  'FN_INSIGHTS_RUN_WEEKLY_PATTERNS' as const;
export const FN_INSIGHTS_RUN_MONTHLY_TRENDS =
  'FN_INSIGHTS_RUN_MONTHLY_TRENDS' as const;
export const FN_INSIGHTS_RUN_YEARLY_SYSTEMIC_REVIEW =
  'FN_INSIGHTS_RUN_YEARLY_SYSTEMIC_REVIEW' as const;

export const FN_INSIGHTS_CACHE_WARM_DASHBOARDS =
  'FN_INSIGHTS_CACHE_WARM_DASHBOARDS' as const;

/* ------------------------------------------------------------------------- */
/* Infrastructure, Health, Metrics & Alerts                                  */
/* ------------------------------------------------------------------------- */

export const FN_HEALTH_GET = 'FN_HEALTH_GET' as const;
export const FN_WORKER_HEARTBEAT = 'FN_WORKER_HEARTBEAT' as const;

export const FN_METRICS_RECORD_WORKFLOW_LATENCY =
  'FN_METRICS_RECORD_WORKFLOW_LATENCY' as const;
export const FN_METRICS_RECORD_QUEUE_DEPTH =
  'FN_METRICS_RECORD_QUEUE_DEPTH' as const;

export const FN_ALERT_ESCALATION_DELAY =
  'FN_ALERT_ESCALATION_DELAY' as const;
export const FN_ALERT_ERROR_RATE = 'FN_ALERT_ERROR_RATE' as const;

/* ------------------------------------------------------------------------- */
/* Security, Privacy, Compliance & Logging                                   */
/* ------------------------------------------------------------------------- */

export const FN_AUTH_VALIDATE_ACCESS_TOKEN =
  'FN_AUTH_VALIDATE_ACCESS_TOKEN' as const;
export const FN_RBAC_CHECK_PERMISSION =
  'FN_RBAC_CHECK_PERMISSION' as const;

export const FN_PRIVACY_ANONYMIZE_PAYLOAD =
  'FN_PRIVACY_ANONYMIZE_PAYLOAD' as const;

export const FN_AUDIT_RECORD_EVENT = 'FN_AUDIT_RECORD_EVENT' as const;
export const FN_COMPLIANCE_EXPORT_AUDIT_LOG =
  'FN_COMPLIANCE_EXPORT_AUDIT_LOG' as const;
export const FN_INSIGHTS_EXPORT_ANALYTICS =
  'FN_INSIGHTS_EXPORT_ANALYTICS' as const;

/** Logging functions – `FN_LOG_SYSTEM_EVENT` is explicitly referenced in specs. */
export const FN_LOG_SYSTEM_EVENT = 'FN_LOG_SYSTEM_EVENT' as const;
export const FN_LOG_SECURITY_EVENT = 'FN_LOG_SECURITY_EVENT' as const;
export const FN_LOG_ROTATE_LOGS = 'FN_LOG_ROTATE_LOGS' as const;
export const FN_LOG_QUERY_ENTITY_ACTIVITY =
  'FN_LOG_QUERY_ENTITY_ACTIVITY' as const;

/** Validation helpers */
export const FN_CONFIG_VALIDATE_BUNDLE =
  'FN_CONFIG_VALIDATE_BUNDLE' as const;
export const FN_VALIDATE_API_PAYLOAD =
  'FN_VALIDATE_API_PAYLOAD' as const;
export const FN_METADATA_NORMALIZE = 'FN_METADATA_NORMALIZE' as const;

/* ------------------------------------------------------------------------- */
/* Aggregates & Type Helpers                                                 */
/* ------------------------------------------------------------------------- */

export const ALL_FUNCTIONAL_IDS = [
  /* Backbone */
  FN_ORG_CREATE_ORGANIZATION,
  FN_ORG_UPDATE_ORGANIZATION,
  FN_PERSON_UPSERT_PERSON_PROFILE,
  FN_RBAC_CREATE_ROLE,
  FN_RBAC_ASSIGN_PERMISSION,
  FN_RBAC_ASSIGN_USER_ROLE,
  FN_IDENTITY_LINK_USER_TO_PERSON,

  /* Signals & ingestion */
  FN_EMAIL_SEND,
  FN_EMAIL_PARSE_INCOMING,
  FN_EMAIL_VALIDATE_PAYLOAD,
  FN_EMAIL_POLL_MAILBOX,
  FN_EMAIL_ROUTE_TO_WORKFLOW,
  FN_SIGNAL_INGEST,
  FN_EMAIL_IMPORT_ARCHIVE,
  FN_SYNC_OFFLINE_NODE,
  FN_SYNC_OFFLINE_TASKS,

  /* Core: Cases, Tasks, Workflow, Labels */
  FN_CASE_CREATE_FROM_SIGNAL,
  FN_CASE_CREATE,
  FN_CASE_GET_WITH_TASKS,
  FN_CASE_RUN_CYCLIC_REVIEW,
  FN_TASK_CREATE,
  FN_TASK_UPDATE_STATUS,
  FN_TASK_ESCALATE,
  FN_TASK_ASSIGN,
  FN_TASK_ADD_COMMENT,
  FN_TASK_GET_BY_ID,
  FN_WORKFLOW_EXECUTE,
  FN_WORKFLOW_VALIDATE_RULES,
  FN_WORKFLOW_SIMULATE,
  FN_ESCALATION_EVALUATE,
  FN_LABEL_RESOLVE,
  FN_ROUTING_APPLY_RULES,
  FN_LABEL_CREATE_DEFINITION,
  FN_LABEL_APPLY_TO_ENTITY,

  /* Config, profiles & feature flags */
  FN_PROFILE_LOAD,
  FN_PROFILE_APPLY_DEFAULTS,
  FN_PROFILE_PREVIEW_DIFF,
  FN_CONFIG_GET_GLOBAL,
  FN_CONFIG_UPDATE_SERVICE_CONFIG,
  FN_CONFIG_IMPORT_BUNDLE,
  FN_FEATURE_FLAG_SET,
  FN_FEATURE_FLAG_EVALUATE,

  /* Interfaces */
  FN_API_LIST_TASKS,
  FN_API_GET_TASK,
  FN_API_CREATE_TASK,
  FN_API_UPDATE_TASK_STATUS,
  FN_API_LIST_CASES,
  FN_API_GET_CASE,
  FN_API_EXECUTE_WORKFLOW,
  FN_UI_ADMIN_TASK_OVERVIEW,
  FN_UI_ADMIN_CASE_OVERVIEW,
  FN_UI_ORG_PROFILE_SETTINGS,
  FN_NOTIFICATION_SEND_IN_APP,
  FN_NOTIFICATION_SEND_EMAIL,
  FN_GATEWAY_TASK_EVENTS_STREAM,

  /* Domain modules */
  FN_DOMAIN_MAINTENANCE_REGISTER_INCIDENT,
  FN_DOMAIN_MAINTENANCE_LIST_INCIDENTS,
  FN_DOMAIN_HR_REGISTER_REPORT,
  FN_DOMAIN_HR_LIST_CASES,
  FN_DOMAIN_EDUCATION_REGISTER_STUDENT_INCIDENT,
  FN_DOMAIN_EDUCATION_LIST_INCIDENTS,
  FN_DOMAIN_TASK_FACTORY_CREATE,
  FN_DOMAIN_WORKFLOW_APPLY_OVERRIDES,

  /* Insights & analytics */
  FN_REPORTS_GET_TASK_VOLUME,
  FN_REPORTS_GET_SLA_BREACHES,
  FN_REPORTS_GET_PROFILE_SCORE,
  FN_ANALYTICS_EXPORT_FACTS,
  FN_ANALYTICS_REFRESH_MATERIALIZED_VIEWS,
  FN_INSIGHTS_RUN_WEEKLY_PATTERNS,
  FN_INSIGHTS_RUN_MONTHLY_TRENDS,
  FN_INSIGHTS_RUN_YEARLY_SYSTEMIC_REVIEW,
  FN_INSIGHTS_CACHE_WARM_DASHBOARDS,
  FN_INSIGHTS_EXPORT_ANALYTICS,

  /* Infra, health, metrics, alerts */
  FN_HEALTH_GET,
  FN_WORKER_HEARTBEAT,
  FN_METRICS_RECORD_WORKFLOW_LATENCY,
  FN_METRICS_RECORD_QUEUE_DEPTH,
  FN_ALERT_ESCALATION_DELAY,
  FN_ALERT_ERROR_RATE,

  /* Security, privacy, compliance, logging */
  FN_AUTH_VALIDATE_ACCESS_TOKEN,
  FN_RBAC_CHECK_PERMISSION,
  FN_PRIVACY_ANONYMIZE_PAYLOAD,
  FN_AUDIT_RECORD_EVENT,
  FN_COMPLIANCE_EXPORT_AUDIT_LOG,
  FN_LOG_SYSTEM_EVENT,
  FN_LOG_SECURITY_EVENT,
  FN_LOG_ROTATE_LOGS,
  FN_LOG_QUERY_ENTITY_ACTIVITY,
  FN_CONFIG_VALIDATE_BUNDLE,
  FN_VALIDATE_API_PAYLOAD,
  FN_METADATA_NORMALIZE,
] as const;

/**
 * Union type of all known functional IDs.
 */
export type FunctionalId = (typeof ALL_FUNCTIONAL_IDS)[number];

/**
 * Type guard to validate whether a string is a known FunctionalId.
 */
export function isFunctionalId(value: string): value is FunctionalId {
  return (ALL_FUNCTIONAL_IDS as readonly string[]).includes(value);
}


=== FILE 17/48: apps/api/src/orgo/core/health/health.controller.ts ===

import { Controller, Get } from '@nestjs/common';
import { HealthService } from './health.service';

type HealthComponentState = 'up' | 'down' | 'degraded';
type HealthOverallStatus = 'ok' | 'degraded' | 'error';

export interface HealthComponentSnapshot {
  state: HealthComponentState;
  latencyMs?: number;
  error?: string;
  details?: Record<string, unknown>;
}

export interface HealthSnapshot {
  /**
   * Overall status of the Orgo backend.
   * - "ok"       → all core components are healthy
   * - "degraded" → at least one component is degraded but core is still functioning
   * - "error"    → at least one critical component is down
   */
  status: HealthOverallStatus;

  /**
   * Environment identifier ("dev" | "staging" | "prod" | "offline").
   */
  environment: string;

  /**
   * Optional version string for the running API (e.g. "3.0.1").
   */
  version?: string;

  /**
   * ISO 8601 timestamp (UTC) for when this snapshot was generated.
   */
  timestamp: string;

  /**
   * Component-level snapshots for the main dependencies.
   * Keys are stable identifiers that ops / monitoring can rely on.
   */
  components: {
    /**
     * Primary database / persistence layer.
     */
    database: HealthComponentSnapshot;

    /**
     * Task / background queues and workers.
     */
    queues: HealthComponentSnapshot;

    /**
     * Config loader and config validation status.
     */
    configLoader: HealthComponentSnapshot;

    /**
     * Domain modules discovery and basic self-checks.
     */
    domainModules: HealthComponentSnapshot;

    /**
     * Insights / analytics slice (warehouse + ETL).
     */
    insights: HealthComponentSnapshot;

    /**
     * Optional additional components (caches, external APIs, etc.).
     */
    [key: string]: HealthComponentSnapshot;
  };
}

export interface HealthError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Standard result shape for API responses that can fail synchronously.
 */
export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: HealthError | null;
}

@Controller('health')
export class HealthController {
  constructor(private readonly healthService: HealthService) {}

  /**
   * GET /api/v3/health
   *
   * Returns an aggregated health snapshot for core Orgo dependencies:
   * - database
   * - queues
   * - config loader
   * - domain modules
   * - insights / analytics slice
   *
   * The HTTP status code is always 200; callers should inspect the payload:
   * - result.ok          → whether the health check itself ran successfully
   * - result.data.status → "ok" | "degraded" | "error" (overall system health)
   */
  @Get()
  async getHealth(): Promise<StandardResult<HealthSnapshot>> {
    try {
      const snapshot = await this.healthService.checkHealth();

      return {
        ok: true,
        data: snapshot,
        error: null,
      };
    } catch (err: unknown) {
      const error: HealthError =
        err instanceof Error
          ? {
              code: 'HEALTH_CHECK_FAILED',
              message: err.message,
              details: {
                name: err.name,
              },
            }
          : {
              code: 'HEALTH_CHECK_FAILED',
              message: 'Unknown error during health check',
              details: {
                error: String(err),
              },
            };

      return {
        ok: false,
        data: null,
        error,
      };
    }
  }
}


=== FILE 18/48: apps/api/src/orgo/core/health/worker-health.service.ts ===

import { Injectable } from '@nestjs/common';
import { LogService } from '../logging/log.service';
import { FN_LOG_SYSTEM_EVENT } from '../functional-ids';

export type WorkerHealthStatus = 'healthy' | 'degraded' | 'unhealthy';

export interface WorkerQueueHeartbeat {
  name: string;
  activeJobs?: number;
  waitingJobs?: number;
  delayedJobs?: number;
  failedJobs?: number;
  /**
   * Queue lag in seconds (e.g. oldest waiting job age or schedule delay).
   */
  lagSeconds?: number | null;
  lastJobStartedAt?: string | Date | null;
  lastJobCompletedAt?: string | Date | null;
}

export interface WorkerHeartbeatPayload {
  /**
   * Stable worker identifier (pod name, instance id, etc.).
   */
  workerId: string;

  /**
   * Logical service / component id (`task_handler`, `email_gateway`, `insights_etl_worker`, etc.).
   * Should align with service identifiers from core services (`task_handler`, `email_gateway`, ...).
   */
  serviceId: string;

  /**
   * Environment, expected to match ENVIRONMENT enum (`dev` | `staging` | `prod` | `offline`).
   * If omitted, defaults from ORGO_ENVIRONMENT or `dev`.
   */
  environment?: string;

  /**
   * Hostname or node identifier.
   */
  hostname?: string;

  /**
   * OS process id, if applicable.
   */
  pid?: number;

  /**
   * When this worker instance started.
   */
  startedAt?: string | Date;

  /**
   * When this heartbeat was emitted. If omitted, "now" is assumed.
   */
  timestamp?: string | Date;

  /**
   * Per-queue metrics (email, workflow, task, etc.).
   */
  queues?: WorkerQueueHeartbeat[];

  /**
   * Optional numeric metrics for dashboards (CPU %, memory MB, etc.).
   */
  metrics?: Record<string, number>;

  /**
   * Free-form metadata for ops dashboards (labels, node role, region, etc.).
   */
  metadata?: Record<string, unknown>;
}

export interface WorkerHeartbeatAnomaly {
  type: 'HIGH_QUEUE_LAG' | 'HIGH_FAILED_JOBS';
  queueName?: string;
  severity: 'warning' | 'critical';
  message: string;
  details?: Record<string, unknown>;
}

export interface WorkerHeartbeatResult {
  workerId: string;
  serviceId: string;
  environment: string;
  status: WorkerHealthStatus;
  timestamp: string;
  anomalies: WorkerHeartbeatAnomaly[];
}

export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: { code: string; message: string; details?: Record<string, unknown> } | null;
}

@Injectable()
export class WorkerHealthService {
  private readonly maxLagSeconds: number;
  private readonly maxFailedJobs: number;

  constructor(private readonly logService: LogService) {
    // Basic, environment-driven thresholds for anomaly detection.
    this.maxLagSeconds = this.parsePositiveInt(
      process.env.ORGO_WORKER_MAX_LAG_SECONDS,
      300, // 5 minutes
    );
    this.maxFailedJobs = this.parsePositiveInt(
      process.env.ORGO_WORKER_MAX_FAILED_JOBS,
      10,
    );
  }

  /**
   * Core entry point for the `orgo.worker.heartbeat` job.
   *
   * Records a heartbeat for a worker instance, performs simple anomaly
   * detection on queue metrics, and logs the result as a SYSTEM-level event
   * for ops dashboards and observability pipelines.
   */
  async heartbeat(
    payload: WorkerHeartbeatPayload,
  ): Promise<StandardResult<WorkerHeartbeatResult>> {
    if (!payload || !payload.workerId || !payload.serviceId) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'WORKER_HEARTBEAT_INVALID_PAYLOAD',
          message: 'workerId and serviceId are required for worker heartbeat.',
          details: { payload },
        },
      };
    }

    const environment =
      payload.environment ||
      process.env.ORGO_ENVIRONMENT ||
      process.env.NODE_ENV ||
      'dev';

    const now = this.normaliseDate(payload.timestamp) ?? new Date();

    const anomalies = this.detectAnomalies(payload);
    const status = this.deriveStatus(anomalies);

    const result: WorkerHeartbeatResult = {
      workerId: payload.workerId,
      serviceId: payload.serviceId,
      environment,
      status,
      timestamp: now.toISOString(),
      anomalies,
    };

    const logLevel = this.chooseLogLevel(anomalies);

    try {
      await this.logService.logEvent({
        category: 'SYSTEM',
        logLevel,
        message: `Worker heartbeat (${payload.serviceId}/${payload.workerId}) – ${status.toUpperCase()}`,
        identifier: `worker:${payload.serviceId}/${payload.workerId}`,
        metadata: {
          functionId: FN_LOG_SYSTEM_EVENT,
          job: 'orgo.worker.heartbeat',
          status,
          environment,
          heartbeat: {
            ...payload,
            timestamp: result.timestamp,
          },
          anomalies,
          thresholds: {
            maxLagSeconds: this.maxLagSeconds,
            maxFailedJobs: this.maxFailedJobs,
          },
        },
      });

      return {
        ok: true,
        data: result,
        error: null,
      };
    } catch (err: any) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'WORKER_HEARTBEAT_LOG_FAILED',
          message: 'Failed to record worker heartbeat log event.',
          details: {
            error: err?.message ?? String(err),
            workerId: payload.workerId,
            serviceId: payload.serviceId,
          },
        },
      };
    }
  }

  /**
   * Inspects queue metrics to detect simple anomalies suitable for ops dashboards.
   */
  private detectAnomalies(payload: WorkerHeartbeatPayload): WorkerHeartbeatAnomaly[] {
    const anomalies: WorkerHeartbeatAnomaly[] = [];

    if (!payload.queues || payload.queues.length === 0) {
      return anomalies;
    }

    for (const queue of payload.queues) {
      const queueName = queue.name;

      if (queue.lagSeconds != null && queue.lagSeconds > this.maxLagSeconds) {
        const severity: 'warning' | 'critical' =
          queue.lagSeconds > this.maxLagSeconds * 2 ? 'critical' : 'warning';

        anomalies.push({
          type: 'HIGH_QUEUE_LAG',
          queueName,
          severity,
          message: `Queue "${queueName}" lag (${queue.lagSeconds}s) exceeds threshold (${this.maxLagSeconds}s).`,
          details: {
            lagSeconds: queue.lagSeconds,
            thresholdSeconds: this.maxLagSeconds,
            activeJobs: queue.activeJobs,
            waitingJobs: queue.waitingJobs,
            delayedJobs: queue.delayedJobs,
          },
        });
      }

      if (typeof queue.failedJobs === 'number' && queue.failedJobs > this.maxFailedJobs) {
        const severity: 'warning' | 'critical' =
          queue.failedJobs > this.maxFailedJobs * 2 ? 'critical' : 'warning';

        anomalies.push({
          type: 'HIGH_FAILED_JOBS',
          queueName,
          severity,
          message: `Queue "${queueName}" failed jobs (${queue.failedJobs}) exceeds threshold (${this.maxFailedJobs}).`,
          details: {
            failedJobs: queue.failedJobs,
            thresholdFailedJobs: this.maxFailedJobs,
            activeJobs: queue.activeJobs,
            waitingJobs: queue.waitingJobs,
          },
        });
      }
    }

    return anomalies;
  }

  private deriveStatus(anomalies: WorkerHeartbeatAnomaly[]): WorkerHealthStatus {
    if (anomalies.length === 0) {
      return 'healthy';
    }

    const hasCritical = anomalies.some((a) => a.severity === 'critical');
    if (hasCritical) {
      return 'unhealthy';
    }

    return 'degraded';
  }

  private chooseLogLevel(anomalies: WorkerHeartbeatAnomaly[]): 'DEBUG' | 'INFO' | 'WARNING' | 'ERROR' | 'CRITICAL' {
    if (anomalies.length === 0) {
      return 'INFO';
    }

    const hasCritical = anomalies.some((a) => a.severity === 'critical');
    return hasCritical ? 'ERROR' : 'WARNING';
  }

  private normaliseDate(value?: string | Date): Date | null {
    if (!value) {
      return null;
    }

    if (value instanceof Date) {
      return value;
    }

    const parsed = new Date(value);
    return Number.isNaN(parsed.getTime()) ? null : parsed;
  }

  private parsePositiveInt(raw: string | undefined, fallback: number): number {
    if (!raw) {
      return fallback;
    }

    const parsed = Number.parseInt(raw, 10);
    if (!Number.isFinite(parsed) || parsed <= 0) {
      return fallback;
    }

    return parsed;
  }
}


=== FILE 19/48: apps/api/src/orgo/core/labels/label-routing.service.ts ===

import { Injectable } from '@nestjs/common';

/**
 * Domain-level representation of a canonical Orgo label:
 *   <BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE?>
 */
export interface LabelParts {
  /** Vertical base (hierarchy level), e.g. 1, 11, 101, 1001. */
  base: number;
  /** Information category digit (1–9). */
  categoryDigit: number;
  /** Intent / subcategory digit (1–5). */
  subcategoryDigit: number;
  /** Optional horizontal role, e.g. "Ops.Maintenance". */
  horizontalRole?: string | null;
}

/**
 * Global Task.category values (Doc 3 / Doc 8).
 */
export type TaskCategory =
  | 'request'
  | 'incident'
  | 'update'
  | 'report'
  | 'distribution';

/**
 * Task severity enum (Doc 2).
 */
export type TaskSeverity = 'MINOR' | 'MODERATE' | 'MAJOR' | 'CRITICAL';

export interface ResolveLabelOptions {
  /**
   * Explicit label string to validate and normalize. When present, this
   * takes precedence over all other hint fields.
   */
  label?: string;

  /**
   * Optional organization identifier for future org‑specific routing.
   * Not used directly yet, but included so the contract remains stable
   * when org‑specific rules are introduced.
   */
  organizationId?: string;

  /**
   * When no explicit label is provided, these fields are used (together
   * with task hints) to construct a canonical label.
   */
  verticalBase?: number;
  infoCategoryDigit?: number;
  infoSubcategoryDigit?: number;
  horizontalRole?: string;

  /**
   * Task‑level hints used when deriving label parts.
   */
  taskType?: string;
  taskCategory?: TaskCategory;
  severity?: TaskSeverity;
}

export interface ResolvedLabelRouting {
  /**
   * Canonical label in the "<BASE>.<CATEGORY><SUBCATEGORY>[.<ROLE>]" form.
   */
  label: string;

  /**
   * Parsed structure of the canonical label.
   */
  parts: LabelParts;

  /**
   * Denormalised role label that can be written to `tasks.assignee_role`.
   * By default this is the horizontalRole part of the label, if present.
   */
  assigneeRole: string | null;

  /**
   * True when the base is one of the reserved broadcast bases (10, 100, 1000).
   */
  isBroadcast: boolean;
}

/**
 * Thrown when a label is syntactically invalid or violates the canonical
 * constraints (digit ranges).
 */
export class InvalidLabelException extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'InvalidLabelException';
  }
}

@Injectable()
export class LabelRoutingService {
  /**
   * Matches labels of the form:
   *   "<BASE>.<CATEGORY><SUBCATEGORY>[.<HORIZONTAL_ROLE>]"
   *
   * Examples:
   *   "100.94.Operations.Safety"
   *   "11.11"
   */
  private readonly labelRegex = /^(\d+)\.(\d)(\d)(?:\.(.+))?$/;

  /**
   * Parse a canonical label string into its parts.
   *
   * Throws InvalidLabelException when the label does not conform to the
   * expected shape or digit ranges.
   */
  parseLabel(label: string): LabelParts {
    if (!label || !label.trim()) {
      throw new InvalidLabelException('Label must be a non-empty string');
    }

    const trimmed = label.trim();
    const match = this.labelRegex.exec(trimmed);

    if (!match) {
      throw new InvalidLabelException(
        `Label "${label}" is not in the canonical "<BASE>.<CATEGORY><SUBCATEGORY>[.<ROLE>]" format`,
      );
    }

    const base = Number(match[1]);
    const categoryDigit = Number(match[2]);
    const subcategoryDigit = Number(match[3]);
    const horizontalRole = match[4]?.trim() || null;

    this.assertBase(base);
    this.assertCategoryDigit(categoryDigit);
    this.assertSubcategoryDigit(subcategoryDigit);

    return {
      base,
      categoryDigit,
      subcategoryDigit,
      horizontalRole,
    };
  }

  /**
   * Format label parts into a canonical label string.
   *
   * Validation is applied to ensure base/category/subcategory are within
   * the allowed ranges. Horizontal role is optional.
   */
  formatLabel(parts: LabelParts): string {
    const { base, categoryDigit, subcategoryDigit } = parts;

    this.assertBase(base);
    this.assertCategoryDigit(categoryDigit);
    this.assertSubcategoryDigit(subcategoryDigit);

    const role = parts.horizontalRole?.trim();
    let label = `${base}.${categoryDigit}${subcategoryDigit}`;

    if (role) {
      label += `.${role}`;
    }

    return label;
  }

  /**
   * Resolve a canonical label and basic routing hints for a task or case.
   *
   * If `options.label` is provided, it is validated and normalized and all
   * other hints are ignored. Otherwise, the label is constructed from the
   * provided hints and reasonable defaults.
   */
  resolveLabel(options: ResolveLabelOptions): ResolvedLabelRouting {
    if (options.label) {
      const parts = this.parseLabel(options.label);
      const normalized = this.formatLabel(parts);

      return {
        label: normalized,
        parts,
        assigneeRole: parts.horizontalRole ?? null,
        isBroadcast: this.isBroadcastBase(parts.base),
      };
    }

    const severity: TaskSeverity = options.severity ?? 'MODERATE';
    const taskCategory: TaskCategory | undefined = options.taskCategory;

    const base =
      options.verticalBase ?? this.deriveBaseFromSeverity(severity);
    const categoryDigit =
      options.infoCategoryDigit ??
      this.deriveCategoryDigitFromTaskCategory(taskCategory);
    const subcategoryDigit =
      options.infoSubcategoryDigit ??
      this.deriveSubcategoryDigitFromTaskCategory(taskCategory);
    const horizontalRole =
      options.horizontalRole ?? this.deriveHorizontalRole(options.taskType);

    const parts: LabelParts = {
      base,
      categoryDigit,
      subcategoryDigit,
      horizontalRole,
    };

    const label = this.formatLabel(parts);

    return {
      label,
      parts,
      assigneeRole: horizontalRole ?? null,
      isBroadcast: this.isBroadcastBase(base),
    };
  }

  /**
   * Convenience helper that returns true when a label uses one of the
   * reserved broadcast bases (10, 100, 1000).
   */
  isBroadcastLabel(label: string): boolean {
    const parts = this.parseLabel(label);
    return this.isBroadcastBase(parts.base);
  }

  /**
   * Reserved broadcast bases are informational by default and must be
   * handled specially by higher‑level workflow/routing logic.
   */
  isBroadcastBase(base: number): boolean {
    return base === 10 || base === 100 || base === 1000;
  }

  /**
   * Derive a vertical base from severity, based on the examples in the spec:
   *
   *   1    – CEO level
   *   2    – C‑level
   *   11   – department head
   *   101  – team lead
   *   1001 – individual staff member
   *
   * Broadcast bases (10 / 100 / 1000) are intentionally not used here;
   * those must be assigned explicitly when the intent is to broadcast.
   */
  private deriveBaseFromSeverity(severity: TaskSeverity): number {
    switch (severity) {
      case 'CRITICAL':
        return 1;
      case 'MAJOR':
        return 11;
      case 'MODERATE':
        return 101;
      case 'MINOR':
      default:
        return 1001;
    }
  }

  /**
   * Map a Task.category to the information category digit (1–9).
   *
   * See Doc 8 §8.3.3 for semantics:
   *   1 – Operational information
   *   3 – Compliance & reporting
   *   6 – Communication & coordination
   *   9 – Crisis & emergency information
   */
  private deriveCategoryDigitFromTaskCategory(
    category?: TaskCategory,
  ): number {
    switch (category) {
      case 'incident':
        // Incidents are usually crisis / emergency.
        return 9;
      case 'update':
      case 'distribution':
        // Communication / coordination.
        return 6;
      case 'report':
        // Structured reports / compliance.
        return 3;
      case 'request':
      default:
        // Default: operational information.
        return 1;
    }
  }

  /**
   * Map a Task.category to the intent/subcategory digit (1–5) as in Doc 8 §8.3.4:
   *
   *   1 – Requests
   *   2 – Updates
   *   3 – Decisions
   *   4 – Reports
   *   5 – Distribution
   */
  private deriveSubcategoryDigitFromTaskCategory(
    category?: TaskCategory,
  ): number {
    switch (category) {
      case 'request':
        return 1;
      case 'update':
        return 2;
      case 'distribution':
        return 5;
      case 'incident':
      case 'report':
        // Incident flows usually surface as reports.
        return 4;
      default:
        return 1;
    }
  }

  /**
   * Derive a horizontal role string (functional axis) from a Task.type /
   * domain identifier.
   *
   * Domain modules can still supply a more specific horizontalRole via
   * ResolveLabelOptions when needed.
   */
  private deriveHorizontalRole(taskType?: string): string | undefined {
    switch (taskType) {
      case 'maintenance':
        return 'Ops.Maintenance';
      case 'hr_case':
      case 'hr':
        return 'HR.CaseManagement';
      case 'education_support':
      case 'education':
        return 'Education.Support';
      case 'it_support':
      case 'it':
        return 'IT.Support';
      case 'operations':
        return 'Ops.General';
      case 'generic':
        return 'Operations.General';
      default:
        return undefined;
    }
  }

  private assertBase(base: number): void {
    if (!Number.isInteger(base) || base <= 0) {
      throw new InvalidLabelException(
        `Label base must be a positive integer, got "${base}"`,
      );
    }
  }

  private assertCategoryDigit(categoryDigit: number): void {
    if (
      !Number.isInteger(categoryDigit) ||
      categoryDigit < 1 ||
      categoryDigit > 9
    ) {
      throw new InvalidLabelException(
        `Label category digit must be between 1 and 9, got "${categoryDigit}"`,
      );
    }
  }

  private assertSubcategoryDigit(subcategoryDigit: number): void {
    if (
      !Number.isInteger(subcategoryDigit) ||
      subcategoryDigit < 1 ||
      subcategoryDigit > 5
    ) {
      throw new InvalidLabelException(
        `Label subcategory digit must be between 1 and 5, got "${subcategoryDigit}"`,
      );
    }
  }
}


=== FILE 20/48: apps/api/src/orgo/core/labels/label.service.ts ===

import {
  BadRequestException,
  ConflictException,
  Injectable,
  NotFoundException,
} from '@nestjs/common';
import { Prisma, PrismaClient, LabelDefinition, EntityLabel } from '@prisma/client';
import { PrismaService } from '../../../persistence/prisma/prisma.service';

export interface CreateLabelDefinitionInput {
  /**
   * Owning organization. Omit or set to null for a global label.
   */
  organizationId?: string | null;
  /**
   * Stable machine-readable code, unique per org/global.
   * Examples: "self_harm_risk", "equipment_failure".
   */
  code: string;
  /**
   * Human-friendly name for the label.
   */
  displayName: string;
  /**
   * Description for admins / reviewers.
   */
  description: string;
  /**
   * High-level classification bucket.
   * Examples: "risk", "topic", "visibility".
   */
  category: string;
  /**
   * Optional color hint for UI (hex or named color).
   */
  colorHint?: string | null;
}

export interface UpdateLabelDefinitionInput {
  displayName?: string;
  description?: string;
  category?: string;
  colorHint?: string | null;
}

export interface AssignLabelToEntityInput {
  /**
   * Organization that owns the entity (tenant).
   */
  organizationId: string;
  /**
   * Classification label code; resolved against org + global definitions.
   */
  labelCode: string;
  /**
   * Target entity type (e.g. "task", "person", "learning_group", "case").
   */
  entityType: string;
  /**
   * Target entity id (UUID from the corresponding table).
   */
  entityId: string;
  /**
   * Optional user who applied the label.
   */
  appliedByUserId?: string | null;
}

export interface RemoveLabelFromEntityInput {
  organizationId: string;
  labelCode: string;
  entityType: string;
  entityId: string;
}

export type EntityLabelWithDefinition = EntityLabel & {
  label: LabelDefinition;
};

/**
 * LabelService
 *
 * Manages classification label definitions (`label_definitions`) and their
 * attachments to entities (`entity_labels`), separate from the single canonical
 * information label stored on Tasks/Cases.
 */
@Injectable()
export class LabelService {
  private readonly prisma: PrismaClient;

  constructor(private readonly prismaService: PrismaService) {
    this.prisma = prismaService;
  }

  /**
   * Create a new LabelDefinition for an org or globally.
   * Enforces uniqueness of (organizationId, code).
   */
  async createLabelDefinition(
    input: CreateLabelDefinitionInput,
  ): Promise<LabelDefinition> {
    const organizationId = input.organizationId ?? null;

    if (!input.code?.trim()) {
      throw new BadRequestException('Label code must be a non-empty string.');
    }
    if (!input.displayName?.trim()) {
      throw new BadRequestException('Label displayName must be a non-empty string.');
    }
    if (!input.description?.trim()) {
      throw new BadRequestException('Label description must be a non-empty string.');
    }
    if (!input.category?.trim()) {
      throw new BadRequestException('Label category must be a non-empty string.');
    }

    const existing = await this.prisma.labelDefinition.findFirst({
      where: {
        code: input.code,
        organizationId,
      },
    });

    if (existing) {
      throw new ConflictException(
        `LabelDefinition with code "${input.code}" already exists for this scope.`,
      );
    }

    try {
      return await this.prisma.labelDefinition.create({
        data: {
          organizationId,
          code: input.code,
          displayName: input.displayName,
          description: input.description,
          category: input.category,
          colorHint: input.colorHint ?? null,
        },
      });
    } catch (error) {
      if (
        error instanceof Prisma.PrismaClientKnownRequestError &&
        error.code === 'P2002'
      ) {
        // Unique constraint violation (e.g. on organizationId + code)
        throw new ConflictException(
          `LabelDefinition with code "${input.code}" already exists.`,
        );
      }
      throw error;
    }
  }

  /**
   * Update an existing LabelDefinition by id, scoped to an org (or global).
   */
  async updateLabelDefinition(
    id: string,
    organizationId: string | null,
    updates: UpdateLabelDefinitionInput,
  ): Promise<LabelDefinition> {
    const normalizedOrgId = organizationId ?? null;

    const label = await this.prisma.labelDefinition.findFirst({
      where: { id, organizationId: normalizedOrgId },
    });

    if (!label) {
      throw new NotFoundException(
        `LabelDefinition "${id}" not found for the specified organization scope.`,
      );
    }

    if (
      updates.displayName !== undefined &&
      !updates.displayName.trim()
    ) {
      throw new BadRequestException('displayName, if provided, must be non-empty.');
    }
    if (
      updates.description !== undefined &&
      !updates.description.trim()
    ) {
      throw new BadRequestException('description, if provided, must be non-empty.');
    }
    if (
      updates.category !== undefined &&
      !updates.category.trim()
    ) {
      throw new BadRequestException('category, if provided, must be non-empty.');
    }

    return this.prisma.labelDefinition.update({
      where: { id: label.id },
      data: {
        displayName: updates.displayName ?? label.displayName,
        description: updates.description ?? label.description,
        category: updates.category ?? label.category,
        colorHint:
          updates.colorHint !== undefined ? updates.colorHint : label.colorHint,
      },
    });
  }

  /**
   * Delete a LabelDefinition by id, scoped to an org (or global).
   *
   * Note: DB-level foreign keys decide whether delete cascades or fails if
   * EntityLabels still reference this label.
   */
  async deleteLabelDefinition(
    id: string,
    organizationId: string | null,
  ): Promise<void> {
    const normalizedOrgId = organizationId ?? null;

    const label = await this.prisma.labelDefinition.findFirst({
      where: { id, organizationId: normalizedOrgId },
    });

    if (!label) {
      throw new NotFoundException(
        `LabelDefinition "${id}" not found for the specified organization scope.`,
      );
    }

    await this.prisma.labelDefinition.delete({
      where: { id: label.id },
    });
  }

  /**
   * Return LabelDefinitions visible to an org:
   *   - Global labels (organizationId = null)
   *   - Org-specific labels (organizationId = <org>)
   * If the same code exists in both scopes, the org-specific one wins.
   */
  async getLabelDefinitionsForOrg(
    organizationId: string,
  ): Promise<LabelDefinition[]> {
    const [globalLabels, orgLabels] = await Promise.all([
      this.prisma.labelDefinition.findMany({
        where: { organizationId: null },
      }),
      this.prisma.labelDefinition.findMany({
        where: { organizationId },
      }),
    ]);

    const byCode = new Map<string, LabelDefinition>();

    for (const label of globalLabels) {
      byCode.set(label.code, label);
    }
    for (const label of orgLabels) {
      // Org-specific overrides global
      byCode.set(label.code, label);
    }

    return Array.from(byCode.values()).sort((a, b) =>
      a.code.localeCompare(b.code),
    );
  }

  /**
   * Resolve a LabelDefinition by code for a given org, with fallback to global.
   * Org-specific definitions override global ones when codes clash.
   */
  async getLabelDefinitionByCode(
    organizationId: string,
    code: string,
  ): Promise<LabelDefinition> {
    if (!code?.trim()) {
      throw new BadRequestException('Label code must be a non-empty string.');
    }

    const [orgSpecific, global] = await Promise.all([
      this.prisma.labelDefinition.findFirst({
        where: {
          organizationId,
          code,
        },
      }),
      this.prisma.labelDefinition.findFirst({
        where: {
          organizationId: null,
          code,
        },
      }),
    ]);

    const label = orgSpecific ?? global;

    if (!label) {
      throw new NotFoundException(
        `LabelDefinition with code "${code}" not found for organization or global scope.`,
      );
    }

    return label;
  }

  /**
   * Attach a classification label (by code) to an entity.
   * Respects org + global label definitions.
   */
  async assignLabelToEntity(
    input: AssignLabelToEntityInput,
  ): Promise<EntityLabel> {
    if (!input.entityType?.trim()) {
      throw new BadRequestException('entityType must be a non-empty string.');
    }
    if (!input.entityId?.trim()) {
      throw new BadRequestException('entityId must be a non-empty string.');
    }

    const label = await this.getLabelDefinitionByCode(
      input.organizationId,
      input.labelCode,
    );

    // Avoid duplicate attachments for the same (org, entity, label)
    const existing = await this.prisma.entityLabel.findFirst({
      where: {
        organizationId: input.organizationId,
        entityType: input.entityType,
        entityId: input.entityId,
        labelId: label.id,
      },
    });

    if (existing) {
      return existing;
    }

    return this.prisma.entityLabel.create({
      data: {
        organizationId: input.organizationId,
        labelId: label.id,
        entityType: input.entityType,
        entityId: input.entityId,
        appliedByUserId: input.appliedByUserId ?? null,
      },
    });
  }

  /**
   * Remove a classification label (by code) from an entity.
   * Returns the number of removed rows.
   */
  async removeLabelFromEntity(
    input: RemoveLabelFromEntityInput,
  ): Promise<number> {
    const label = await this.getLabelDefinitionByCode(
      input.organizationId,
      input.labelCode,
    );

    const result = await this.prisma.entityLabel.deleteMany({
      where: {
        organizationId: input.organizationId,
        entityType: input.entityType,
        entityId: input.entityId,
        labelId: label.id,
      },
    });

    if (result.count === 0) {
      throw new NotFoundException(
        `EntityLabel not found for entity "${input.entityType}:${input.entityId}" and label code "${input.labelCode}".`,
      );
    }

    return result.count;
  }

  /**
   * List all EntityLabels (with resolved LabelDefinition) for a given entity.
   */
  async getLabelsForEntity(
    organizationId: string,
    entityType: string,
    entityId: string,
  ): Promise<EntityLabelWithDefinition[]> {
    if (!entityType?.trim()) {
      throw new BadRequestException('entityType must be a non-empty string.');
    }
    if (!entityId?.trim()) {
      throw new BadRequestException('entityId must be a non-empty string.');
    }

    return this.prisma.entityLabel.findMany({
      where: {
        organizationId,
        entityType,
        entityId,
      },
      include: {
        label: true,
      },
    }) as Promise<EntityLabelWithDefinition[]>;
  }
}


=== FILE 21/48: apps/api/src/orgo/core/labels/labels.module.ts ===

import { Module } from '@nestjs/common';
import { PersistenceModule } from '../../../persistence/persistence.module';
import { LabelService } from './label.service';
import { LabelRoutingService } from './label-routing.service';
import { RoutingRuleService } from './routing-rule.service';

@Module({
  imports: [PersistenceModule],
  providers: [LabelService, LabelRoutingService, RoutingRuleService],
  exports: [LabelService, LabelRoutingService, RoutingRuleService],
})
export class LabelsModule {}


=== FILE 22/48: apps/api/src/orgo/core/labels/routing-rule.service.ts ===

import { Injectable } from '@nestjs/common';
import { PrismaService } from '../../../persistence/prisma/prisma.service';
import { LogService } from '../logging/log.service';

export type TaskCategory =
  | 'request'
  | 'incident'
  | 'update'
  | 'report'
  | 'distribution';

export type TaskPriority = 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';

const PRIORITY_ORDER: TaskPriority[] = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'];

export interface OrgoError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: OrgoError | null;
}

export interface ApplyRoutingRulesInput {
  /**
   * Tenant / organization that owns the task or signal.
   */
  organizationId: string;

  /**
   * Domain-level task type (maintenance, hr_case, it_support, etc.).
   */
  taskType?: string | null;

  /**
   * Canonical task category (“request” | “incident” | “update” | “report” | “distribution”).
   */
  taskCategory?: string | null;

  /**
   * Task priority. May be canonical enum casing or lower-case JSON form.
   */
  priority?: string | null;

  /**
   * Classification label codes attached to the task/signal
   * (e.g. ["anonymous", "equipment_failure"]).
   */
  labelCodes?: string[];

  /**
   * Optional task identifier (for logging correlation).
   */
  taskId?: string;
}

export interface RoutingDecision {
  /**
   * Organization that owns the chosen rule (may be null for global rules).
   */
  organizationId: string | null;

  /**
   * Target role that should initially own the task, if defined by the rule.
   */
  targetRoleId: string | null;

  /**
   * Target user that should initially own the task, if defined by the rule.
   * Used sparingly; routing should primarily be role-based.
   */
  targetUserId: string | null;

  /**
   * Identifier and name of the applied rule for auditability.
   */
  ruleId: string | null;
  ruleName: string | null;

  /**
   * Whether the selected rule is marked as a fallback.
   */
  isFallback: boolean;
}

/**
 * Internal normalized view of the routing context.
 */
interface NormalizedRoutingContext {
  organizationId: string;
  taskType?: string;
  taskCategory?: TaskCategory;
  priority?: TaskPriority;
  labelCodes: string[];
  taskId?: string;
}

/**
 * Internal normalized view of a routing rule record.
 * The physical table is `routing_rules` (Doc 1).
 */
interface NormalizedRoutingRule {
  id: string;
  organizationId: string | null;
  name: string;
  taskType?: string;
  taskCategory?: TaskCategory;
  labelCodes: string[];
  priorityMin?: TaskPriority;
  targetRoleId?: string | null;
  targetUserId?: string | null;
  isFallback: boolean;
  weight: number;
}

@Injectable()
export class RoutingRuleService {
  constructor(
    private readonly prisma: PrismaService,
    private readonly logService: LogService,
  ) {}

  /**
   * Applies routing_rules for the given context and returns the chosen
   * role/user assignment, following Core Services + Doc 1/2 semantics.
   *
   * Matching semantics:
   * - organization_id: prefer org-specific rules over global (NULL).
   * - task_type: must match if rule.task_type is not NULL (case-insensitive).
   * - task_category: must match if rule.task_category is not NULL (lower-case).
   * - label_codes: all rule.label_codes must be present in context.labelCodes.
   * - priority_min: context.priority must be >= rule.priority_min.
   *
   * Selection semantics:
   * - First prefer non-fallback rules; if none match, use fallback rules.
   * - Within that set, prefer org-specific rules.
   * - Within org/global scope, pick rule with highest weight.
   * - If still tied, pick rule with lexicographically smallest id
   *   to keep behaviour deterministic.
   */
  async applyRoutingRules(
    input: ApplyRoutingRulesInput,
  ): Promise<StandardResult<RoutingDecision>> {
    const context = this.normalizeContext(input);

    try {
      const rawRules = await this.prisma.routingRule.findMany({
        where: {
          OR: [
            { organizationId: context.organizationId },
            { organizationId: null },
          ],
        },
      });

      const normalizedRules = rawRules.map((rule) =>
        this.normalizeRule(rule as any),
      );
      const matchingRules = normalizedRules.filter((rule) =>
        this.matchesRule(rule, context),
      );

      const selectedRule = this.pickBestRule(
        matchingRules,
        context.organizationId,
      );

      if (!selectedRule) {
        this.logService.logEvent({
          category: 'WORKFLOW',
          logLevel: 'WARNING',
          message: 'No routing rule matched context',
          identifier: context.taskId
            ? `task_id:${context.taskId}`
            : undefined,
          metadata: {
            organizationId: context.organizationId,
            taskType: context.taskType,
            taskCategory: context.taskCategory,
            priority: context.priority,
            labelCodes: context.labelCodes,
          },
        });

        return {
          ok: false,
          data: null,
          error: {
            code: 'ROUTING_RULE_NOT_FOUND',
            message: 'No routing rule matched the provided context.',
            details: {
              organizationId: context.organizationId,
              taskType: context.taskType,
              taskCategory: context.taskCategory,
            },
          },
        };
      }

      const decision: RoutingDecision = {
        organizationId: selectedRule.organizationId,
        targetRoleId: selectedRule.targetRoleId ?? null,
        targetUserId: selectedRule.targetUserId ?? null,
        ruleId: selectedRule.id,
        ruleName: selectedRule.name,
        isFallback: selectedRule.isFallback,
      };

      this.logService.logEvent({
        category: 'WORKFLOW',
        logLevel: 'INFO',
        message: 'Routing rule applied',
        identifier: context.taskId ? `task_id:${context.taskId}` : undefined,
        metadata: {
          organizationId: context.organizationId,
          taskType: context.taskType,
          taskCategory: context.taskCategory,
          priority: context.priority,
          labelCodes: context.labelCodes,
          ruleId: decision.ruleId,
          ruleName: decision.ruleName,
          targetRoleId: decision.targetRoleId,
          targetUserId: decision.targetUserId,
          isFallback: decision.isFallback,
        },
      });

      return {
        ok: true,
        data: decision,
        error: null,
      };
    } catch (error) {
      this.logService.logEvent({
        category: 'SYSTEM',
        logLevel: 'ERROR',
        message: 'Failed to evaluate routing rules',
        identifier: input.taskId ? `task_id:${input.taskId}` : undefined,
        metadata: {
          error:
            error instanceof Error
              ? { name: error.name, message: error.message }
              : String(error),
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'ROUTING_RULE_EVALUATION_ERROR',
          message: 'Failed to evaluate routing rules.',
          details: {},
        },
      };
    }
  }

  private normalizeContext(
    input: ApplyRoutingRulesInput,
  ): NormalizedRoutingContext {
    const labelCodes =
      input.labelCodes?.map((code) => code.trim().toLowerCase()).filter(Boolean) ??
      [];

    const taskType = input.taskType
      ? input.taskType.trim().toLowerCase()
      : undefined;

    const taskCategory = input.taskCategory
      ? (input.taskCategory.trim().toLowerCase() as TaskCategory)
      : undefined;

    const priority = this.normalizePriority(input.priority);

    return {
      organizationId: input.organizationId,
      taskType,
      taskCategory,
      priority: priority ?? undefined,
      labelCodes,
      taskId: input.taskId,
    };
  }

  private normalizeRule(rule: any): NormalizedRoutingRule {
    const labelCodes: string[] =
      (rule.labelCodes ?? rule.label_codes ?? []) as string[];

    const weightRaw: number | null | undefined =
      rule.weight !== undefined ? rule.weight : rule.weight ?? 0;

    return {
      id: String(rule.id),
      organizationId:
        (rule.organizationId ?? rule.organization_id) ?? null,
      name: rule.name,
      taskType: rule.taskType
        ? String(rule.taskType).trim().toLowerCase()
        : rule.task_type
        ? String(rule.task_type).trim().toLowerCase()
        : undefined,
      taskCategory: rule.taskCategory
        ? (String(rule.taskCategory).trim().toLowerCase() as TaskCategory)
        : rule.task_category
        ? (String(rule.task_category).trim().toLowerCase() as TaskCategory)
        : undefined,
      labelCodes: labelCodes.map((c) => c.trim().toLowerCase()).filter(Boolean),
      priorityMin: this.normalizePriority(
        rule.priorityMin ?? rule.priority_min ?? null,
      ) ?? undefined,
      targetRoleId:
        (rule.targetRoleId ?? rule.target_role_id) ?? null,
      targetUserId:
        (rule.targetUserId ?? rule.target_user_id) ?? null,
      isFallback: Boolean(rule.isFallback ?? rule.is_fallback),
      weight: typeof weightRaw === 'number' ? weightRaw : 0,
    };
  }

  private matchesRule(
    rule: NormalizedRoutingRule,
    ctx: NormalizedRoutingContext,
  ): boolean {
    if (rule.taskType && (!ctx.taskType || rule.taskType !== ctx.taskType)) {
      return false;
    }

    if (
      rule.taskCategory &&
      (!ctx.taskCategory || rule.taskCategory !== ctx.taskCategory)
    ) {
      return false;
    }

    if (rule.labelCodes.length > 0) {
      const ctxCodes = new Set(ctx.labelCodes);
      const hasAllLabels = rule.labelCodes.every((code) => ctxCodes.has(code));
      if (!hasAllLabels) {
        return false;
      }
    }

    if (rule.priorityMin) {
      if (!ctx.priority) {
        return false;
      }
      if (!this.hasRequiredPriority(ctx.priority, rule.priorityMin)) {
        return false;
      }
    }

    return true;
  }

  private pickBestRule(
    rules: NormalizedRoutingRule[],
    organizationId: string,
  ): NormalizedRoutingRule | null {
    if (rules.length === 0) {
      return null;
    }

    const nonFallback = rules.filter((r) => !r.isFallback);
    const pool = nonFallback.length > 0 ? nonFallback : rules.filter((r) => r.isFallback);

    if (pool.length === 0) {
      return null;
    }

    const orgSpecific = pool.filter((r) => r.organizationId === organizationId);
    const scopedPool = orgSpecific.length > 0 ? orgSpecific : pool;

    scopedPool.sort((a, b) => {
      if (b.weight !== a.weight) {
        return b.weight - a.weight;
      }
      return a.id.localeCompare(b.id);
    });

    return scopedPool[0] ?? null;
  }

  private normalizePriority(
    priority: string | null | undefined,
  ): TaskPriority | null {
    if (!priority) {
      return null;
    }

    const upper = priority.toString().trim().toUpperCase();

    switch (upper) {
      case 'LOW':
      case 'MEDIUM':
      case 'HIGH':
      case 'CRITICAL':
        return upper;
      default:
        return null;
    }
  }

  private hasRequiredPriority(
    contextPriority: TaskPriority,
    rulePriorityMin: TaskPriority,
  ): boolean {
    const contextIndex = PRIORITY_ORDER.indexOf(contextPriority);
    const ruleIndex = PRIORITY_ORDER.indexOf(rulePriorityMin);

    if (contextIndex === -1 || ruleIndex === -1) {
      return false;
    }

    return contextIndex >= ruleIndex;
  }
}


=== FILE 23/48: apps/api/src/orgo/core/logging/log.service.ts ===

// apps/api/src/orgo/core/logging/log.service.ts

import {
  Injectable,
  Logger as NestLogger,
  OnModuleInit,
} from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { promises as fsp } from 'fs';
import * as path from 'path';
import {
  FN_LOG_SECURITY_EVENT,
  FN_LOG_SYSTEM_EVENT,
  FunctionalId,
  isFunctionalId,
} from '../functional-ids';

/**
 * Canonical log categories (must align with Orgo LOG_CATEGORY enum).
 */
export enum LogCategory {
  WORKFLOW = 'WORKFLOW',
  TASK = 'TASK',
  SYSTEM = 'SYSTEM',
  SECURITY = 'SECURITY',
  EMAIL = 'EMAIL',
}

/**
 * Canonical log levels (must align with Orgo LOG_LEVEL enum).
 */
export enum LogLevel {
  DEBUG = 'DEBUG',
  INFO = 'INFO',
  WARNING = 'WARNING',
  ERROR = 'ERROR',
  CRITICAL = 'CRITICAL',
}

/**
 * VISIBILITY enum used for log/event classification.
 * Mirrors the VISIBILITY enum used in Tasks/Cases and privacy docs.
 */
export const LOG_VISIBILITY_VALUES = [
  'PUBLIC',
  'INTERNAL',
  'RESTRICTED',
  'ANONYMISED',
] as const;

export type LogVisibility = (typeof LOG_VISIBILITY_VALUES)[number];

/**
 * Behaviour/profile-level logging detail (Doc 7 – logging_level).
 */
export const PROFILE_LOGGING_LEVEL_VALUES = [
  'minimal',
  'standard',
  'detailed',
  'audit',
] as const;

export type ProfileLoggingLevel =
  (typeof PROFILE_LOGGING_LEVEL_VALUES)[number];

export type LogFormat = 'json' | 'text';

export interface LoggingCategoryConfig {
  /**
   * File name for this category, relative to the configured logDir.
   * Example: "workflow_activity.log"
   */
  file: string;

  /**
   * How long to keep rotated files (in days) before deleting.
   */
  retentionDays: number;

  /**
   * Rotation strategy:
   * - "daily" / "weekly": intended for scheduled rotateLogs() calls.
   * - "size": rotate when file exceeds maxFileSizeMb.
   */
  rotation: 'daily' | 'weekly' | 'size';

  /**
   * Max file size in megabytes before size-based rotation.
   */
  maxFileSizeMb: number;
}

export interface LoggingConfig {
  /**
   * Minimum level to actually emit logs (DEBUG < INFO < WARNING < ERROR < CRITICAL).
   */
  level: LogLevel;

  /**
   * Output format for log lines.
   */
  format: LogFormat;

  /**
   * Root directory where category log files are written.
   */
  logDir: string;

  /**
   * Per-category file/retention/rotation configuration.
   */
  categories: Record<LogCategory, LoggingCategoryConfig>;
}

/**
 * Logical log event shape as persisted to log files.
 *
 * This matches the Core Services spec (Doc 5 §9.3) with additional optional
 * context fields for multi-tenant and functional ID tracing.
 */
export interface StructuredLogEvent {
  timestamp: string; // ISO8601 UTC
  level: LogLevel;
  category: LogCategory;
  message: string;
  /**
   * Optional correlation identifier (e.g. "task_id:123").
   */
  identifier?: string;
  /**
   * Tenant / organization scope (maps to organizations.id).
   */
  organizationId?: string;
  /**
   * Stable functional identifier for the originating operation.
   * (e.g. FN_LOG_SYSTEM_EVENT, FN_ALERT_ESCALATION_DELAY)
   */
  functionId?: FunctionalId | string;
  /**
   * Event-level visibility classification.
   */
  visibility?: LogVisibility;
  /**
   * Arbitrary structured metadata.
   * When privacy rules require sanitisation, this may contain only a minimal,
   * non-sensitive subset of the original payload.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Input payload for logEvent.
 *
 * This is the canonical TS form of log_event(category, log_level, message, ...)
 * from Doc 5 §9.3, extended with tenant/functional/visibility context.
 */
export interface LogEventInput {
  /**
   * Category token; case-insensitive string or enum. Invalid values are normalised to SYSTEM.
   */
  category: LogCategory | string;

  /**
   * Level token; case-insensitive string or enum. "WARN" is treated as "WARNING".
   * Callers may use either `level` or `logLevel` (to mirror the spec).
   * If both are omitted, defaults to INFO.
   */
  level?: LogLevel | string;
  logLevel?: LogLevel | string;

  /**
   * Human-readable message.
   */
  message: string;

  /**
   * Optional correlation identifier (e.g. "task_id:123").
   */
  identifier?: string;

  /**
   * Arbitrary structured metadata that will be serialised into the log line.
   */
  metadata?: Record<string, unknown>;

  /**
   * Optional timestamp; if omitted, current time (in UTC) is used.
   */
  timestamp?: Date;

  /**
   * Stable functional identifier for the operation emitting this event.
   * When provided, it is normalised against FunctionalId and attached
   * as both top-level `functionId` and metadata.functionId/fn.
   */
  functionId?: FunctionalId | string;

  /**
   * Tenant / organization scope (maps to organizations.id).
   */
  organizationId?: string;

  /**
   * Optional user context for traceability. These are forwarded into metadata.
   */
  actorUserId?: string;
  actorRoleId?: string;

  /**
   * Visibility classification (PUBLIC / INTERNAL / RESTRICTED / ANONYMISED).
   * Used together with profileLoggingLevel / sanitizeMetadata to decide
   * whether to include or strip potentially sensitive metadata.
   */
  visibility?: LogVisibility | string;

  /**
   * Organization profile logging_level ("minimal" | "standard" | "detailed" | "audit")
   * if known to the caller (see profiles logging_level).
   */
  profileLoggingLevel?: ProfileLoggingLevel;

  /**
   * Force scrubbing of sensitive metadata fields regardless of profileLoggingLevel.
   * When true, only safe structural context (e.g. organizationId, functionId,
   * visibility) is retained in metadata; arbitrary payload fields are dropped.
   */
  sanitizeMetadata?: boolean;
}

/**
 * Numeric severity ranking for log levels (for threshold comparisons).
 */
const LOG_LEVEL_ORDER: Record<LogLevel, number> = {
  [LogLevel.DEBUG]: 10,
  [LogLevel.INFO]: 20,
  [LogLevel.WARNING]: 30,
  [LogLevel.ERROR]: 40,
  [LogLevel.CRITICAL]: 50,
};

/**
 * Default per-category logging configuration, aligned with the core logging spec.
 * (Doc 5 §9.2 – logging_config).
 */
const DEFAULT_CATEGORY_CONFIG: Record<LogCategory, LoggingCategoryConfig> = {
  [LogCategory.WORKFLOW]: {
    file: 'workflow_activity.log',
    retentionDays: 180,
    rotation: 'weekly',
    maxFileSizeMb: 50,
  },
  [LogCategory.TASK]: {
    file: 'task_execution.log',
    retentionDays: 365,
    rotation: 'weekly',
    maxFileSizeMb: 50,
  },
  [LogCategory.SYSTEM]: {
    file: 'system_activity.log',
    retentionDays: 180,
    rotation: 'weekly',
    maxFileSizeMb: 50,
  },
  [LogCategory.SECURITY]: {
    file: 'security_events.log',
    retentionDays: 730,
    rotation: 'weekly',
    maxFileSizeMb: 20,
  },
  [LogCategory.EMAIL]: {
    file: 'email_events.log',
    retentionDays: 180,
    rotation: 'weekly',
    maxFileSizeMb: 50,
  },
};

/**
 * Core logging service for Orgo.
 *
 * Responsibilities:
 * - Provide a single structured logEvent entry point.
 * - Enforce canonical LOG_CATEGORY / LOG_LEVEL tokens.
 * - Honour a minimum log level threshold.
 * - Write structured JSON/text lines to per-category log files.
 * - Attach functional IDs and tenant/visibility context to events.
 * - Provide helpers for security/system events and log rotation.
 */
@Injectable()
export class LogService implements OnModuleInit {
  private readonly logger = new NestLogger(LogService.name);
  private readonly config: LoggingConfig;
  private readonly minLevel: LogLevel;

  constructor(private readonly configService: ConfigService) {
    this.config = this.buildConfigFromEnv();
    this.minLevel = this.config.level;
  }

  async onModuleInit(): Promise<void> {
    await this.ensureLogDirectoryExists();
  }

  /**
   * Main entry point: write a structured log event.
   *
   * This method is intentionally "fire-and-forget" from the caller’s perspective;
   * file I/O is performed asynchronously and errors are logged to the Nest logger.
   */
  logEvent(input: LogEventInput): void {
    const category = this.normalizeCategory(input.category);
    const level = this.resolveLevel(input);

    if (!this.shouldLog(level)) {
      return;
    }

    const timestamp = (input.timestamp ?? new Date()).toISOString();
    const visibility = this.normalizeVisibilityToken(
      input.visibility as string | undefined,
    );
    const normalizedFunctionId = this.normalizeFunctionId(input.functionId);

    const metadata = this.buildSafeMetadata({
      baseMetadata: input.metadata,
      organizationId: input.organizationId,
      functionId: normalizedFunctionId,
      actorUserId: input.actorUserId,
      actorRoleId: input.actorRoleId,
      visibility,
      profileLoggingLevel: input.profileLoggingLevel,
      sanitizeMetadata: input.sanitizeMetadata,
    });

    const event: StructuredLogEvent = {
      timestamp,
      level,
      category,
      message: input.message,
      identifier: input.identifier,
      organizationId: input.organizationId,
      functionId: normalizedFunctionId,
      visibility,
      metadata,
    };

    const line =
      this.config.format === 'json'
        ? JSON.stringify(event)
        : this.formatTextLine(event);

    this.logToNest(level, line);
    void this.writeToFile(category, line);
  }

  /**
   * Convenience helper for SYSTEM-category events.
   *
   * Uses FN_LOG_SYSTEM_EVENT by default when no functionId is provided.
   */
  logSystemEvent(
    message: string,
    options: Omit<LogEventInput, 'category' | 'message'> = {},
  ): void {
    const { functionId, ...rest } = options;

    this.logEvent({
      ...rest,
      category: LogCategory.SYSTEM,
      message,
      functionId: functionId ?? FN_LOG_SYSTEM_EVENT,
    });
  }

  /**
   * Convenience helper for SECURITY-category events.
   *
   * Example usage:
   *   logSecurityEvent('User login failed', {
   *     identifier: `user_id:${id}`,
   *     organizationId,
   *     actorUserId,
   *     metadata: {...},
   *   });
   *
   * Default level is WARNING when not explicitly provided.
   * Uses FN_LOG_SECURITY_EVENT by default when no functionId is provided.
   */
  logSecurityEvent(
    message: string,
    options: Omit<LogEventInput, 'category' | 'message'> & {
      level?: LogLevel | string;
    } = {},
  ): void {
    const { level, logLevel, functionId, ...rest } = options;

    this.logEvent({
      ...rest,
      category: LogCategory.SECURITY,
      message,
      // Preserve explicit level/logLevel if provided, otherwise default WARNING.
      level: level ?? logLevel ?? LogLevel.WARNING,
      functionId: functionId ?? FN_LOG_SECURITY_EVENT,
    });
  }

  /**
   * Rotate all category log files according to their configured rotation strategy.
   *
   * This is intended to be called periodically (e.g. via a cron job).
   * - For rotation: "daily" / "weekly", the current file is always rotated on invocation.
   * - For rotation: "size", this method delegates to size-based rotation as a fallback
   *   (size-based rotation is also applied on each write).
   */
  async rotateLogs(referenceDate: Date = new Date()): Promise<void> {
    const tasks: Promise<void>[] = [];

    for (const [categoryKey, categoryConfig] of Object.entries(
      this.config.categories,
    )) {
      const category = categoryKey as LogCategory;
      tasks.push(
        this.rotateCategoryLogs(category, categoryConfig, referenceDate).catch(
          (error) => {
            this.logger.error(
              `Failed to rotate logs for category "${category}": ${
                (error as Error).message
              }`,
            );
          },
        ),
      );
    }

    await Promise.all(tasks);
  }

  // ---------------------------------------------------------------------------
  // Internal helpers
  // ---------------------------------------------------------------------------

  private buildConfigFromEnv(): LoggingConfig {
    const envLevel = this.configService.get<string>('ORGO_LOG_LEVEL');
    const envFormat = this.configService.get<string>('ORGO_LOG_FORMAT');
    const envDir = this.configService.get<string>('ORGO_LOG_DIR');

    const level =
      this.normalizeLevelToken(envLevel) ?? LogLevel.INFO; // default INFO

    const format: LogFormat =
      envFormat && envFormat.toLowerCase() === 'text' ? 'text' : 'json';

    const logDir =
      envDir && envDir.trim().length > 0
        ? path.resolve(envDir)
        : path.resolve(process.cwd(), 'logs');

    // Deep clone default category config so we can mutate per-instance safely
    const categories: Record<LogCategory, LoggingCategoryConfig> =
      {} as Record<LogCategory, LoggingCategoryConfig>;

    for (const [key, cfg] of Object.entries(DEFAULT_CATEGORY_CONFIG)) {
      const category = key as LogCategory;
      categories[category] = { ...cfg };
    }

    return {
      level,
      format,
      logDir,
      categories,
    };
  }

  private async ensureLogDirectoryExists(): Promise<void> {
    try {
      await fsp.mkdir(this.config.logDir, { recursive: true });
    } catch (error) {
      this.logger.error(
        `Failed to ensure log directory "${this.config.logDir}": ${
          (error as Error).message
        }`,
      );
    }
  }

  private normalizeLevelToken(token?: string | null): LogLevel | undefined {
    if (!token) {
      return undefined;
    }

    const upper = token.toUpperCase().trim();

    switch (upper) {
      case 'DEBUG':
        return LogLevel.DEBUG;
      case 'INFO':
        return LogLevel.INFO;
      case 'WARN':
      case 'WARNING':
        return LogLevel.WARNING;
      case 'ERROR':
        return LogLevel.ERROR;
      case 'CRITICAL':
        return LogLevel.CRITICAL;
      default:
        this.logger.warn(
          `Unknown log level token "${token}", falling back to default.`,
        );
        return undefined;
    }
  }

  /**
   * Normalise a severity value from LogEventInput.
   * Accepts both level/logLevel and defaults to INFO when neither is set.
   */
  private resolveLevel(input: LogEventInput): LogLevel {
    const candidate = input.level ?? input.logLevel ?? LogLevel.INFO;
    return this.normalizeLevel(candidate);
  }

  private normalizeLevel(level: LogLevel | string): LogLevel {
    if (Object.values(LogLevel).includes(level as LogLevel)) {
      return level as LogLevel;
    }

    const token = this.normalizeLevelToken(String(level));
    return token ?? LogLevel.INFO;
  }

  private normalizeCategory(category: LogCategory | string): LogCategory {
    if (Object.values(LogCategory).includes(category as LogCategory)) {
      return category as LogCategory;
    }

    const upper = String(category).toUpperCase().trim();
    const found = Object.values(LogCategory).find((c) => c === upper);

    if (found) {
      return found;
    }

    this.logger.warn(
      `Unknown log category "${category}", defaulting to SYSTEM.`,
    );
    return LogCategory.SYSTEM;
  }

  private normalizeVisibilityToken(
    visibility?: string | LogVisibility | null,
  ): LogVisibility | undefined {
    if (!visibility) {
      return undefined;
    }

    const upper = String(visibility).toUpperCase().trim();
    if (
      (LOG_VISIBILITY_VALUES as readonly string[]).includes(upper)
    ) {
      return upper as LogVisibility;
    }

    this.logger.warn(
      `Unknown log visibility "${visibility}", defaulting to INTERNAL.`,
    );
    return 'INTERNAL';
  }

  private normalizeFunctionId(
    functionId?: FunctionalId | string,
  ): FunctionalId | string | undefined {
    if (!functionId) {
      return undefined;
    }

    const token = String(functionId).trim();
    if (!token) {
      return undefined;
    }

    if (isFunctionalId(token)) {
      return token;
    }

    // Allow non-canonical functional IDs but keep them as plain strings.
    this.logger.warn(
      `Non-canonical functionalId "${token}" used in log event.`,
    );
    return token;
  }

  private shouldLog(level: LogLevel): boolean {
    return (
      LOG_LEVEL_ORDER[level] >= LOG_LEVEL_ORDER[this.minLevel as LogLevel]
    );
  }

  /**
   * Build metadata for a log event, attaching tenant/functional/actor/visibility
   * context and applying privacy rules when required.
   */
  private buildSafeMetadata(input: {
    baseMetadata?: Record<string, unknown>;
    organizationId?: string;
    functionId?: FunctionalId | string;
    actorUserId?: string;
    actorRoleId?: string;
    visibility?: LogVisibility;
    profileLoggingLevel?: ProfileLoggingLevel;
    sanitizeMetadata?: boolean;
  }): Record<string, unknown> | undefined {
    const effectiveVisibility = input.visibility;
    const shouldSanitize = this.shouldSanitizeMetadata(
      effectiveVisibility,
      input.profileLoggingLevel,
      input.sanitizeMetadata,
    );

    // If we must sanitize, keep only structural, non-sensitive context.
    if (shouldSanitize) {
      const sanitized: Record<string, unknown> = {};

      if (input.organizationId) {
        sanitized.organizationId = input.organizationId;
      }

      if (input.functionId) {
        sanitized.functionId = input.functionId;
        sanitized.fn = input.functionId;
      }

      if (effectiveVisibility) {
        sanitized.visibility = effectiveVisibility;
      }

      if (input.actorUserId) {
        sanitized.actorUserId = input.actorUserId;
      }

      if (input.actorRoleId) {
        sanitized.actorRoleId = input.actorRoleId;
      }

      return Object.keys(sanitized).length > 0 ? sanitized : undefined;
    }

    // No sanitisation required → merge full metadata payload plus context.
    const metadata: Record<string, unknown> = {
      ...(input.baseMetadata ?? {}),
    };

    if (input.organizationId && metadata.organizationId == null) {
      metadata.organizationId = input.organizationId;
    }

    if (input.functionId) {
      if (metadata.functionId == null) {
        metadata.functionId = input.functionId;
      }
      if (metadata.fn == null) {
        metadata.fn = input.functionId;
      }
    }

    if (input.actorUserId && metadata.actorUserId == null) {
      metadata.actorUserId = input.actorUserId;
    }

    if (input.actorRoleId && metadata.actorRoleId == null) {
      metadata.actorRoleId = input.actorRoleId;
    }

    if (effectiveVisibility && metadata.visibility == null) {
      metadata.visibility = effectiveVisibility;
    }

    return Object.keys(metadata).length > 0 ? metadata : undefined;
  }

  /**
   * Decide whether metadata should be stripped down to non-sensitive context.
   *
   * Behaviour:
   * - explicit sanitizeMetadata=true → always sanitize.
   * - visibility=ANONYMISED → always sanitize.
   * - visibility=RESTRICTED and profileLoggingLevel is missing or "minimal"
   *   → sanitize to avoid leaking sensitive fields in operational logs.
   */
  private shouldSanitizeMetadata(
    visibility?: LogVisibility,
    profileLoggingLevel?: ProfileLoggingLevel,
    explicit?: boolean,
  ): boolean {
    if (explicit) {
      return true;
    }

    if (!visibility) {
      return false;
    }

    if (visibility === 'ANONYMISED') {
      return true;
    }

    if (
      visibility === 'RESTRICTED' &&
      (!profileLoggingLevel || profileLoggingLevel === 'minimal')
    ) {
      return true;
    }

    return false;
  }

  private formatTextLine(event: StructuredLogEvent): string {
    const parts: string[] = [
      event.timestamp,
      event.level,
      event.category,
      event.identifier ?? '-',
      event.message,
    ];

    if (event.metadata && Object.keys(event.metadata).length > 0) {
      parts.push(JSON.stringify(event.metadata));
    }

    return parts.join(' | ');
  }

  private logToNest(level: LogLevel, message: string): void {
    switch (level) {
      case LogLevel.DEBUG:
        this.logger.debug(message);
        break;
      case LogLevel.INFO:
        this.logger.log(message);
        break;
      case LogLevel.WARNING:
        this.logger.warn(message);
        break;
      case LogLevel.ERROR:
      case LogLevel.CRITICAL:
        this.logger.error(message);
        break;
      default:
        this.logger.log(message);
        break;
    }
  }

  private async writeToFile(
    category: LogCategory,
    line: string,
  ): Promise<void> {
    const categoryConfig = this.config.categories[category];
    if (!categoryConfig) {
      return;
    }

    const filePath = path.join(this.config.logDir, categoryConfig.file);

    try {
      // Size-based rotation is always enforced as a safeguard.
      await this.rotateIfNeededBySize(
        filePath,
        categoryConfig.maxFileSizeMb,
        categoryConfig.retentionDays,
      );

      await fsp.appendFile(filePath, line + '\n', { encoding: 'utf8' });
    } catch (error) {
      this.logger.error(
        `Failed to write log file "${filePath}": ${
          (error as Error).message
        }`,
      );
    }
  }

  private async rotateIfNeededBySize(
    filePath: string,
    maxFileSizeMb: number,
    retentionDays: number,
  ): Promise<void> {
    let stats;
    try {
      stats = await fsp.stat(filePath);
    } catch (error) {
      // ENOENT = file does not exist yet → nothing to rotate
      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
        return;
      }
      throw error;
    }

    const maxBytes = maxFileSizeMb * 1024 * 1024;
    if (stats.size <= maxBytes) {
      return;
    }

    await this.rotateSingleFile(filePath, retentionDays);
  }

  private async rotateCategoryLogs(
    category: LogCategory,
    categoryConfig: LoggingCategoryConfig,
    referenceDate: Date,
  ): Promise<void> {
    const filePath = path.join(this.config.logDir, categoryConfig.file);

    // For daily/weekly rotation, we simply rotate the current file if it exists.
    if (categoryConfig.rotation === 'daily') {
      await this.rotateIfExists(filePath, categoryConfig.retentionDays);
    } else if (categoryConfig.rotation === 'weekly') {
      await this.rotateIfExists(filePath, categoryConfig.retentionDays);
    } else if (categoryConfig.rotation === 'size') {
      await this.rotateIfNeededBySize(
        filePath,
        categoryConfig.maxFileSizeMb,
        categoryConfig.retentionDays,
      );
    } else {
      this.logger.warn(
        `Unknown rotation strategy "${
          categoryConfig.rotation as string
        }" for category "${category}".`,
      );
    }

    // referenceDate is currently unused, but kept for future time-based policies.
    void referenceDate;
  }

  private async rotateIfExists(
    filePath: string,
    retentionDays: number,
  ): Promise<void> {
    try {
      await fsp.stat(filePath);
    } catch (error) {
      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
        return; // nothing to rotate
      }
      throw error;
    }

    await this.rotateSingleFile(filePath, retentionDays);
  }

  private async rotateSingleFile(
    filePath: string,
    retentionDays: number,
  ): Promise<void> {
    const dir = path.dirname(filePath);
    const base = path.basename(filePath, path.extname(filePath));
    const ext = path.extname(filePath) || '.log';
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');

    const rotatedPath = path.join(dir, `${base}.${timestamp}${ext}`);

    try {
      await fsp.rename(filePath, rotatedPath);
    } catch (error) {
      this.logger.error(
        `Failed to rotate log file "${filePath}": ${
          (error as Error).message
        }`,
      );
      return;
    }

    await this.cleanupOldRotatedFiles(dir, base, ext, retentionDays);
  }

  private async cleanupOldRotatedFiles(
    dir: string,
    base: string,
    ext: string,
    retentionDays: number,
  ): Promise<void> {
    const retentionMs = retentionDays * 24 * 60 * 60 * 1000;
    const now = Date.now();

    let entries: string[];
    try {
      entries = await fsp.readdir(dir);
    } catch (error) {
      this.logger.error(
        `Failed to read log directory "${dir}" for cleanup: ${
          (error as Error).message
        }`,
      );
      return;
    }

    const prefix = `${base}.`;

    const candidates = entries.filter(
      (name) => name.startsWith(prefix) && name.endsWith(ext),
    );

    const deletions: Promise<void>[] = [];

    for (const name of candidates) {
      const fullPath = path.join(dir, name);
      deletions.push(
        (async () => {
          try {
            const stats = await fsp.stat(fullPath);
            const ageMs = now - stats.mtime.getTime();
            if (ageMs > retentionMs) {
              await fsp.unlink(fullPath);
            }
          } catch (error) {
            this.logger.error(
              `Failed to evaluate or delete rotated log file "${fullPath}": ${
                (error as Error).message
              }`,
            );
          }
        })(),
      );
    }

    await Promise.all(deletions);
  }
}


=== FILE 24/48: apps/api/src/orgo/core/logging/logger.module.ts ===

import { Global, Module } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';
import { LogService } from './log.service';
import { LogRotationService } from './log-rotation.service';
import { LogQueryService } from './log-query.service';

/**
 * Injection token for the core Orgo logger_service.
 *
 * This matches the logical service identifier used in the Orgo
 * Core Services specification and can be used with:
 *
 *   @Inject(LOGGER_SERVICE_TOKEN) private readonly logService: LogService
 */
export const LOGGER_SERVICE_TOKEN = 'logger_service';

@Global()
@Module({
  imports: [
    // Uses the global ConfigModule instance from AppModule.
    // LogService is responsible for reading logging_config.yaml or
    // equivalent configuration via ConfigService.
    ConfigModule,
  ],
  providers: [
    LogService,
    {
      // Provide LogService under the stable string token "logger_service"
      // so other modules can depend on the logical core service id
      // instead of the concrete class name.
      provide: LOGGER_SERVICE_TOKEN,
      useExisting: LogService,
    },
    LogRotationService,
    LogQueryService,
  ],
  exports: [
    // Export both the concrete class and the string token so that
    // consumers can choose either style of injection.
    LogService,
    LOGGER_SERVICE_TOKEN,
    LogRotationService,
    LogQueryService,
  ],
})
export class LoggerModule {}


=== FILE 25/48: apps/api/src/orgo/core/metrics/metrics.service.ts ===

// apps/api/src/orgo/core/metrics/metrics.service.ts

import { Inject, Injectable, Optional } from '@nestjs/common';
import { LogCategory, LogLevel, LogService } from '../logging/log.service';
import {
  FN_METRICS_RECORD_QUEUE_DEPTH,
  FN_METRICS_RECORD_WORKFLOW_LATENCY,
} from '../functional-ids';

/**
 * Canonical environment values (Doc 2 – ENVIRONMENT).
 */
export type Environment = 'dev' | 'staging' | 'prod' | 'offline';

/**
 * Standard result error shape (Doc 5 §2.4).
 */
export interface StandardError {
  code: string;
  message: string;
  details?: unknown;
}

/**
 * Standard result shape (ok / data / error) used across Core Services (Doc 5 §2.4).
 */
export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardError | null;
}

/**
 * Outcome of a workflow execution as used for latency metrics.
 */
export type WorkflowOutcome = 'success' | 'error' | 'timeout' | 'cancelled';

/**
 * Pluggable sink for metrics.
 *
 * Implementations can forward metrics to Prometheus, StatsD, OpenTelemetry, etc.
 */
export interface MetricsSink {
  /**
   * Record a latency/distribution metric (typically backed by a Histogram/Summary).
   */
  recordHistogram(
    name: string,
    value: number,
    labels?: Record<string, string>,
  ): Promise<void> | void;

  /**
   * Record a gauge metric (current value).
   */
  setGauge(
    name: string,
    value: number,
    labels?: Record<string, string>,
  ): Promise<void> | void;
}

/**
 * Injection token for a pluggable MetricsSink implementation.
 *
 * A provider may bind to this token in a MetricsModule:
 *
 *   {
 *     provide: METRICS_SINK,
 *     useClass: PrometheusMetricsSink,
 *   }
 */
export const METRICS_SINK = 'metrics_sink';

/**
 * Input payload for recording per-workflow latency metrics.
 *
 * This is the logical payload expected from jobs such as
 * `orgo.metrics.record-workflow-latency`.
 */
export interface WorkflowLatencyMetricInput {
  /**
   * Stable workflow identifier (e.g. workflow definition code).
   */
  workflowId: string;

  /**
   * Total duration of the workflow execution in milliseconds.
   */
  durationMs: number;

  /**
   * Organization / tenant this execution belongs to, if applicable.
   */
  organizationId?: string;

  /**
   * Environment in which the workflow ran. If omitted, derived from ORGO_ENV / NODE_ENV.
   */
  environment?: string;

  /**
   * Outcome of the workflow execution.
   * Defaults to "success" if omitted.
   */
  outcome?: WorkflowOutcome;

  /**
   * Optional error code when outcome is not "success".
   */
  errorCode?: string;

  /**
   * Logical service or worker that executed the workflow (e.g. "workflow_engine").
   */
  serviceId?: string;

  /**
   * Concrete worker instance ID, if available.
   */
  workerId?: string;

  /**
   * When this latency measurement was captured.
   * Defaults to "now" if omitted.
   */
  timestamp?: Date | string;

  /**
   * Optional additional labels used for metrics backends.
   */
  labels?: Record<string, string>;

  /**
   * Free-form metadata added to logs only (not required by metrics backends).
   */
  metadata?: Record<string, unknown>;
}

/**
 * Normalised workflow-latency metric, as recorded by MetricsService.
 */
export interface WorkflowLatencyMetric {
  workflowId: string;
  durationMs: number;
  durationSeconds: number;
  organizationId?: string;
  environment: Environment;
  outcome: WorkflowOutcome;
  errorCode?: string;
  serviceId?: string;
  workerId?: string;
  timestamp: string; // ISO-8601 (UTC)
  labels?: Record<string, string>;
  metadata?: Record<string, unknown>;
}

/**
 * Input describing one queue’s depth snapshot.
 *
 * Used by recordQueueDepth() to capture per-queue metrics for autoscaling/alerting.
 */
export interface QueueDepthSampleInput {
  /**
   * Stable queue name (e.g. "task_default", "email_outbound").
   */
  queueName: string;

  /**
   * Jobs waiting to be processed (ready jobs).
   */
  readyJobs?: number;

  /**
   * Jobs currently being processed by workers.
   */
  activeJobs?: number;

  /**
   * Jobs scheduled for the future / delayed.
   */
  delayedJobs?: number;

  /**
   * Jobs in failed state.
   */
  failedJobs?: number;

  /**
   * Approximate end-to-end lag for this queue in seconds, if available.
   */
  lagSeconds?: number | null;
}

/**
 * Normalised per-queue depth snapshot.
 */
export interface QueueDepthSample {
  queueName: string;
  readyJobs: number;
  activeJobs: number;
  delayedJobs: number;
  failedJobs: number;
  lagSeconds: number | null;
}

/**
 * Input payload for recording queue-depth metrics.
 *
 * Typically produced by a background job such as
 * `orgo.metrics.record-queue-depth`.
 */
export interface QueueDepthMetricInput {
  samples: QueueDepthSampleInput[];

  /**
   * Environment in which queues are running. If omitted, derived from ORGO_ENV / NODE_ENV.
   */
  environment?: string;

  /**
   * Logical service / worker group owning these queues (e.g. "task_worker").
   */
  serviceId?: string;

  /**
   * Optional organization scope; queues may be shared across orgs.
   */
  organizationId?: string;

  /**
   * When this snapshot was generated. Defaults to "now" if omitted.
   */
  timestamp?: Date | string;

  /**
   * Additional metadata to be attached to logs.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Normalised queue-depth snapshot as recorded by MetricsService.
 */
export interface QueueDepthMetric {
  environment: Environment;
  serviceId?: string;
  organizationId?: string;
  timestamp: string; // ISO-8601 (UTC)
  samples: QueueDepthSample[];
  summary: {
    totalQueues: number;
    totalReadyJobs: number;
    totalActiveJobs: number;
    totalDelayedJobs: number;
    totalFailedJobs: number;
  };
}

/**
 * MetricsService
 *
 * Core responsibilities:
 * - Record per-workflow latency metrics (recordWorkflowLatency).
 * - Record per-queue depth metrics (recordQueueDepth).
 * - Emit structured log events for observability pipelines.
 * - Optionally forward metrics to a pluggable MetricsSink (Prometheus, etc.).
 */
@Injectable()
export class MetricsService {
  constructor(
    private readonly logService: LogService,
    @Optional()
    @Inject(METRICS_SINK)
    private readonly metricsSink?: MetricsSink,
  ) {}

  /**
   * Record latency for a single workflow execution.
   *
   * This method normalises the environment and timestamp, logs a structured
   * SYSTEM event, and optionally forwards the measurement to a MetricsSink.
   */
  async recordWorkflowLatency(
    input: WorkflowLatencyMetricInput,
  ): Promise<StandardResult<WorkflowLatencyMetric>> {
    if (
      !input ||
      !input.workflowId ||
      !Number.isFinite(Number(input.durationMs)) ||
      Number(input.durationMs) < 0
    ) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'METRICS_WORKFLOW_LATENCY_INVALID_PAYLOAD',
          message:
            'workflowId and non-negative durationMs are required to record workflow latency.',
          details: { input },
        },
      };
    }

    const environment = this.resolveEnvironment(input.environment);
    const timestampDate = this.normaliseDate(input.timestamp) ?? new Date();

    const durationMs = Number(input.durationMs);
    const durationSeconds = durationMs / 1000;
    const outcome: WorkflowOutcome = input.outcome ?? 'success';

    const metric: WorkflowLatencyMetric = {
      workflowId: input.workflowId,
      durationMs,
      durationSeconds,
      organizationId: input.organizationId,
      environment,
      outcome,
      errorCode: input.errorCode,
      serviceId: input.serviceId,
      workerId: input.workerId,
      timestamp: timestampDate.toISOString(),
      labels: input.labels,
      metadata: input.metadata,
    };

    try {
      // Forward to metrics backend if available.
      if (this.metricsSink) {
        await this.metricsSink.recordHistogram(
          'orgo_workflow_latency_seconds',
          metric.durationSeconds,
          {
            environment: metric.environment,
            workflow_id: metric.workflowId,
            ...(metric.organizationId
              ? { organization_id: metric.organizationId }
              : {}),
            ...(metric.serviceId ? { service_id: metric.serviceId } : {}),
            ...(metric.workerId ? { worker_id: metric.workerId } : {}),
            outcome: metric.outcome,
            ...(metric.labels ?? {}),
          },
        );
      }

      // Always emit a structured log event for observability/log-based metrics.
      this.logService.logEvent({
        category: LogCategory.SYSTEM,
        level: LogLevel.INFO,
        message: `Workflow latency recorded for "${metric.workflowId}" (${metric.durationMs}ms).`,
        identifier: `workflow_id:${metric.workflowId}`,
        metadata: {
          functionId: FN_METRICS_RECORD_WORKFLOW_LATENCY,
          environment: metric.environment,
          organizationId: metric.organizationId ?? null,
          serviceId: metric.serviceId ?? null,
          workerId: metric.workerId ?? null,
          outcome: metric.outcome,
          errorCode: metric.errorCode ?? null,
          durationMs: metric.durationMs,
          durationSeconds: metric.durationSeconds,
          timestamp: metric.timestamp,
          labels: metric.labels ?? {},
          extraMetadata: metric.metadata ?? {},
        },
      });

      return {
        ok: true,
        data: metric,
        error: null,
      };
    } catch (error) {
      const err =
        error instanceof Error
          ? error
          : new Error('Unknown error in recordWorkflowLatency');

      this.logService.logEvent({
        category: LogCategory.SYSTEM,
        level: LogLevel.ERROR,
        message: 'Failed to record workflow latency metric.',
        identifier: `workflow_id:${input.workflowId}`,
        metadata: {
          functionId: FN_METRICS_RECORD_WORKFLOW_LATENCY,
          environment,
          error: err.message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'METRICS_WORKFLOW_LATENCY_RECORD_FAILED',
          message: err.message,
          details: {
            workflowId: input.workflowId,
            environment,
          },
        },
      };
    }
  }

  /**
   * Record current depth metrics for one or more queues.
   *
   * Typical usage:
   * - Periodic job reads queue depths from the queue backend,
   *   then calls recordQueueDepth with one QueueDepthSample per queue.
   */
  async recordQueueDepth(
    input: QueueDepthMetricInput,
  ): Promise<StandardResult<QueueDepthMetric>> {
    if (!input || !Array.isArray(input.samples) || input.samples.length === 0) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'METRICS_QUEUE_DEPTH_INVALID_PAYLOAD',
          message: 'At least one queue depth sample is required.',
          details: { input },
        },
      };
    }

    const environment = this.resolveEnvironment(input.environment);
    const timestampDate = this.normaliseDate(input.timestamp) ?? new Date();

    const samples: QueueDepthSample[] = input.samples.map((sample) => ({
      queueName: sample.queueName,
      readyJobs: this.toNonNegativeInt(sample.readyJobs),
      activeJobs: this.toNonNegativeInt(sample.activeJobs),
      delayedJobs: this.toNonNegativeInt(sample.delayedJobs),
      failedJobs: this.toNonNegativeInt(sample.failedJobs),
      lagSeconds: this.toNonNegativeNumber(sample.lagSeconds),
    }));

    const summary = samples.reduce(
      (acc, s) => {
        acc.totalReadyJobs += s.readyJobs;
        acc.totalActiveJobs += s.activeJobs;
        acc.totalDelayedJobs += s.delayedJobs;
        acc.totalFailedJobs += s.failedJobs;
        return acc;
      },
      {
        totalQueues: samples.length,
        totalReadyJobs: 0,
        totalActiveJobs: 0,
        totalDelayedJobs: 0,
        totalFailedJobs: 0,
      },
    );

    const metric: QueueDepthMetric = {
      environment,
      serviceId: input.serviceId,
      organizationId: input.organizationId,
      timestamp: timestampDate.toISOString(),
      samples,
      summary,
    };

    try {
      if (this.metricsSink) {
        for (const sample of samples) {
          const labels: Record<string, string> = {
            environment: metric.environment,
            queue: sample.queueName,
          };

          if (metric.serviceId) {
            labels.service_id = metric.serviceId;
          }
          if (metric.organizationId) {
            labels.organization_id = metric.organizationId;
          }

          await this.metricsSink.setGauge(
            'orgo_queue_ready_jobs',
            sample.readyJobs,
            labels,
          );
          await this.metricsSink.setGauge(
            'orgo_queue_active_jobs',
            sample.activeJobs,
            labels,
          );
          await this.metricsSink.setGauge(
            'orgo_queue_delayed_jobs',
            sample.delayedJobs,
            labels,
          );
          await this.metricsSink.setGauge(
            'orgo_queue_failed_jobs',
            sample.failedJobs,
            labels,
          );

          if (sample.lagSeconds != null) {
            await this.metricsSink.setGauge(
              'orgo_queue_lag_seconds',
              sample.lagSeconds,
              labels,
            );
          }
        }
      }

      this.logService.logEvent({
        category: LogCategory.SYSTEM,
        level: LogLevel.INFO,
        message: 'Queue depth metrics recorded.',
        identifier: input.serviceId
          ? `service_id:${input.serviceId}`
          : input.organizationId
          ? `org_id:${input.organizationId}`
          : undefined,
        metadata: {
          functionId: FN_METRICS_RECORD_QUEUE_DEPTH,
          environment: metric.environment,
          serviceId: metric.serviceId ?? null,
          organizationId: metric.organizationId ?? null,
          timestamp: metric.timestamp,
          summary: metric.summary,
          samples: metric.samples,
          extraMetadata: input.metadata ?? {},
        },
      });

      return {
        ok: true,
        data: metric,
        error: null,
      };
    } catch (error) {
      const err =
        error instanceof Error
          ? error
          : new Error('Unknown error in recordQueueDepth');

      this.logService.logEvent({
        category: LogCategory.SYSTEM,
        level: LogLevel.ERROR,
        message: 'Failed to record queue depth metrics.',
        identifier: input.serviceId
          ? `service_id:${input.serviceId}`
          : input.organizationId
          ? `org_id:${input.organizationId}`
          : undefined,
        metadata: {
          functionId: FN_METRICS_RECORD_QUEUE_DEPTH,
          environment,
          error: err.message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'METRICS_QUEUE_DEPTH_RECORD_FAILED',
          message: err.message,
          details: {
            serviceId: input.serviceId,
            organizationId: input.organizationId,
            environment,
          },
        },
      };
    }
  }

  // ---------------------------------------------------------------------------
  // Internal helpers
  // ---------------------------------------------------------------------------

  /**
   * Resolve an Orgo ENVIRONMENT value from an optional explicit value
   * plus process environment variables.
   *
   * Canonical values: "dev" | "staging" | "prod" | "offline".
   */
  private resolveEnvironment(explicit?: string): Environment {
    const raw =
      explicit ??
      process.env.ORGO_ENV ??
      process.env.ORGO_ENVIRONMENT ??
      process.env.NODE_ENV ??
      'dev';

    const value = raw.toLowerCase();

    if (value === 'dev' || value === 'development' || value === 'local') {
      return 'dev';
    }

    if (value === 'staging' || value === 'stage') {
      return 'staging';
    }

    if (value === 'prod' || value === 'production') {
      return 'prod';
    }

    if (value === 'offline') {
      return 'offline';
    }

    // Fallback: be explicit and predictable.
    return 'dev';
  }

  /**
   * Normalise a timestamp value to a Date, or null if invalid.
   */
  private normaliseDate(value?: string | Date): Date | null {
    if (!value) {
      return null;
    }

    if (value instanceof Date) {
      return value;
    }

    const parsed = new Date(value);
    if (Number.isNaN(parsed.getTime())) {
      return null;
    }

    return parsed;
  }

  /**
   * Coerce an optional number into a non-negative integer (default 0).
   */
  private toNonNegativeInt(value?: number | null): number {
    const num = typeof value === 'number' ? value : 0;
    if (!Number.isFinite(num) || num <= 0) {
      return 0;
    }
    return Math.floor(num);
  }

  /**
   * Coerce an optional number into a non-negative number (or null if unavailable).
   */
  private toNonNegativeNumber(value?: number | null): number | null {
    if (value == null) {
      return null;
    }
    const num = Number(value);
    if (!Number.isFinite(num)) {
      return null;
    }
    return num < 0 ? 0 : num;
  }
}


=== FILE 26/48: apps/api/src/orgo/core/notifications/notification.controller.ts ===

import { Controller, Get, Post, Body, Query } from '@nestjs/common';
import { ApiTags, ApiOperation, ApiResponse, ApiProperty } from '@nestjs/swagger';

import { NotificationService } from './notification.service';

/**
 * Canonical notification channels and statuses as per Doc 1/Doc 2.
 * DB stores these as lower-case strings; API uses the same tokens.
 */
export enum NotificationChannel {
  EMAIL = 'email',
  SMS = 'sms',
  IN_APP = 'in_app',
  WEBHOOK = 'webhook',
}

export enum NotificationStatus {
  QUEUED = 'queued',
  SENT = 'sent',
  FAILED = 'failed',
  CANCELLED = 'cancelled',
}

/**
 * Query DTO for listing notifications for the current user.
 * Filtering is intentionally minimal; more filters can be added later
 * (e.g. by template code, task, date range).
 */
export class ListNotificationsQueryDto {
  @ApiProperty({
    required: false,
    enum: NotificationChannel,
    description: 'Filter by notification channel (email, sms, in_app, webhook).',
  })
  channel?: NotificationChannel;

  @ApiProperty({
    required: false,
    enum: NotificationStatus,
    description: 'Filter by delivery status (queued, sent, failed, cancelled).',
  })
  status?: NotificationStatus;

  @ApiProperty({
    required: false,
    minimum: 1,
    maximum: 200,
    default: 50,
    description: 'Maximum number of items to return (1–200). Defaults to 50.',
  })
  limit?: number;

  @ApiProperty({
    required: false,
    description:
      'Opaque cursor for pagination; use the value returned as nextCursor from a previous call.',
  })
  cursor?: string;
}

/**
 * Logical Notification view returned by the API.
 * Fields mirror the logical Notification model over the notifications table.
 */
export class NotificationDto {
  @ApiProperty({ format: 'uuid' })
  id!: string;

  @ApiProperty({ format: 'uuid', description: 'Tenant / organization identifier.' })
  organizationId!: string;

  @ApiProperty({ enum: NotificationChannel })
  channel!: NotificationChannel;

  @ApiProperty({ enum: NotificationStatus })
  status!: NotificationStatus;

  @ApiProperty({
    format: 'uuid',
    nullable: true,
    description: 'Recipient user id, if the notification is tied to a user account.',
  })
  recipientUserId!: string | null;

  @ApiProperty({
    nullable: true,
    description:
      'Recipient address (email/phone/webhook URL/device token) for non user-tied notifications.',
  })
  recipientAddress!: string | null;

  @ApiProperty({
    format: 'uuid',
    nullable: true,
    description: 'Related Task id, when the notification is tied to a Task lifecycle event.',
  })
  relatedTaskId!: string | null;

  @ApiProperty({
    type: 'object',
    description:
      'Channel-ready payload (for in_app: title/body + context; for email/webhook: rendered payload).',
    additionalProperties: true,
  })
  payload!: Record<string, unknown>;

  @ApiProperty({
    nullable: true,
    description: 'Time the notification was queued for delivery (ISO 8601, UTC).',
  })
  queuedAt!: string | null;

  @ApiProperty({
    nullable: true,
    description: 'Time the notification was sent successfully (ISO 8601, UTC).',
  })
  sentAt!: string | null;

  @ApiProperty({
    nullable: true,
    description: 'Time the notification failed permanently (ISO 8601, UTC).',
  })
  failedAt!: string | null;

  @ApiProperty({
    nullable: true,
    description: 'Error message captured when delivery fails.',
  })
  errorMessage!: string | null;
}

/**
 * Paginated notifications feed response.
 */
export class NotificationFeedResponseDto {
  @ApiProperty({ type: [NotificationDto] })
  items!: NotificationDto[];

  @ApiProperty({
    nullable: true,
    description:
      'Cursor to fetch the next page. Omitted/null when there are no more results.',
  })
  nextCursor?: string | null;
}

/**
 * DTO for sending an ad-hoc in-app notification.
 * This uses the NotificationService.sendInApp logical entrypoint from Doc 4.
 * Task-driven notifications (CREATED/ASSIGNED/ESCALATED/COMPLETED) are typically
 * triggered internally via sendTaskNotification, not via this controller.
 */
export class SendInAppNotificationDto {
  @ApiProperty({
    format: 'uuid',
    description: 'Recipient user id within the current organization.',
  })
  recipientUserId!: string;

  @ApiProperty({
    maxLength: 200,
    description: 'Short title used in in-app banners/toasts.',
  })
  title!: string;

  @ApiProperty({
    maxLength: 2000,
    description: 'Body text shown in the in-app notification.',
  })
  body!: string;

  @ApiProperty({
    required: false,
    format: 'uuid',
    description: 'Optional related Task id to deep-link from the notification.',
  })
  relatedTaskId?: string;

  @ApiProperty({
    required: false,
    type: 'object',
    additionalProperties: true,
    description:
      'Optional extra metadata to embed in the payload (e.g. label, domain info, deep-link params).',
  })
  metadata?: Record<string, unknown>;
}

@ApiTags('notifications')
@Controller('notifications')
export class NotificationController {
  constructor(private readonly notificationService: NotificationService) {}

  @Get()
  @ApiOperation({
    summary: 'List notifications for the current user',
    description:
      'Returns a paginated feed of notifications (email, sms, in_app, webhook) for the authenticated user, filtered by channel/status as needed.',
  })
  @ApiResponse({
    status: 200,
    type: NotificationFeedResponseDto,
  })
  async listNotifications(
    @Query() query: ListNotificationsQueryDto,
  ): Promise<NotificationFeedResponseDto> {
    // Basic, defensive normalization of limit without assuming any specific validation pipe.
    const rawLimit = (query as any).limit;
    const numericLimit = rawLimit !== undefined ? Number(rawLimit) : NaN;
    const effectiveLimit =
      Number.isFinite(numericLimit) && numericLimit > 0
        ? Math.min(Math.max(Math.floor(numericLimit), 1), 200)
        : 50;

    const filters: ListNotificationsQueryDto = {
      ...query,
      limit: effectiveLimit,
    };

    // Multi-tenant + user scoping is handled inside NotificationService,
    // using whatever auth/context mechanism is wired into the app.
    return this.notificationService.listNotificationsForCurrentUser(filters);
  }

  @Post('in-app')
  @ApiOperation({
    summary: 'Send an ad-hoc in-app notification',
    description:
      'Queues an in-app notification to a single user in the current organization. Task-driven lifecycle notifications should use Task/Workflow services instead.',
  })
  @ApiResponse({
    status: 201,
    type: NotificationDto,
  })
  async sendInApp(
    @Body() body: SendInAppNotificationDto,
  ): Promise<NotificationDto> {
    return this.notificationService.sendInApp(body);
  }
}


=== FILE 27/48: apps/api/src/orgo/core/notifications/notification.module.ts ===

import { Module } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';

import { PersistenceModule } from '../../../persistence/persistence.module';
import { LoggerModule } from '../logging/logger.module';
import { ConfigModule as OrgoConfigModule } from '../../config/config.module';
import { NotificationService } from './notification.service';

/**
 * NotificationModule
 *
 * Exposes NotificationService and integrates it with:
 * - Nest env config (ConfigModule),
 * - Orgo YAML config (notification_config.yaml),
 * - Shared persistence layer,
 * - Structured logging.
 */
@Module({
  imports: [
    ConfigModule,
    OrgoConfigModule,
    PersistenceModule,
    LoggerModule,
  ],
  providers: [NotificationService],
  exports: [NotificationService],
})
export class NotificationModule {}


=== FILE 28/48: apps/api/src/orgo/core/notifications/notification.service.ts ===

// apps/api/src/orgo/core/notifications/notification.service.ts

import {
  BadRequestException,
  ForbiddenException,
  Inject,
  Injectable,
  Logger,
  Optional,
  UnauthorizedException,
} from '@nestjs/common';
import { REQUEST } from '@nestjs/core';
import type { Request } from 'express';

import { OrgoConfigService } from '../../config/config.service';
import { OrgProfileService } from '../../config/org-profile.service';
import { FeatureFlagService } from '../../config/feature-flag.service';
import type { FeatureFlagEvaluationContext } from '../../config/feature-flag.service';
import { LogService } from '../logging/log.service';
import { EmailService } from '../email/email.service';
import { PrismaService } from './././persistence/prisma/prisma.service';
import type {
  ListNotificationsQueryDto,
  NotificationChannel as ApiNotificationChannel,
  NotificationStatus as ApiNotificationStatus,
  NotificationDto,
  NotificationFeedResponseDto,
  SendInAppNotificationDto,
} from './notification.controller';

/**
 * Injection token for a pluggable recipient resolver.
 * A provider must be bound to this token in the NotificationsModule.
 */
export const NOTIFICATION_RECIPIENT_RESOLVER =
  'NOTIFICATION_RECIPIENT_RESOLVER';

/**
 * Canonical notification channels (Doc 2 §2.8 / Doc 5 §7).
 */
export type NotificationChannel = 'EMAIL' | 'SMS' | 'IN_APP' | 'WEBHOOK';

/**
 * Canonical notification scopes (Doc 2 §2.8, Doc 7 profiles.notification_scope).
 */
export type NotificationScope = 'user' | 'team' | 'department' | 'org_wide';

/**
 * Supported task lifecycle notification events (Doc 5 §7.3).
 */
export type TaskNotificationEventType =
  | 'CREATED'
  | 'ASSIGNED'
  | 'ESCALATED'
  | 'COMPLETED';

/**
 * Canonical VISIBILITY enum (JSON / service form).
 */
export type TaskVisibility = 'PUBLIC' | 'INTERNAL' | 'RESTRICTED' | 'ANONYMISED';

/**
 * Standard service-level error shape (Doc 5 §2.4).
 */
export interface ServiceError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Standard result shape (Doc 5 §2.4).
 */
export interface ServiceResult<T> {
  ok: boolean;
  data: T | null;
  error: ServiceError | null;
}

/**
 * Minimal Task payload required to send notifications.
 * Logical view aligned with the canonical Task model (Doc 5 §3.1 / Doc 8 §8.4.2).
 */
export interface NotifiableTask {
  taskId: string;
  organizationId: string;

  title: string;
  description: string;
  label: string;

  status: string;
  priority: string;
  severity: string;
  visibility: TaskVisibility;

  source: 'email' | 'api' | 'manual' | 'sync';

  ownerRoleId?: string | null;
  ownerUserId?: string | null;
  assigneeRole?: string | null;

  createdByUserId?: string | null;
  requesterPersonId?: string | null;

  metadata?: Record<string, unknown>;
}

/**
 * Recipient representation for notifications across channels.
 */
export interface NotificationRecipient {
  userId?: string;
  email?: string | null;
  displayName?: string | null;
  /**
   * Optional per-recipient channel override.
   * If omitted, all selected channels are used.
   */
  preferredChannels?: NotificationChannel[];
}

/**
 * Result of resolving recipients for a task notification.
 */
export interface ResolvedNotificationRecipients {
  primary: NotificationRecipient[];
  cc: NotificationRecipient[];
}

/**
 * Dispatch result for a single channel.
 */
export interface NotificationChannelDispatchResult {
  channel: NotificationChannel;
  success: boolean;
  recipients: string[]; // normalized recipient identifiers (typically emails or user IDs)
  cc?: string[];
  error?: string;
  providerMetadata?: Record<string, unknown>;
}

/**
 * Summary for a Task notification operation.
 */
export interface TaskNotificationDispatchSummary {
  taskId: string;
  organizationId: string;
  eventType: TaskNotificationEventType;
  scope: NotificationScope;
  suppressed: boolean;
  suppressionReason?: string;
  channels: NotificationChannelDispatchResult[];
}

/**
 * Normalised Notification configuration (Doc 5 §7.2), as exposed by OrgoConfigService.
 */
export interface NotificationConfig {
  defaultChannel: NotificationChannel;
  channels: {
    email: {
      enabled: boolean;
      senderName: string;
      senderAddress: string;
    };
    inApp: {
      enabled: boolean;
    };
    sms?: {
      enabled: boolean;
    };
    webhook?: {
      enabled: boolean;
      endpoint?: string;
    };
  };
  templates: {
    taskCreated: string;
    taskAssignment: string;
    taskEscalation: string;
    taskCompleted: string;
  };
}

/**
 * Minimal Org profile view used here (Doc 7).
 */
export interface OrgProfile {
  notification_scope: NotificationScope;
}

/**
 * Contract for a pluggable recipient resolver.
 * Implementation is responsible for mapping roles/users/profiles → concrete recipients.
 */
export interface NotificationRecipientResolver {
  resolveTaskRecipients(params: {
    task: NotifiableTask;
    eventType: TaskNotificationEventType;
    scope: NotificationScope;
  }): Promise<ResolvedNotificationRecipients>;
}

/**
 * DB-level channel and status enums, matching notification_channel_enum /
 * notification_status_enum (Doc 1, Module 7).
 */
type NotificationChannelDb = 'email' | 'sms' | 'in_app' | 'webhook';
type NotificationStatusDb = 'queued' | 'sent' | 'failed' | 'cancelled';

interface AuthContext {
  organizationId: string;
  userId: string;
}

interface RequestWithAuthContext extends Request {
  organizationId?: string;
  userId?: string;
  user?: {
    organizationId?: string;
    userId?: string;
    [key: string]: unknown;
  };
}

/**
 * NotificationService – orchestrates Task-driven notifications
 * across configured channels (email, in-app, etc.) (Doc 5 §7),
 * and persists them into the notifications table.
 */
@Injectable()
export class NotificationService {
  private readonly logger = new Logger(NotificationService.name);

  constructor(
    private readonly emailService: EmailService,
    private readonly orgProfileService: OrgProfileService,
    private readonly configService: OrgoConfigService,
    private readonly logService: LogService,
    private readonly prisma: PrismaService,
    private readonly featureFlagService: FeatureFlagService,
    @Inject(NOTIFICATION_RECIPIENT_RESOLVER)
    private readonly recipientResolver: NotificationRecipientResolver,
    @Inject(REQUEST) @Optional()
    private readonly request?: RequestWithAuthContext,
  ) {}

  /**
   * Public entry point: send notifications for a Task lifecycle event
   * (Doc 5 §7.3). This is invoked by task/case/workflow engines (NOTIFY actions).
   */
  async sendTaskNotification(
    task: NotifiableTask,
    eventType: TaskNotificationEventType,
  ): Promise<ServiceResult<TaskNotificationDispatchSummary>> {
    if (!task || !task.taskId || !task.organizationId) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'NOTIFICATION_INVALID_TASK',
          message: 'Task and its identifiers are required to send notifications',
        },
      };
    }

    try {
      const [notificationConfig, profile] = await Promise.all([
        this.loadNotificationConfig(task.organizationId),
        this.orgProfileService.loadProfile(
          task.organizationId,
        ) as Promise<OrgProfile>,
      ]);

      const scope = this.normaliseNotificationScope(
        profile?.notification_scope,
      );

      const featureContext: FeatureFlagEvaluationContext = {
        organizationId: task.organizationId,
        userId: task.createdByUserId ?? null,
      };

      // Global per-org notifications flag. If disabled, all task notifications
      // are suppressed regardless of config.
      const notificationsEnabled = await this.isFeatureFlagEnabledOrUnset(
        'orgo.notifications.enabled',
        task.organizationId,
        featureContext,
      );

      if (!notificationsEnabled) {
        const summary: TaskNotificationDispatchSummary = {
          taskId: task.taskId,
          organizationId: task.organizationId,
          eventType,
          scope,
          suppressed: true,
          suppressionReason:
            'Notifications disabled for organization via feature flag',
          channels: [],
        };

        await this.safeLogEvent({
          category: 'TASK',
          logLevel: 'INFO',
          message: 'Notification suppressed: notifications globally disabled',
          identifier: `task_id:${task.taskId}`,
          metadata: { eventType, scope },
        });

        return {
          ok: true,
          data: summary,
          error: null,
        };
      }

      let channels = this.selectChannelsForEvent(notificationConfig, eventType);

      // Per-channel flags (email / in_app / sms / webhook).
      channels = await this.filterChannelsByFeatureFlags(
        channels,
        task.organizationId,
        featureContext,
      );

      if (channels.length === 0) {
        const summary: TaskNotificationDispatchSummary = {
          taskId: task.taskId,
          organizationId: task.organizationId,
          eventType,
          scope,
          suppressed: true,
          suppressionReason: 'No enabled notification channels for event',
          channels: [],
        };

        await this.safeLogEvent({
          category: 'TASK',
          logLevel: 'INFO',
          message: 'Notification suppressed: no enabled channels',
          identifier: `task_id:${task.taskId}`,
          metadata: { eventType, scope },
        });

        return {
          ok: true,
          data: summary,
          error: null,
        };
      }

      const recipients = await this.recipientResolver.resolveTaskRecipients({
        task,
        eventType,
        scope,
      });

      const hasAnyResolvedRecipient =
        recipients.primary.length > 0 || recipients.cc.length > 0;

      if (!hasAnyResolvedRecipient) {
        const summary: TaskNotificationDispatchSummary = {
          taskId: task.taskId,
          organizationId: task.organizationId,
          eventType,
          scope,
          suppressed: true,
          suppressionReason: 'No recipients resolved for notification',
          channels: [],
        };

        await this.safeLogEvent({
          category: 'TASK',
          logLevel: 'INFO',
          message: 'Notification suppressed: no recipients',
          identifier: `task_id:${task.taskId}`,
          metadata: { eventType, scope, visibility: task.visibility },
        });

        return {
          ok: true,
          data: summary,
          error: null,
        };
      }

      const recipientsByChannel = this.splitRecipientsByChannel(recipients);

      const hasRecipientsForAtLeastOneChannel = channels.some((channel) => {
        const channelRecipients = recipientsByChannel[channel];

        if (channel === 'EMAIL') {
          const to = this.extractEmails(channelRecipients.primary);
          const cc = this.extractEmails(channelRecipients.cc);
          return to.length > 0 || cc.length > 0;
        }

        if (channel === 'IN_APP') {
          const identifiers = this.extractInAppRecipientIdentifiers(
            channelRecipients.primary,
            channelRecipients.cc,
          );
          return identifiers.length > 0;
        }

        // For unimplemented channels (SMS/WEBHOOK), we keep the original
        // preference-based behaviour.
        return (
          channelRecipients.primary.length > 0 ||
          channelRecipients.cc.length > 0
        );
      });

      if (!hasRecipientsForAtLeastOneChannel) {
        const summary: TaskNotificationDispatchSummary = {
          taskId: task.taskId,
          organizationId: task.organizationId,
          eventType,
          scope,
          suppressed: true,
          suppressionReason:
            'No recipients resolved for any of the selected notification channels',
          channels: [],
        };

        await this.safeLogEvent({
          category: 'TASK',
          logLevel: 'INFO',
          message:
            'Notification suppressed: recipients have no matching channel preferences',
          identifier: `task_id:${task.taskId}`,
          metadata: {
            eventType,
            scope,
            visibility: task.visibility,
            channels,
          },
        });

        return {
          ok: true,
          data: summary,
          error: null,
        };
      }

      const channelResults: NotificationChannelDispatchResult[] = [];

      for (const channel of channels) {
        const channelRecipients = recipientsByChannel[channel];

        switch (channel) {
          case 'EMAIL': {
            const to = this.extractEmails(channelRecipients.primary);
            const cc = this.extractEmails(channelRecipients.cc);

            const result = await this.sendEmailTaskNotification(
              task,
              eventType,
              notificationConfig,
              to,
              cc,
            );
            channelResults.push(result);
            break;
          }

          case 'IN_APP': {
            const recipientIdentifiers = this.extractInAppRecipientIdentifiers(
              channelRecipients.primary,
              channelRecipients.cc,
            );

            const result = await this.sendInAppTaskNotification(
              task,
              eventType,
              recipientIdentifiers,
            );
            channelResults.push(result);
            break;
          }

          default: {
            const normalised = this.normaliseRecipientIdentifiers(
              channelRecipients,
            );
            channelResults.push({
              channel,
              success: false,
              recipients: normalised.to,
              cc: normalised.cc,
              error: 'Channel not implemented',
            });
            break;
          }
        }
      }

      const summary: TaskNotificationDispatchSummary = {
        taskId: task.taskId,
        organizationId: task.organizationId,
        eventType,
        scope,
        suppressed: false,
        channels: channelResults,
      };

      await this.safeLogEvent({
        category: 'TASK',
        logLevel: 'INFO',
        message: 'Task notifications dispatched',
        identifier: `task_id:${task.taskId}`,
        metadata: {
          eventType,
          scope,
          channels: channelResults.map((c) => ({
            channel: c.channel,
            success: c.success,
          })),
        },
      });

      return {
        ok: true,
        data: summary,
        error: null,
      };
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Failed to send notifications for task ${task.taskId} (${eventType}): ${error.message}`,
        error.stack,
      );

      await this.safeLogEvent({
        category: 'TASK',
        logLevel: 'ERROR',
        message: 'Task notification failed',
        identifier: `task_id:${task.taskId}`,
        metadata: {
          eventType,
          error: error.message,
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'NOTIFICATION_ERROR',
          message: error.message,
        },
      };
    }
  }

  /**
   * List notifications for the current user (notifications feed API).
   * Multi-tenant + user scoping is derived from the request context.
   */
  async listNotificationsForCurrentUser(
    filters: ListNotificationsQueryDto,
  ): Promise<NotificationFeedResponseDto> {
    const { organizationId, userId } = this.getAuthContextOrThrow();

    const limit =
      typeof filters.limit === 'number' && Number.isFinite(filters.limit)
        ? Math.min(Math.max(Math.floor(filters.limit), 1), 200)
        : 50;

    const where: any = {
      organization_id: organizationId,
      recipient_user_id: userId,
    };

    if (filters.channel) {
      where.channel = filters.channel;
    }

    if (filters.status) {
      where.status = filters.status;
    }

    const query: any = {
      where,
      orderBy: {
        queued_at: 'desc',
      },
      take: limit + 1,
    };

    if (filters.cursor) {
      query.cursor = { id: filters.cursor };
      query.skip = 1;
    }

    const rows = await this.prisma.notification.findMany(query);

    const hasMore = rows.length > limit;
    const slice = rows.slice(0, limit);

    const items: NotificationDto[] = slice.map((row: any) => ({
      id: row.id,
      organizationId: row.organization_id,
      channel: row.channel as ApiNotificationChannel,
      status: row.status as ApiNotificationStatus,
      recipientUserId: row.recipient_user_id,
      recipientAddress: row.recipient_address,
      relatedTaskId: row.related_task_id,
      payload: (row.payload ?? {}) as Record<string, unknown>,
      queuedAt: row.queued_at ? row.queued_at.toISOString() : null,
      sentAt: row.sent_at ? row.sent_at.toISOString() : null,
      failedAt: row.failed_at ? row.failed_at.toISOString() : null,
      errorMessage: row.error_message ?? null,
    }));

    return {
      items,
      nextCursor: hasMore ? rows[limit].id : null,
    };
  }

  /**
   * Send an ad-hoc in-app notification to a single user in the current org.
   * Used by the /api/v3/notifications/in-app endpoint.
   */
  async sendInApp(body: SendInAppNotificationDto): Promise<NotificationDto> {
    const { organizationId, userId } = this.getAuthContextOrThrow();

    if (!body.recipientUserId) {
      throw new BadRequestException('recipientUserId is required');
    }
    if (!body.title || !body.title.trim()) {
      throw new BadRequestException('title is required');
    }
    if (!body.body || !body.body.trim()) {
      throw new BadRequestException('body is required');
    }

    const featureContext: FeatureFlagEvaluationContext = {
      organizationId,
      userId,
    };

    const inAppEnabled = await this.isFeatureFlagEnabledOrUnset(
      'orgo.notifications.in_app',
      organizationId,
      featureContext,
    );

    if (!inAppEnabled) {
      throw new ForbiddenException(
        'In-app notifications are disabled for this organization',
      );
    }

    const now = new Date();

    const payload: Record<string, unknown> = {
      title: body.title,
      body: body.body,
      ...(body.metadata ? { metadata: body.metadata } : {}),
      ...(body.relatedTaskId ? { relatedTaskId: body.relatedTaskId } : {}),
      triggeredByUserId: userId,
    };

    const record = await this.prisma.notification.create({
      data: {
        organization_id: organizationId,
        channel: 'in_app',
        status: 'sent',
        recipient_user_id: body.recipientUserId,
        recipient_address: null,
        template_id: null,
        payload,
        related_task_id: body.relatedTaskId ?? null,
        queued_at: now,
        sent_at: now,
        failed_at: null,
        error_message: null,
      },
    });

    await this.safeLogEvent({
      category: 'TASK',
      logLevel: 'INFO',
      message: 'Ad-hoc in-app notification created',
      identifier: `notification_id:${record.id}`,
      metadata: {
        recipientUserId: body.recipientUserId,
        relatedTaskId: body.relatedTaskId ?? null,
      },
    });

    return {
      id: record.id,
      organizationId: record.organization_id,
      channel: record.channel as ApiNotificationChannel,
      status: record.status as ApiNotificationStatus,
      recipientUserId: record.recipient_user_id,
      recipientAddress: record.recipient_address,
      relatedTaskId: record.related_task_id,
      payload: (record.payload ?? {}) as Record<string, unknown>,
      queuedAt: record.queued_at ? record.queued_at.toISOString() : null,
      sentAt: record.sent_at ? record.sent_at.toISOString() : null,
      failedAt: record.failed_at ? record.failed_at.toISOString() : null,
      errorMessage: record.error_message ?? null,
    };
  }

  /**
   * Load and normalise notification configuration for an organization
   * (Doc 5 §7.2). Delegates to OrgoConfigService.
   */
  private async loadNotificationConfig(
    organizationId: string,
  ): Promise<NotificationConfig> {
    const config =
      await this.configService.getNotificationConfig(organizationId);

    if (!config) {
      throw new Error(
        `Notification configuration not found for organization ${organizationId}`,
      );
    }

    return config;
  }

  /**
   * Normalise org notification scope coming from OrgProfile into the canonical
   * NotificationScope enum, falling back to "department" for unknown/missing values
   * (Doc 2 §2.8 / Doc 7).
   */
  private normaliseNotificationScope(
    rawScope: string | null | undefined,
  ): NotificationScope {
    if (
      rawScope === 'user' ||
      rawScope === 'team' ||
      rawScope === 'department' ||
      rawScope === 'org_wide'
    ) {
      return rawScope;
    }

    return 'department';
  }

  /**
   * Select channels to use for a given event, based on config.
   * At minimum, uses the default channel if enabled; also adds IN_APP
   * if enabled as a secondary channel.
   */
  private selectChannelsForEvent(
    config: NotificationConfig,
    _eventType: TaskNotificationEventType,
  ): NotificationChannel[] {
    const channels: NotificationChannel[] = [];

    if (this.isChannelEnabled(config, config.defaultChannel)) {
      channels.push(config.defaultChannel);
    }

    // Enable IN_APP as a secondary channel for key lifecycle events if configured.
    if (
      this.isChannelEnabled(config, 'IN_APP') &&
      !channels.includes('IN_APP')
    ) {
      channels.push('IN_APP');
    }

    // Hook point: per-event channel routing could be added here.
    // For now, all events share the same channel selection logic.

    return channels;
  }

  private isChannelEnabled(
    config: NotificationConfig,
    channel: NotificationChannel,
  ): boolean {
    switch (channel) {
      case 'EMAIL':
        return !!config.channels.email?.enabled;
      case 'IN_APP':
        return !!config.channels.inApp?.enabled;
      case 'SMS':
        return !!config.channels.sms?.enabled;
      case 'WEBHOOK':
        return !!config.channels.webhook?.enabled;
      default:
        return false;
    }
  }

  /**
   * Filter eligible channels based on per-channel feature flags.
   * Missing flags do not gate behaviour (config remains the source of truth).
   */
  private async filterChannelsByFeatureFlags(
    channels: NotificationChannel[],
    organizationId: string,
    context: FeatureFlagEvaluationContext,
  ): Promise<NotificationChannel[]> {
    if (!this.featureFlagService || channels.length === 0) {
      return channels;
    }

    const enabledChannels: NotificationChannel[] = [];

    for (const channel of channels) {
      const flagCode = this.getChannelFeatureFlagCode(channel);
      const enabled = await this.isFeatureFlagEnabledOrUnset(
        flagCode,
        organizationId,
        context,
      );
      if (enabled) {
        enabledChannels.push(channel);
      }
    }

    return enabledChannels;
  }

  private getChannelFeatureFlagCode(channel: NotificationChannel): string {
    switch (channel) {
      case 'EMAIL':
        return 'orgo.notifications.email';
      case 'SMS':
        return 'orgo.notifications.sms';
      case 'IN_APP':
        return 'orgo.notifications.in_app';
      case 'WEBHOOK':
        return 'orgo.notifications.webhook';
      default:
        return 'orgo.notifications.unknown';
    }
  }

  /**
   * Check whether a recipient allows a given channel based on preferredChannels.
   * If preferredChannels is empty/undefined, all channels are allowed.
   */
  private doesRecipientAllowChannel(
    recipient: NotificationRecipient,
    channel: NotificationChannel,
  ): boolean {
    const { preferredChannels } = recipient;
    if (!preferredChannels || preferredChannels.length === 0) {
      return true;
    }
    return preferredChannels.includes(channel);
  }

  /**
   * Split resolved recipients into per-channel buckets, respecting
   * per-recipient preferredChannels.
   */
  private splitRecipientsByChannel(
    recipients: ResolvedNotificationRecipients,
  ): Record<
    NotificationChannel,
    { primary: NotificationRecipient[]; cc: NotificationRecipient[] }
  > {
    const result: Record<
      NotificationChannel,
      { primary: NotificationRecipient[]; cc: NotificationRecipient[] }
    > = {
      EMAIL: { primary: [], cc: [] },
      SMS: { primary: [], cc: [] },
      IN_APP: { primary: [], cc: [] },
      WEBHOOK: { primary: [], cc: [] },
    };

    const addRecipient = (
      recipient: NotificationRecipient,
      type: 'primary' | 'cc',
    ) => {
      (['EMAIL', 'SMS', 'IN_APP', 'WEBHOOK'] as NotificationChannel[]).forEach(
        (channel) => {
          if (this.doesRecipientAllowChannel(recipient, channel)) {
            result[channel][type].push(recipient);
          }
        },
      );
    };

    recipients.primary.forEach((recipient) =>
      addRecipient(recipient, 'primary'),
    );
    recipients.cc.forEach((recipient) => addRecipient(recipient, 'cc'));

    return result;
  }

  /**
   * Send email notification using EmailService (Doc 4 / Doc 5 §4.3).
   * Provider failures are captured as a channel-level error so that
   * the overall notification operation can still return a structured result.
   * Each send is also persisted into the notifications table.
   */
  private async sendEmailTaskNotification(
    task: NotifiableTask,
    eventType: TaskNotificationEventType,
    config: NotificationConfig,
    to: string[],
    cc: string[],
  ): Promise<NotificationChannelDispatchResult> {
    if (to.length === 0 && cc.length === 0) {
      return {
        channel: 'EMAIL',
        success: false,
        recipients: [],
        cc: [],
        error: 'No email recipients resolved',
      };
    }

    const templateId = this.getTemplateIdForEvent(config, eventType);
    const subject = this.buildEmailSubject(task, eventType);
    const variables = this.buildEmailTemplateVariables(task, eventType);

    const payloadForPersistence: Record<string, unknown> = {
      subject,
      templateId,
      variables,
      to,
      cc,
      eventType,
      taskId: task.taskId,
    };

    try {
      const result = await this.emailService.sendEmail({
        to,
        cc,
        subject,
        templateId,
        variables,
        senderName: config.channels.email.senderName,
        senderAddress: config.channels.email.senderAddress,
      });

      const status: NotificationStatusDb = result.ok ? 'sent' : 'failed';

      await this.persistNotificationRecord({
        organizationId: task.organizationId,
        channel: 'EMAIL',
        status,
        recipientUserId: null,
        recipientAddress: to[0] ?? cc[0] ?? null,
        templateId,
        relatedTaskId: task.taskId,
        payload: payloadForPersistence,
        errorMessage: result.ok ? null : result.error?.message ?? undefined,
      });

      if (!result.ok) {
        this.logger.warn(
          `Email notification failed for task ${task.taskId} (${eventType}): ${result.error?.message}`,
        );
      }

      return {
        channel: 'EMAIL',
        success: result.ok,
        recipients: to,
        cc,
        error: result.ok ? undefined : result.error?.message,
        providerMetadata: result.data ?? undefined,
      };
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Email notification threw for task ${task.taskId} (${eventType}): ${error.message}`,
        error.stack,
      );

      await this.persistNotificationRecord({
        organizationId: task.organizationId,
        channel: 'EMAIL',
        status: 'failed',
        recipientUserId: null,
        recipientAddress: to[0] ?? cc[0] ?? null,
        templateId,
        relatedTaskId: task.taskId,
        payload: payloadForPersistence,
        errorMessage: error.message,
      });

      return {
        channel: 'EMAIL',
        success: false,
        recipients: to,
        cc,
        error: error.message,
      };
    }
  }

  /**
   * In-app notifications for task events.
   * Currently persisted into notifications table with status=sent and
   * channel-ready payload (title/description + recipients/metadata).
   */
  private async sendInAppTaskNotification(
    task: NotifiableTask,
    eventType: TaskNotificationEventType,
    recipientIdentifiers: string[],
  ): Promise<NotificationChannelDispatchResult> {
    if (recipientIdentifiers.length === 0) {
      return {
        channel: 'IN_APP',
        success: false,
        recipients: [],
        error: 'No in-app recipients resolved',
      };
    }

    const payload: Record<string, unknown> = {
      taskId: task.taskId,
      organizationId: task.organizationId,
      eventType,
      recipients: recipientIdentifiers,
      title: this.buildEmailSubject(task, eventType),
      description: task.description,
    };

    await this.persistNotificationRecord({
      organizationId: task.organizationId,
      channel: 'IN_APP',
      status: 'sent',
      recipientUserId: null,
      recipientAddress: null,
      templateId: null,
      relatedTaskId: task.taskId,
      payload,
    });

    await this.safeLogEvent({
      category: 'TASK',
      logLevel: 'INFO',
      message: 'In-app notification emitted',
      identifier: `task_id:${task.taskId}`,
      metadata: {
        eventType,
        recipients: recipientIdentifiers,
      },
    });

    return {
      channel: 'IN_APP',
      success: true,
      recipients: recipientIdentifiers,
    };
  }

  private getTemplateIdForEvent(
    config: NotificationConfig,
    eventType: TaskNotificationEventType,
  ): string {
    switch (eventType) {
      case 'CREATED':
        return config.templates.taskCreated;
      case 'ASSIGNED':
        return config.templates.taskAssignment;
      case 'ESCALATED':
        return config.templates.taskEscalation;
      case 'COMPLETED':
        return config.templates.taskCompleted;
      default:
        // Fallback to created template for unknown events (should not occur).
        return config.templates.taskCreated;
    }
  }

  private buildEmailSubject(
    task: NotifiableTask,
    eventType: TaskNotificationEventType,
  ): string {
    const prefix = (() => {
      switch (eventType) {
        case 'CREATED':
          return '[Task Created]';
        case 'ASSIGNED':
          return '[Task Assigned]';
        case 'ESCALATED':
          return '[Task Escalated]';
        case 'COMPLETED':
          return '[Task Completed]';
        default:
          return '[Task Update]';
      }
    })();

    return `${prefix} ${task.title}`;
  }

  private buildEmailTemplateVariables(
    task: NotifiableTask,
    eventType: TaskNotificationEventType,
  ): Record<string, unknown> {
    return {
      taskId: task.taskId,
      organizationId: task.organizationId,
      title: task.title,
      description: task.description,
      label: task.label,
      status: task.status,
      priority: task.priority,
      severity: task.severity,
      visibility: task.visibility,
      source: task.source,
      ownerRoleId: task.ownerRoleId ?? null,
      ownerUserId: task.ownerUserId ?? null,
      assigneeRole: task.assigneeRole ?? null,
      createdByUserId: task.createdByUserId ?? null,
      requesterPersonId: task.requesterPersonId ?? null,
      metadata: task.metadata ?? {},
      eventType,
    };
  }

  /**
   * Normalise a single recipient identifier for logging / unimplemented channels.
   * Preference order: email → userId → displayName.
   */
  private normaliseRecipientIdentifier(
    recipient: NotificationRecipient,
  ): string | null {
    const email = (recipient.email || '').trim();
    if (email.length > 0) {
      return email;
    }

    const userId = (recipient.userId || '').trim();
    if (userId.length > 0) {
      return userId;
    }

    const displayName = (recipient.displayName || '').trim();
    if (displayName.length > 0) {
      return displayName;
    }

    return null;
  }

  private normaliseRecipientIdentifiers(recipients: {
    primary: NotificationRecipient[];
    cc: NotificationRecipient[];
  }): { to: string[]; cc: string[] } {
    const to = recipients.primary
      .map((recipient) => this.normaliseRecipientIdentifier(recipient))
      .filter((identifier): identifier is string => !!identifier);

    const cc = recipients.cc
      .map((recipient) => this.normaliseRecipientIdentifier(recipient))
      .filter((identifier): identifier is string => !!identifier);

    return { to, cc };
  }

  /**
   * Extract identifiers for IN_APP notifications.
   * Prefers userId; falls back to normalised identifiers if none present.
   * (Fixes the earlier malformed spread syntax).
   */
  private extractInAppRecipientIdentifiers(
    primaryRecipients: NotificationRecipient[],
    ccRecipients: NotificationRecipient[],
  ): string[] {
    const byUserId = [...primaryRecipients, ...ccRecipients]
      .map((recipient) => (recipient.userId || '').trim())
      .filter((userId) => userId.length > 0);

    if (byUserId.length > 0) {
      return byUserId;
    }

    const normalised = this.normaliseRecipientIdentifiers({
      primary: primaryRecipients,
      cc: ccRecipients,
    });

    return [...normalised.to, ...normalised.cc];
  }

  private extractEmails(recipients: NotificationRecipient[]): string[] {
    return recipients
      .map((r) => (r.email || '').trim())
      .filter((email) => email.length > 0);
  }

  /**
   * Persist a notification into the notifications table.
   * This is the central "queue" primitive for all channels; current
   * implementation persists final status (sent/failed) with channel-ready payload.
   */
  private async persistNotificationRecord(params: {
    organizationId?: string | null;
    channel: NotificationChannel;
    status: NotificationStatusDb;
    recipientUserId?: string | null;
    recipientAddress?: string | null;
    templateId?: string | null;
    relatedTaskId?: string | null;
    payload: Record<string, unknown>;
    queuedAt?: Date | null;
    sentAt?: Date | null;
    failedAt?: Date | null;
    errorMessage?: string | null;
  }): Promise<void> {
    const {
      organizationId,
      channel,
      status,
      recipientUserId,
      recipientAddress,
      templateId,
      relatedTaskId,
      payload,
      queuedAt,
      sentAt,
      failedAt,
      errorMessage,
    } = params;

    if (!organizationId) {
      // Without an org context we cannot enforce multi-tenant boundaries; skip persistence.
      return;
    }

    const now = new Date();
    const queuedAtEffective = queuedAt ?? now;

    try {
      await this.prisma.notification.create({
        data: {
          organization_id: organizationId,
          channel: this.toDbChannel(channel),
          status,
          recipient_user_id: recipientUserId ?? null,
          recipient_address: recipientAddress ?? null,
          template_id: templateId ?? null,
          payload,
          related_task_id: relatedTaskId ?? null,
          queued_at: queuedAtEffective,
          sent_at: sentAt ?? (status === 'sent' ? now : null),
          failed_at: failedAt ?? (status === 'failed' ? now : null),
          error_message: errorMessage ?? null,
        },
      });
    } catch (err) {
      const error = err as Error;
      this.logger.error(
        `Failed to persist notification record (channel=${channel}, status=${status}): ${error.message}`,
        error.stack,
      );
    }
  }

  private toDbChannel(channel: NotificationChannel): NotificationChannelDb {
    switch (channel) {
      case 'EMAIL':
        return 'email';
      case 'SMS':
        return 'sms';
      case 'IN_APP':
        return 'in_app';
      case 'WEBHOOK':
        return 'webhook';
      default:
        return 'email';
    }
  }

  /**
   * Resolve auth context (organizationId + userId) from the current request.
   * Used to enforce multi-tenant and per-user scoping for the feed and ad-hoc
   * in-app notifications.
   */
  private getAuthContextFromRequest(): AuthContext | null {
    const req = this.request as RequestWithAuthContext | undefined;
    if (!req) {
      return null;
    }

    const userFromReq = (req as any).user || {};

    const organizationId =
      (userFromReq && (userFromReq.organizationId as string | undefined)) ??
      (req as any).organizationId ??
      null;

    const userId =
      (userFromReq && (userFromReq.userId as string | undefined)) ??
      (req as any).userId ??
      (userFromReq && (userFromReq.id as string | undefined)) ??
      null;

    if (!organizationId || !userId) {
      return null;
    }

    return { organizationId, userId };
  }

  private getAuthContextOrThrow(): AuthContext {
    const ctx = this.getAuthContextFromRequest();
    if (!ctx) {
      throw new UnauthorizedException(
        'Authentication context is not available for notifications',
      );
    }
    return ctx;
  }

  /**
   * Feature flag helper: if the flag does not exist, treat it as "not gating"
   * and fall back to configuration (returns true).
   */
  private async isFeatureFlagEnabledOrUnset(
    code: string,
    organizationId: string | null,
    context: FeatureFlagEvaluationContext,
  ): Promise<boolean> {
    if (!this.featureFlagService) {
      return true;
    }

    try {
      const flag = await this.featureFlagService.getFlag(code, organizationId);

      if (!flag) {
        // No explicit flag configured; do not gate behaviour.
        return true;
      }

      return this.featureFlagService.isFeatureEnabled(code, {
        organizationId,
        context,
      });
    } catch (err) {
      const error = err as Error;
      this.logger.warn(
        `Feature flag evaluation failed for ${code} (org=${organizationId ?? 'null'}): ${error.message}. Defaulting to enabled.`,
      );
      return true;
    }
  }

  /**
   * Safely log notification-related events without allowing logging failures
   * to break the notification flow (Doc 5 §2.4).
   */
  private async safeLogEvent(event: {
    category: string;
    logLevel: 'DEBUG' | 'INFO' | 'WARN' | 'ERROR';
    message: string;
    identifier?: string;
    metadata?: Record<string, unknown>;
  }): Promise<void> {
    try {
      await this.logService.logEvent({
        ...event,
        metadata: {
          ...(event.metadata ?? {}),
          component: 'NotificationService',
        },
      });
    } catch (err) {
      const error = err as Error;
      this.logger.warn(
        `Failed to log notification event (${event.message}): ${error.message}`,
      );
    }
  }
}


=== FILE 29/48: apps/api/src/orgo/core/offline/offline-sync.module.ts ===

// apps/api/src/orgo/core/offline/offline-sync.module.ts

import { Module } from '@nestjs/common';
import { DatabaseModule } from '../database/database.module';
import { SyncService } from './sync.service';

/**
 * OfflineSyncModule
 *
 * Core Services – Offline & Sync.
 *
 * Wires up SyncService, which coordinates sync sessions between offline
 * nodes (SQLite) and the central Postgres database using:
 *  - offline_nodes
 *  - sync_sessions
 *  - sync_conflicts
 *  - tasks
 *
 * Depends on:
 *  - DatabaseModule (DatabaseService / Prisma access).
 */
@Module({
  imports: [DatabaseModule],
  providers: [SyncService],
  exports: [SyncService],
})
export class OfflineSyncModule {}


=== FILE 30/48: apps/api/src/orgo/core/offline/sync.service.ts ===

// apps/api/src/orgo/core/offline/sync.service.ts

import { Injectable, Logger } from '@nestjs/common';
import { DatabaseService } from '../database/database.service';

export type SyncDirection = 'upload' | 'download' | 'bidirectional';

export interface OfflineTaskChange {
  /**
   * Operation performed on the offline node.
   * - insert: new task created on the offline node
   * - update: existing task updated on the offline node
   * - delete: task deleted/voided on the offline node (mapped to CANCELLED)
   */
  operation: 'insert' | 'update' | 'delete';

  /**
   * Task identifier as known on the server (tasks.id / task_id).
   * For inserts this can be omitted; for updates/deletes it should be provided
   * if the offline node already knows the server ID.
   */
  taskId?: string;

  /**
   * The client-side representation of the task after the operation.
   * This is stored/merged into the canonical tasks row.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  data: Record<string, any>;

  /**
   * Snapshot of the server version that the client last saw when applying
   * this change. Used for optimistic concurrency / conflict detection.
   * If omitted, the change is applied with "last write wins" semantics.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  serverVersion?: Record<string, any> | null;
}

export interface OfflineSyncPayload {
  /**
   * Tenant isolation key; this must match organizations.id.
   */
  organizationId: string;

  /**
   * Stable identifier for the offline node (e.g. device id / host slug).
   * Maps to offline_nodes.node_identifier.
   */
  nodeIdentifier: string;

  /**
   * Direction of sync:
   * - upload: client → server only
   * - download: server → client only
   * - bidirectional: upload then download in a single session
   */
  direction: SyncDirection;

  /**
   * Last successful sync timestamp as known by the client (ISO‑8601).
   * This is used as a hint when building the download snapshot.
   */
  clientLastSyncAt?: string | null;

  /**
   * Offline task changes to upload. Only used when direction includes "upload".
   */
  taskChanges?: OfflineTaskChange[];
}

export interface SyncSummary {
  uploadedTasks: number;
  createdTasks: number;
  updatedTasks: number;
  deletedTasks: number;
  conflicts: number;
  downloadedTasks: number;
}

export interface DownloadSnapshot {
  /**
   * Tasks changed on the server since last sync and relevant to this org.
   * Shape is the raw tasks rows; filtering/normalisation is handled by the client.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  tasks: any[];
}

export interface SyncResult {
  sessionId: string;
  nodeId: string;
  direction: SyncDirection;
  summary: SyncSummary;
  /**
   * Optional download snapshot (only present when direction is "download"
   * or "bidirectional").
   */
  download?: DownloadSnapshot;
}

/**
 * SyncService
 *
 * Coordinates sync sessions between SQLite‑backed offline nodes and the
 * central Postgres database using:
 *  - offline_nodes
 *  - sync_sessions
 *  - sync_conflicts
 *  - tasks
 *
 * This service is intentionally generic and does not embed domain logic.
 * It works with the canonical Task model and multi‑tenant invariants.
 * It always runs against the ONLINE Postgres database via DatabaseService.
 */
@Injectable()
export class SyncService {
  private readonly logger = new Logger(SyncService.name);

  constructor(private readonly db: DatabaseService) {}

  /**
   * High-level entry point for synchronising an offline node.
   *
   * 1. Ensures offline_nodes row exists for (organizationId, nodeIdentifier).
   * 2. Creates a sync_sessions row in "running" state.
   * 3. Applies uploaded changes (if direction === upload|bidirectional).
   * 4. Builds a download snapshot (if direction === download|bidirectional).
   * 5. Marks the sync_sessions row as completed/failed with summary + error.
   * 6. Updates offline_nodes.last_sync_at on success.
   */
  async syncOfflineNode(payload: OfflineSyncPayload): Promise<SyncResult> {
    const { organizationId, nodeIdentifier, direction } = payload;

    if (!organizationId) {
      throw new Error('organizationId is required for offline sync');
    }
    if (!nodeIdentifier) {
      throw new Error('nodeIdentifier is required for offline sync');
    }
    if (!direction) {
      throw new Error('direction is required for offline sync');
    }

    const prisma = this.getPrismaClient();

    const summary: SyncSummary = {
      uploadedTasks: 0,
      createdTasks: 0,
      updatedTasks: 0,
      deletedTasks: 0,
      conflicts: 0,
      downloadedTasks: 0,
    };

    // 1. Ensure offline_nodes row exists
    const offlineNode = await this.ensureOfflineNode(
      prisma,
      organizationId,
      nodeIdentifier,
    );

    // 2. Start sync session (sync_sessions)
    const session = await this.startSyncSession(
      prisma,
      offlineNode.id,
      direction,
    );

    let download: DownloadSnapshot | undefined;

    try {
      // 3. Apply upload changes
      if (direction === 'upload' || direction === 'bidirectional') {
        await this.applyTaskUploadChanges(
          prisma,
          session.id,
          organizationId,
          payload.taskChanges ?? [],
          summary,
        );
      }

      // 4. Build download snapshot
      if (direction === 'download' || direction === 'bidirectional') {
        download = await this.buildDownloadSnapshot(
          prisma,
          organizationId,
          offlineNode,
          payload.clientLastSyncAt ?? null,
          summary,
        );
      }

      // 5. Mark session as completed
      await this.completeSyncSession(prisma, session.id, 'completed', summary);

      // 6. Update offline_nodes.last_sync_at
      await prisma.offlineNode.update({
        where: { id: offlineNode.id },
        data: { last_sync_at: new Date() },
      });

      this.logger.log(
        `Offline sync completed for node=${nodeIdentifier} org=${organizationId} direction=${direction}`,
      );

      return {
        sessionId: session.id,
        nodeId: offlineNode.id,
        direction,
        summary,
        download,
      };
    } catch (error) {
      this.logger.error(
        `Offline sync failed for node=${nodeIdentifier} org=${organizationId}: ${
          (error as Error).message
        }`,
        (error as Error).stack,
      );

      await this.completeSyncSession(
        prisma,
        session.id,
        'failed',
        summary,
        error,
      );

      throw error;
    }
  }

  /**
   * Convenience entry point for task‑only upload jobs (e.g. queue job
   * orgo.db.sync-offline). It simply delegates to syncOfflineNode with
   * direction "upload".
   */
  async syncOfflineTasks(payload: OfflineSyncPayload): Promise<SyncResult> {
    return this.syncOfflineNode({ ...payload, direction: 'upload' });
  }

  // ---------------------------------------------------------------------------
  // Internal helpers
  // ---------------------------------------------------------------------------

  /**
   * Obtain a PrismaClient from the DatabaseService.
   * This is intentionally tolerant to slight variations in DatabaseService
   * implementations (prisma vs getPrismaClient()).
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private getPrismaClient(): any {
    const anyDb = this.db as any;

    if (typeof anyDb.getPrismaClient === 'function') {
      return anyDb.getPrismaClient();
    }

    if (anyDb.prisma) {
      return anyDb.prisma;
    }

    return anyDb;
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async ensureOfflineNode(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    organizationId: string,
    nodeIdentifier: string,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ): Promise<any> {
    const existing = await prisma.offlineNode.findFirst({
      where: {
        organization_id: organizationId,
        node_identifier: nodeIdentifier,
      },
    });

    if (existing) {
      return existing;
    }

    this.logger.log(
      `Creating offline node for org=${organizationId}, node=${nodeIdentifier}`,
    );

    return prisma.offlineNode.create({
      data: {
        organization_id: organizationId,
        node_identifier: nodeIdentifier,
        status: 'active', // offline_nodes.status enum: active | inactive | retired
        last_sync_at: null,
      },
    });
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async startSyncSession(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    offlineNodeId: string,
    direction: SyncDirection,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ): Promise<any> {
    return prisma.syncSession.create({
      data: {
        offline_node_id: offlineNodeId,
        direction,
        status: 'running', // sync_sessions.status enum: running | completed | failed
        started_at: new Date(),
        summary: {},
        error_message: null,
      },
    });
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async completeSyncSession(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    sessionId: string,
    status: 'completed' | 'failed',
    summary: SyncSummary,
    error?: unknown,
  ): Promise<void> {
    await prisma.syncSession.update({
      where: { id: sessionId },
      data: {
        status,
        finished_at: new Date(),
        summary,
        error_message: error ? String((error as Error).message ?? error) : null,
      },
    });
  }

  /**
   * Apply uploaded task changes from an offline node to the central tasks table.
   * Enforces:
   *  - multi-tenant safety (organization_id checks),
   *  - optimistic concurrency via serverVersion / updated_at,
   *  - conflict logging into sync_conflicts,
   *  - soft-delete semantics (CANCELLED) for deletes.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async applyTaskUploadChanges(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    sessionId: string,
    organizationId: string,
    changes: OfflineTaskChange[],
    summary: SyncSummary,
  ): Promise<void> {
    if (!changes.length) {
      return;
    }

    summary.uploadedTasks += changes.length;

    for (const change of changes) {
      const baseTaskId =
        change.taskId ??
        (change.data.task_id as string | undefined) ??
        (change.data.id as string | undefined);

      switch (change.operation) {
        case 'insert': {
          // Never allow offline nodes to override identity/tenant fields.
          const data = { ...change.data };

          delete (data as any).id;
          delete (data as any).task_id;
          delete (data as any).taskId;
          delete (data as any).organization_id;
          delete (data as any).organizationId;

          await prisma.task.create({
            data: {
              ...data,
              organization_id: organizationId,
            },
          });
          summary.createdTasks += 1;
          break;
        }

        case 'update': {
          if (!baseTaskId) {
            this.logger.warn(
              'Skipping offline update without taskId or data.id',
            );
            continue;
          }

          const serverRow = await prisma.task.findUnique({
            where: { id: baseTaskId },
          });

          if (!serverRow) {
            // If server no longer has the row, treat as create for this org.
            const data = { ...change.data };

            delete (data as any).id;
            delete (data as any).task_id;
            delete (data as any).taskId;
            delete (data as any).organization_id;
            delete (data as any).organizationId;

            await prisma.task.create({
              data: {
                ...data,
                organization_id: organizationId,
              },
            });
            summary.createdTasks += 1;
            break;
          }

          const serverOrgId =
            (serverRow as any).organization_id ??
            (serverRow as any).organizationId ??
            (serverRow as any).org_id ??
            null;

          if (serverOrgId && serverOrgId !== organizationId) {
            this.logger.error(
              `Cross-tenant offline update prevented for task=${baseTaskId}: server organization=${serverOrgId}, client organization=${organizationId}`,
            );

            await this.recordConflict(
              prisma,
              sessionId,
              'task',
              baseTaskId,
              serverRow,
              change.data,
            );
            summary.conflicts += 1;
            break;
          }

          if (this.hasVersionConflict(serverRow, change.serverVersion)) {
            await this.recordConflict(
              prisma,
              sessionId,
              'task',
              baseTaskId,
              serverRow,
              change.data,
            );
            summary.conflicts += 1;
            break;
          }

          const data = { ...change.data };

          delete (data as any).id;
          delete (data as any).task_id;
          delete (data as any).taskId;
          delete (data as any).organization_id;
          delete (data as any).organizationId;

          await prisma.task.update({
            where: { id: baseTaskId },
            data,
          });
          summary.updatedTasks += 1;
          break;
        }

        case 'delete': {
          if (!baseTaskId) {
            this.logger.warn(
              'Skipping offline delete without taskId or data.id',
            );
            continue;
          }

          const serverRow = await prisma.task.findUnique({
            where: { id: baseTaskId },
          });

          if (!serverRow) {
            // Already deleted on the server; nothing to do.
            break;
          }

          const serverOrgId =
            (serverRow as any).organization_id ??
            (serverRow as any).organizationId ??
            (serverRow as any).org_id ??
            null;

          if (serverOrgId && serverOrgId !== organizationId) {
            this.logger.error(
              `Cross-tenant offline delete prevented for task=${baseTaskId}: server organization=${serverOrgId}, client organization=${organizationId}`,
            );

            await this.recordConflict(
              prisma,
              sessionId,
              'task',
              baseTaskId,
              serverRow,
              change.data,
            );
            summary.conflicts += 1;
            break;
          }

          if (this.hasVersionConflict(serverRow, change.serverVersion)) {
            await this.recordConflict(
              prisma,
              sessionId,
              'task',
              baseTaskId,
              serverRow,
              change.data,
            );
            summary.conflicts += 1;
            break;
          }

          // Map delete to a canonical CANCELLED transition; we do not hard‑delete
          // tasks because they are part of the audit trail.
          await prisma.task.update({
            where: { id: baseTaskId },
            data: {
              status: 'CANCELLED',
              closed_at: new Date(),
            },
          });
          summary.deletedTasks += 1;
          break;
        }

        default: {
          this.logger.warn(
            `Unknown offline task operation: ${(change as any).operation}`,
          );
          break;
        }
      }
    }
  }

  /**
   * Returns true if there is a conflict between the current server row and the
   * version the client claims to have seen.
   *
   * Conflict heuristic:
   *  - If client provided serverVersion.updated_at and it differs from the
   *    current server updated_at, treat as conflict.
   *  - If no version information is provided, no conflict is detected.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private hasVersionConflict(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    serverRow: any,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    clientServerVersion?: Record<string, any> | null,
  ): boolean {
    if (!clientServerVersion) {
      return false;
    }

    const serverUpdatedAt =
      serverRow.updated_at ?? serverRow.updatedAt ?? serverRow.updated_at_utc;
    const clientUpdatedAt =
      clientServerVersion.updated_at ??
      clientServerVersion.updatedAt ??
      clientServerVersion.updated_at_utc;

    if (!serverUpdatedAt || !clientUpdatedAt) {
      return false;
    }

    const serverTime = new Date(serverUpdatedAt).getTime();
    const clientTime = new Date(clientUpdatedAt).getTime();

    return serverTime !== clientTime;
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async recordConflict(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    sessionId: string,
    entityType: string,
    entityId: string,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    serverVersion: any,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    clientVersion: any,
  ): Promise<void> {
    await prisma.syncConflict.create({
      data: {
        sync_session_id: sessionId,
        entity_type: entityType,
        entity_id: entityId,
        server_version: serverVersion,
        client_version: clientVersion,
        resolution_strategy: 'manual_review',
        resolved: false,
        resolved_at: null,
        resolved_by_user_id: null,
      },
    });

    this.logger.warn(
      `Recorded sync conflict for entity_type=${entityType} entity_id=${entityId} session_id=${sessionId}`,
    );
  }

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async buildDownloadSnapshot(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    prisma: any,
    organizationId: string,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    offlineNode: any,
    clientLastSyncAt: string | null | undefined,
    summary: SyncSummary,
  ): Promise<DownloadSnapshot> {
    const lastSyncIso =
      clientLastSyncAt ??
      (offlineNode.last_sync_at
        ? new Date(offlineNode.last_sync_at).toISOString()
        : null);

    const lastSyncDate = lastSyncIso ? new Date(lastSyncIso) : new Date(0);

    const tasks = await prisma.task.findMany({
      where: {
        organization_id: organizationId,
        updated_at: {
          gt: lastSyncDate,
        },
      },
    });

    summary.downloadedTasks = tasks.length;

    return { tasks };
  }
}


=== FILE 31/48: apps/api/src/orgo/core/signals/dto/create-signal.dto.ts ===

import { ApiProperty, ApiPropertyOptional } from '@nestjs/swagger';
import {
  IsUUID,
  IsString,
  IsOptional,
  IsNotEmpty,
  IsIn,
  IsObject,
} from 'class-validator';
import { Transform } from 'class-transformer';

export const TASK_CATEGORY_VALUES = [
  'request',
  'incident',
  'update',
  'report',
  'distribution',
] as const;

export type TaskCategory = (typeof TASK_CATEGORY_VALUES)[number];

export const TASK_PRIORITY_VALUES = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'] as const;
export type TaskPriority = (typeof TASK_PRIORITY_VALUES)[number];

export const TASK_SEVERITY_VALUES = ['MINOR', 'MODERATE', 'MAJOR', 'CRITICAL'] as const;
export type TaskSeverity = (typeof TASK_SEVERITY_VALUES)[number];

export const VISIBILITY_VALUES = [
  'PUBLIC',
  'INTERNAL',
  'RESTRICTED',
  'ANONYMISED',
] as const;
export type Visibility = (typeof VISIBILITY_VALUES)[number];

export const TASK_SOURCE_VALUES = ['email', 'api', 'manual', 'sync'] as const;
export type TaskSource = (typeof TASK_SOURCE_VALUES)[number];

/**
 * DTO for ingesting a generic Signal via API / UI / webhooks.
 *
 * The goal is to capture enough structured information for the workflow engine
 * to decide whether to open a Case, create Task(s), or both.
 *
 * Many fields are optional hints; profiles + workflows can override them.
 */
export class CreateSignalDto {
  @ApiProperty({
    description: 'Organization this signal belongs to (tenant ID).',
    format: 'uuid',
  })
  @IsUUID('4')
  organizationId!: string;

  @ApiPropertyOptional({
    description:
      'Optional idempotency key or external correlation id from the source system.',
    example: 'ext-incident-12345',
  })
  @IsOptional()
  @IsString()
  externalId?: string;

  @ApiPropertyOptional({
    description:
      'Optional existing Case to attach this signal to (otherwise workflows may open a new Case).',
    format: 'uuid',
  })
  @IsOptional()
  @IsUUID('4')
  caseId?: string;

  @ApiProperty({
    description: 'Origin of this signal, reusing the task source enumeration.',
    enum: TASK_SOURCE_VALUES,
    example: 'api',
  })
  @IsString()
  @IsIn(TASK_SOURCE_VALUES)
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toLowerCase() : value,
  )
  source!: TaskSource;

  @ApiProperty({
    description: 'Short human-readable summary for this signal.',
    example: 'Student slipped on wet floor in main lobby',
  })
  @IsString()
  @IsNotEmpty()
  title!: string;

  @ApiProperty({
    description: 'Free-text body or description of the signal.',
    example:
      'A student slipped on a wet floor near the main entrance. No visible injuries, but this has happened several times this month.',
  })
  @IsString()
  @IsNotEmpty()
  description!: string;

  @ApiPropertyOptional({
    description:
      'Domain type hint; should match Task.type / domain module name (e.g. "maintenance", "hr_case").',
    example: 'maintenance',
  })
  @IsOptional()
  @IsString()
  type?: string;

  @ApiPropertyOptional({
    description:
      'Optional Task.category hint. If omitted, workflows will derive it.',
    enum: TASK_CATEGORY_VALUES,
    example: 'incident',
  })
  @IsOptional()
  @IsString()
  @IsIn(TASK_CATEGORY_VALUES)
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toLowerCase() : value,
  )
  category?: TaskCategory;

  @ApiPropertyOptional({
    description:
      'Domain-specific subtype hint; must be valid for the chosen domain module (e.g. "ticket", "harassment").',
    example: 'ticket',
  })
  @IsOptional()
  @IsString()
  subtype?: string;

  @ApiPropertyOptional({
    description:
      'Optional canonical label hint ("<base>.<category><subcategory>.<horizontal_role>").',
    example: '100.94.Operations.Safety',
  })
  @IsOptional()
  @IsString()
  label?: string;

  @ApiPropertyOptional({
    description:
      'Optional priority hint; defaults are derived from org profile and workflows.',
    enum: TASK_PRIORITY_VALUES,
    example: 'HIGH',
  })
  @IsOptional()
  @IsString()
  @IsIn(TASK_PRIORITY_VALUES)
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toUpperCase() : value,
  )
  priority?: TaskPriority;

  @ApiPropertyOptional({
    description:
      'Optional severity hint; defaults are derived from org profile and workflows.',
    enum: TASK_SEVERITY_VALUES,
    example: 'MAJOR',
  })
  @IsOptional()
  @IsString()
  @IsIn(TASK_SEVERITY_VALUES)
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toUpperCase() : value,
  )
  severity?: TaskSeverity;

  @ApiPropertyOptional({
    description:
      'Optional visibility hint for any Task/Case created from this signal. Guardrails may override this.',
    enum: VISIBILITY_VALUES,
    example: 'INTERNAL',
  })
  @IsOptional()
  @IsString()
  @IsIn(VISIBILITY_VALUES)
  @Transform(({ value }) =>
    typeof value === 'string' ? value.toUpperCase() : value,
  )
  visibility?: Visibility;

  @ApiPropertyOptional({
    description:
      'If set, the Person profile this signal is primarily about (subject of the Case/Task).',
    format: 'uuid',
  })
  @IsOptional()
  @IsUUID('4')
  requesterPersonId?: string;

  @ApiPropertyOptional({
    description:
      'If set, the Orgo user who submitted this signal (mapped to created_by_user_id on Tasks).',
    format: 'uuid',
  })
  @IsOptional()
  @IsUUID('4')
  createdByUserId?: string;

  @ApiPropertyOptional({
    description:
      'Optional external reference or URL related to the signal (ticket id, form submission id, etc.).',
    example: 'JIRA-1234',
  })
  @IsOptional()
  @IsString()
  sourceReference?: string;

  @ApiPropertyOptional({
    description:
      'Arbitrary structured payload for domain-specific context (location, group ids, tags, raw form data, etc.). Must not duplicate canonical Task fields.',
    type: Object,
  })
  @IsOptional()
  @IsObject()
  metadata?: Record<string, any>;
}


=== FILE 32/48: apps/api/src/orgo/core/signals/signal-ingest.service.ts ===

// apps/api/src/orgo/core/signals/signal-ingest.service.ts

import { Injectable, Logger } from '@nestjs/common';

import {
  LogCategory,
  LogLevel,
  LogService,
} from '../logging/log.service';
import { FN_SIGNAL_INGEST } from '../functional-ids';

import {
  WorkflowContext,
  WorkflowEngineResult,
  WorkflowExecutionResultData,
  ResolvedWorkflowAction,
  WorkflowEngineService,
} from '../workflow/workflow-engine.service';

import {
  TaskService,
  CreateTaskInput,
  TaskDto,
  TaskCategory,
  TaskPriority,
  TaskSeverity,
  TaskVisibility,
  TaskSource,
} from '../tasks/task.service';

import { CreateSignalDto } from './dto/create-signal.dto';

/**
 * Standard error shape (Doc 5 §2.4).
 */
export interface StandardError {
  code: string;
  message: string;
  details?: unknown;
}

/**
 * Standard result shape (ok / data / error).
 */
export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardError | null;
}

/**
 * Result payload for SignalIngestService.ingest.
 */
export interface SignalIngestResult {
  organizationId: string;
  source: TaskSource | string;
  /**
   * Full workflow execution details (matched rules + resolved actions).
   */
  workflowExecution: WorkflowExecutionResultData;
  /**
   * Tasks created as a consequence of workflow actions.
   */
  createdTasks: TaskDto[];
}

/**
 * Normalised in-memory representation of a Signal, derived from the
 * public CreateSignalDto or the legacy snake_case DTO.
 */
interface NormalizedSignal {
  organizationId: string;
  externalId?: string;
  caseId?: string;
  source: TaskSource | string;

  type?: string;
  category?: TaskCategory;
  subtype?: string;
  label?: string;

  title: string;
  description: string;

  priority?: TaskPriority | Lowercase<TaskPriority>;
  severity?: TaskSeverity | Lowercase<TaskSeverity>;
  visibility?: TaskVisibility | Lowercase<TaskVisibility>;

  requesterPersonId?: string;
  createdByUserId?: string;
  sourceReference?: string;

  metadata?: Record<string, any>;

  /**
   * Original raw DTO, kept for logging / debugging.
   */
  raw: unknown;
}

/**
 * Legacy DTO shape used in the earlier SignalController implementation
 * (snake_case keys, enum-less source).
 *
 * This is defined here for structural compatibility; the controller's
 * class-based DTO will be assignable to this interface.
 */
interface LegacySignalDto {
  organization_id: string;
  source: 'email' | 'api' | 'manual' | 'sync';
  type?: string;
  title?: string;
  description?: string;
  label?: string;
  created_by_user_id?: string;
  requester_person_id?: string;
  payload?: Record<string, unknown>;
}

type SignalInput = CreateSignalDto | LegacySignalDto;

@Injectable()
export class SignalIngestService {
  private readonly logger = new Logger(SignalIngestService.name);

  constructor(
    private readonly workflowEngine: WorkflowEngineService,
    private readonly taskService: TaskService,
    private readonly logService: LogService,
  ) {}

  /**
   * Core entry point for API / UI / webhook signals.
   *
   * Responsibilities (aligned with Docs 2, 4, 5 and 8):
   *  - Normalise the incoming payload into a canonical Signal shape.
   *  - Build a WorkflowContext from that Signal.
   *  - Execute workflow rules via WorkflowEngineService.
   *  - Apply CREATE_TASK actions by delegating to TaskService.
   *  - Return a standard { ok, data, error } envelope.
   */
  async ingest(dto: SignalInput): Promise<StandardResult<SignalIngestResult>> {
    const normalisedResult = this.normaliseSignal(dto);

    if (!normalisedResult.ok || !normalisedResult.data) {
      // Propagate validation/normalisation errors in the standard shape,
      // but with the SignalIngestResult data type.
      return {
        ok: false,
        data: null,
        error: normalisedResult.error,
      };
    }

    const signal = normalisedResult.data;

    const workflowContext: WorkflowContext = {
      // WorkflowEngineService expects camelCase organizationId + WorkflowEventSource.
      organizationId: signal.organizationId,
      // All non-email signals are treated as coming from the "API" event source.
      source: 'API',
      type: signal.type,
      category: signal.category,
      severity: signal.severity,
      label: signal.label,
      title: signal.title,
      description: signal.description,
      metadata: {
        ...(signal.metadata ?? {}),
        organizationId: signal.organizationId,
        externalId: signal.externalId ?? null,
        caseId: signal.caseId ?? null,
        sourceReference: signal.sourceReference ?? null,
        createdByUserId: signal.createdByUserId ?? null,
        requesterPersonId: signal.requesterPersonId ?? null,
        signalSource: signal.source,
      },
      payload: {
        signal,
        raw: dto,
      },
    };

    let workflowResult: WorkflowEngineResult<WorkflowExecutionResultData>;

    try {
      workflowResult = await this.workflowEngine.executeWorkflow(workflowContext);
    } catch (err: unknown) {
      const error: StandardError = {
        code: 'SIGNAL_WORKFLOW_EXECUTION_ERROR',
        message: 'Failed to execute workflow for signal.',
        details: {
          organizationId: signal.organizationId,
          error:
            err instanceof Error ? err.message : (err as string | unknown),
        },
      };

      await this.logService.logEvent({
        category: LogCategory.WORKFLOW,
        level: LogLevel.ERROR,
        message: error.message,
        identifier: FN_SIGNAL_INGEST,
        metadata: {
          functionId: FN_SIGNAL_INGEST,
          stage: 'workflow_execute_throw',
          organizationId: signal.organizationId,
          source: signal.source,
          error: error.details,
        },
      });

      this.logger.error(
        `Workflow execution failed for signal (org=${signal.organizationId})`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );

      return {
        ok: false,
        data: null,
        error,
      };
    }

    if (!workflowResult.ok || !workflowResult.data) {
      const error: StandardError = {
        code:
          workflowResult.error?.code ?? 'SIGNAL_WORKFLOW_EXECUTION_FAILED',
        message:
          workflowResult.error?.message ??
          'Workflow execution failed for signal.',
        details: workflowResult.error?.details,
      };

      await this.logService.logEvent({
        category: LogCategory.WORKFLOW,
        level: LogLevel.ERROR,
        message: error.message,
        identifier: FN_SIGNAL_INGEST,
        metadata: {
          functionId: FN_SIGNAL_INGEST,
          stage: 'workflow_execute_result_error',
          organizationId: signal.organizationId,
          source: signal.source,
          error: error.details,
        },
      });

      return {
        ok: false,
        data: null,
        error,
      };
    }

    const execution = workflowResult.data;

    const createdTasks: TaskDto[] = [];
    const failedActions: StandardError[] = [];

    // Apply CREATE_TASK actions only; other action types (ROUTE, ESCALATE, NOTIFY)
    // are intentionally left for future extensions or domain-specific services.
    for (const resolved of execution.actions) {
      if (resolved.action.type !== 'CREATE_TASK') {
        continue;
      }

      const result = await this.applyCreateTaskAction(signal, resolved);

      if (!result.ok || !result.data) {
        failedActions.push(
          result.error ?? {
            code: 'SIGNAL_CREATE_TASK_FAILED',
            message: 'Task creation failed for signal (no error payload).',
          },
        );
        continue;
      }

      createdTasks.push(result.data);
    }

    if (failedActions.length > 0) {
      await this.logService.logEvent({
        category: LogCategory.TASK,
        level: LogLevel.ERROR,
        message:
          'One or more CREATE_TASK actions failed while ingesting signal.',
        identifier: FN_SIGNAL_INGEST,
        metadata: {
          functionId: FN_SIGNAL_INGEST,
          organizationId: signal.organizationId,
          source: signal.source,
          failedActions,
        },
      });
    }

    await this.logService.logEvent({
      category: LogCategory.WORKFLOW,
      level: LogLevel.INFO,
      message: 'Signal ingested via API / UI.',
      identifier: FN_SIGNAL_INGEST,
      metadata: {
        functionId: FN_SIGNAL_INGEST,
        organizationId: signal.organizationId,
        source: signal.source,
        matchedRuleIds: execution.matchedRules.map((r) => r.id),
        createdTaskIds: createdTasks.map((t) => t.taskId ?? t.task_id),
      },
    });

    return {
      ok: true,
      data: {
        organizationId: signal.organizationId,
        source: signal.source,
        workflowExecution: execution,
        createdTasks,
      },
      error: null,
    };
  }

  /**
   * Normalise either the new CreateSignalDto or the legacy snake_case DTO
   * into a single internal NormalizedSignal shape.
   */
  private normaliseSignal(dto: SignalInput): StandardResult<NormalizedSignal> {
    try {
      const isLegacy =
        (dto as LegacySignalDto).organization_id !== undefined;

      if (isLegacy) {
        const legacy = dto as LegacySignalDto;

        if (!legacy.organization_id || !legacy.source) {
          return {
            ok: false,
            data: null,
            error: {
              code: 'SIGNAL_VALIDATION_ERROR',
              message:
                'organization_id and source are required to ingest a signal.',
              details: { dto },
            },
          };
        }

        const title =
          legacy.title && legacy.title.trim()
            ? legacy.title.trim()
            : `Signal from ${legacy.source}`;

        const description =
          legacy.description && legacy.description.trim()
            ? legacy.description.trim()
            : title;

        const normalised: NormalizedSignal = {
          organizationId: legacy.organization_id,
          source: legacy.source,
          type: legacy.type,
          title,
          description,
          label: legacy.label,
          createdByUserId: legacy.created_by_user_id,
          requesterPersonId: legacy.requester_person_id,
          metadata: legacy.payload ? { ...legacy.payload } : undefined,
          raw: dto,
        };

        return {
          ok: true,
          data: normalised,
          error: null,
        };
      }

      const modern = dto as CreateSignalDto;

      if (
        !modern.organizationId ||
        !modern.source ||
        !modern.title ||
        !modern.description
      ) {
        return {
          ok: false,
          data: null,
          error: {
            code: 'SIGNAL_VALIDATION_ERROR',
            message:
              'organizationId, source, title and description are required to ingest a signal.',
            details: { dto },
          },
        };
      }

      const normalised: NormalizedSignal = {
        organizationId: modern.organizationId,
        externalId: modern.externalId,
        caseId: modern.caseId,
        source: modern.source as TaskSource | string,
        type: modern.type,
        category: modern.category as TaskCategory | undefined,
        subtype: modern.subtype,
        label: modern.label,
        title: modern.title,
        description: modern.description,
        priority: modern.priority as
          | TaskPriority
          | Lowercase<TaskPriority>
          | undefined,
        severity: modern.severity as
          | TaskSeverity
          | Lowercase<TaskSeverity>
          | undefined,
        visibility: modern.visibility as
          | TaskVisibility
          | Lowercase<TaskVisibility>
          | undefined,
        requesterPersonId: modern.requesterPersonId,
        createdByUserId: modern.createdByUserId,
        sourceReference: modern.sourceReference,
        metadata: modern.metadata ? { ...modern.metadata } : undefined,
        raw: dto,
      };

      return {
        ok: true,
        data: normalised,
        error: null,
      };
    } catch (err: unknown) {
      const error: StandardError = {
        code: 'SIGNAL_NORMALISATION_ERROR',
        message: 'Failed to normalise signal payload.',
        details: {
          error:
            err instanceof Error ? err.message : (err as string | unknown),
        },
      };

      this.logger.error(
        `Failed to normalise signal payload: ${
          err instanceof Error ? err.stack ?? err.message : String(err)
        }`,
      );

      // Best-effort structured log for observability; failures here must not
      // break the original error path.
      this.logService
        .logEvent({
          category: LogCategory.WORKFLOW,
          level: LogLevel.ERROR,
          message: error.message,
          identifier: FN_SIGNAL_INGEST,
          metadata: {
            functionId: FN_SIGNAL_INGEST,
            stage: 'normalise_signal_error',
            error: error.details,
          },
        })
        .catch((logErr) => {
          this.logger.warn(
            `Failed to write signal normalisation log event: ${
              logErr instanceof Error ? logErr.message : String(logErr)
            }`,
          );
        });

      return {
        ok: false,
        data: null,
        error,
      };
    }
  }

  /**
   * Apply a single CREATE_TASK workflow action by building a CreateTaskInput
   * from the normalised Signal plus action.set overrides, then delegating
   * to TaskService.
   */
  private async applyCreateTaskAction(
    signal: NormalizedSignal,
    resolved: ResolvedWorkflowAction,
  ): Promise<StandardResult<TaskDto>> {
    const action = resolved.action;
    const set = (action.set ?? {}) as Record<string, unknown>;

    const mergeString = (
      override: unknown,
      base: string | undefined | null,
      fallback: string,
    ): string =>
      typeof override === 'string' && override.trim()
        ? override.trim()
        : base && base.trim()
        ? base.trim()
        : fallback;

    const mergeOptionalString = (
      override: unknown,
      base?: string | null,
    ): string | null =>
      typeof override === 'string' && override.trim()
        ? override.trim()
        : base && base.trim()
        ? base.trim()
        : null;

    const mergedCategory =
      (set.category as TaskCategory | undefined) ??
      (signal.category as TaskCategory | undefined) ??
      ('request' as TaskCategory);

    const mergedPriority =
      (set.priority as TaskPriority | Lowercase<TaskPriority> | undefined) ??
      signal.priority ??
      ('MEDIUM' as TaskPriority);

    const mergedSeverity =
      (set.severity as TaskSeverity | Lowercase<TaskSeverity> | undefined) ??
      signal.severity ??
      ('MINOR' as TaskSeverity);

    const mergedVisibility =
      (set.visibility as TaskVisibility | Lowercase<TaskVisibility> | undefined) ??
      signal.visibility ??
      ('INTERNAL' as TaskVisibility);

    const mergedSource =
      (set.source as TaskSource | string | undefined) ??
      signal.source ??
      'api';

    const mergedLabel = mergeString(
      set.label,
      signal.label,
      '000.00.Unclassified',
    );

    const createInput: CreateTaskInput = {
      organizationId: signal.organizationId,
      type: mergeString(set.type, signal.type, 'generic'),
      category: mergedCategory,
      title: mergeString(set.title, signal.title, 'Signal'),
      description: mergeString(
        set.description,
        signal.description,
        'Signal ingested via API/UI.',
      ),
      priority: mergedPriority,
      severity: mergedSeverity,
      visibility: mergedVisibility,
      label: mergedLabel,
      source: mergedSource as TaskSource,

      caseId:
        (set.caseId as string | undefined) ??
        signal.caseId ??
        null,
      subtype:
        mergeOptionalString(set.subtype, signal.subtype) ?? null,
      createdByUserId:
        (set.createdByUserId as string | undefined) ??
        signal.createdByUserId ??
        null,
      requesterPersonId:
        (set.requesterPersonId as string | undefined) ??
        signal.requesterPersonId ??
        null,
      ownerRoleId:
        (set.ownerRoleId as string | undefined) ?? null,
      ownerUserId:
        (set.ownerUserId as string | undefined) ?? null,
      assigneeRole:
        (set.assigneeRole as string | undefined) ??
        (action.to_role as string | undefined) ??
        null,

      dueAt: (set.dueAt as string | Date | undefined) ?? null,

      metadata: this.buildTaskMetadataFromSignal(signal, resolved),

      reactivitySeconds:
        (set.reactivitySeconds as number | undefined) ?? null,
      reactivityTimeIso:
        (set.reactivityTimeIso as string | undefined) ?? null,
      reactivityDeadlineAt:
        (set.reactivityDeadlineAt as string | Date | undefined) ?? null,
    };

    try {
      const result = await this.taskService.createTask(createInput);

      if (!result.ok || !result.data) {
        return {
          ok: false,
          data: null,
          error:
            (result.error as StandardError | null) ?? {
              code: 'SIGNAL_CREATE_TASK_FAILED',
              message: 'TaskService.createTask returned error for signal.',
              details: { createInput },
            },
        };
      }

      return {
        ok: true,
        data: result.data,
        error: null,
      };
    } catch (err: unknown) {
      const error: StandardError = {
        code: 'SIGNAL_CREATE_TASK_ERROR',
        message: 'Unhandled error while creating task from signal.',
        details: {
          organizationId: signal.organizationId,
          error:
            err instanceof Error ? err.message : (err as string | unknown),
        },
      };

      this.logger.error(
        `Unhandled error while creating task from signal (org=${signal.organizationId})`,
        err instanceof Error ? err.stack ?? err.message : String(err),
      );

      return {
        ok: false,
        data: null,
        error,
      };
    }
  }

  /**
   * Build the metadata object passed to TaskService.createTask, merging
   * existing signal metadata with workflow/action-level context.
   */
  private buildTaskMetadataFromSignal(
    signal: NormalizedSignal,
    resolved: ResolvedWorkflowAction,
  ): Record<string, any> {
    const baseMetadata: Record<string, any> =
      signal.metadata && typeof signal.metadata === 'object'
        ? { ...signal.metadata }
        : {};

    const workflowMeta: Record<string, any> = {
      ruleId: resolved.ruleId,
      ruleVersion: resolved.ruleVersion,
      actionIndex: resolved.actionIndex,
      actionType: resolved.action.type,
      origin: 'signal_ingest',
    };

    const signalMeta: Record<string, any> = {
      organizationId: signal.organizationId,
      externalId: signal.externalId ?? null,
      caseId: signal.caseId ?? null,
      source: signal.source,
      sourceReference: signal.sourceReference ?? null,
      createdByUserId: signal.createdByUserId ?? null,
      requesterPersonId: signal.requesterPersonId ?? null,
    };

    return {
      ...baseMetadata,
      workflow: {
        ...(baseMetadata.workflow ?? {}),
        ...workflowMeta,
      },
      signal: {
        ...(baseMetadata.signal ?? {}),
        ...signalMeta,
      },
    };
  }
}


=== FILE 33/48: apps/api/src/orgo/core/signals/signal.controller.ts ===

import {
  Body,
  Controller,
  HttpCode,
  HttpStatus,
  Post,
} from '@nestjs/common';
import { IsEnum, IsNotEmpty, IsObject, IsOptional, IsString, IsUUID } from 'class-validator';
import { SignalIngestService } from './signal-ingest.service';

/**
 * Canonical signal source values, aligned with task_source_enum:
 * 'email' | 'api' | 'manual' | 'sync'.
 */
export enum SignalSource {
  EMAIL = 'email',
  API = 'api',
  MANUAL = 'manual',
  SYNC = 'sync',
}

/**
 * DTO for ingesting a generic "signal" into Orgo.
 *
 * A signal is a normalized input that Core Services can route into
 * Tasks and/or Cases via the workflow engine. It is intentionally
 * flexible while still enforcing core invariants:
 *
 * - organization_id is always required (multi‑tenant key).
 * - source maps to the canonical task_source_enum.
 * - type may hint at the target Task.type (maintenance, hr_case, etc.).
 * - title/description are optional summaries for human‑readable context.
 * - label can carry a canonical information label if already known.
 * - created_by_user_id / requester_person_id link the signal to actors.
 * - payload carries any additional, domain‑specific JSON.
 */
export class CreateSignalDto {
  @IsUUID()
  organization_id!: string;

  @IsEnum(SignalSource)
  source!: SignalSource;

  /**
   * Optional domain type hint, e.g. "maintenance", "hr_case",
   * "education_support", "generic". This is expected to map to Task.type.
   */
  @IsString()
  @IsOptional()
  type?: string;

  @IsString()
  @IsOptional()
  @IsNotEmpty()
  title?: string;

  @IsString()
  @IsOptional()
  @IsNotEmpty()
  description?: string;

  /**
   * Optional canonical information label:
   * "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE>"
   * (see Doc 2/8 label semantics).
   */
  @IsString()
  @IsOptional()
  label?: string;

  /**
   * Optional linkage to the Orgo user that is submitting the signal.
   * In many deployments this will be derived from auth context instead
   * of being sent explicitly; this field exists for explicit overrides
   * and non‑user API clients.
   */
  @IsUUID()
  @IsOptional()
  created_by_user_id?: string;

  /**
   * Optional linkage to the Person the signal is about (student, employee,
   * player, community member, etc.).
   */
  @IsUUID()
  @IsOptional()
  requester_person_id?: string;

  /**
   * Optional arbitrary JSON payload carrying domain‑specific content
   * (form fields, structured metadata, attachments references, etc.).
   * Core Services and domain handlers are responsible for interpreting
   * this payload and mapping it into Task/Case metadata.
   */
  @IsObject()
  @IsOptional()
  payload?: Record<string, unknown>;
}

/**
 * SignalController
 *
 * HTTP entrypoint for ingesting generic signals (non‑email) into Orgo.
 * Typical route: POST /api/v3/signals
 *
 * This controller is intentionally thin: it validates the incoming DTO
 * and delegates to SignalIngestService.ingest, which implements the
 * standard result shape { ok, data, error } and is responsible for
 * mapping the signal into Tasks/Cases via the workflow engine.
 */
@Controller('signals')
export class SignalController {
  constructor(private readonly signalIngestService: SignalIngestService) {}

  /**
   * Ingest a new signal.
   *
   * The service is expected to:
   * - normalise the signal into the internal representation,
   * - invoke the workflow engine,
   * - create any resulting Tasks/Cases,
   * - and return a standard result shape.
   */
  @Post()
  @HttpCode(HttpStatus.OK)
  async createSignal(@Body() dto: CreateSignalDto): Promise<any> {
    return this.signalIngestService.ingest(dto);
  }
}


=== FILE 34/48: apps/api/src/orgo/core/signals/signals.module.ts ===

import { Module } from '@nestjs/common';
import { SignalController } from './signal.controller';
import { SignalIngestService } from './signal-ingest.service';

/**
 * Core API / Signals module.
 *
 * Exposes SignalIngestService.ingest via SignalController.createSignal to
 * normalize non-email signals (REST, UI forms, webhooks) into a common
 * signal shape that downstream workflows can turn into Cases/Tasks.
 */
@Module({
  imports: [],
  controllers: [SignalController],
  providers: [SignalIngestService],
  exports: [SignalIngestService],
})
export class SignalsModule {}


=== FILE 35/48: apps/api/src/orgo/core/tasks/dto/create-task.dto.ts ===

import { ApiProperty, ApiPropertyOptional } from '@nestjs/swagger';
import {
  IsUUID,
  IsString,
  IsNotEmpty,
  IsEnum,
  IsOptional,
  MaxLength,
  IsDateString,
  IsObject,
} from 'class-validator';

/**
 * JSON-level enums for Task fields.
 * These reflect the canonical API representations (lower-case),
 * which are mapped to DB enums in the service layer.
 */

export enum TaskCategory {
  REQUEST = 'request',
  INCIDENT = 'incident',
  UPDATE = 'update',
  REPORT = 'report',
  DISTRIBUTION = 'distribution',
}

export enum TaskPriority {
  LOW = 'low',
  MEDIUM = 'medium',
  HIGH = 'high',
  CRITICAL = 'critical',
}

export enum TaskSeverity {
  MINOR = 'minor',
  MODERATE = 'moderate',
  MAJOR = 'major',
  CRITICAL = 'critical',
}

export enum TaskVisibility {
  PUBLIC = 'public',
  INTERNAL = 'internal',
  RESTRICTED = 'restricted',
  ANONYMISED = 'anonymised', // always with an "s"
}

export enum TaskSource {
  EMAIL = 'email',
  API = 'api',
  MANUAL = 'manual',
  SYNC = 'sync',
}

/**
 * DTO for creating a Task.
 *
 * This models the canonical create_task payload:
 * - Includes all writable, non-derived fields.
 * - Excludes DB-/service-owned fields such as:
 *   task_id, status, reactivity_time, reactivity_deadline_at,
 *   escalation_level, created_at, updated_at, closed_at.
 */
export class CreateTaskDto {
  @ApiProperty({
    description: 'Tenant / organization identifier (UUID).',
    format: 'uuid',
  })
  @IsUUID()
  @IsNotEmpty()
  organization_id!: string;

  @ApiProperty({
    description:
      'Domain-level task type (e.g. "maintenance", "hr_case", "education_support", "generic").',
    example: 'maintenance',
  })
  @IsString()
  @IsNotEmpty()
  type!: string;

  @ApiProperty({
    description:
      'Global task category. Must match the canonical category enum.',
    enum: TaskCategory,
    example: TaskCategory.REQUEST,
  })
  @IsEnum(TaskCategory)
  category!: TaskCategory;

  @ApiProperty({
    description: 'Canonical information label code.',
    example: '100.94.Operations.Safety',
  })
  @IsString()
  @IsNotEmpty()
  label!: string;

  @ApiProperty({
    description: 'Short human-readable title of the task.',
    maxLength: 512,
  })
  @IsString()
  @IsNotEmpty()
  @MaxLength(512)
  title!: string;

  @ApiProperty({
    description: 'Detailed description / body of the task.',
  })
  @IsString()
  @IsNotEmpty()
  description!: string;

  @ApiProperty({
    description:
      'Priority of the task. JSON uses lower-case values mapping to DB enum.',
    enum: TaskPriority,
    example: TaskPriority.MEDIUM,
  })
  @IsEnum(TaskPriority)
  priority!: TaskPriority;

  @ApiProperty({
    description:
      'Severity of the task. JSON uses lower-case values mapping to DB enum.',
    enum: TaskSeverity,
    example: TaskSeverity.MINOR,
  })
  @IsEnum(TaskSeverity)
  severity!: TaskSeverity;

  @ApiProperty({
    description:
      'Visibility of the task. Controls who can see it within the organization.',
    enum: TaskVisibility,
    example: TaskVisibility.INTERNAL,
  })
  @IsEnum(TaskVisibility)
  visibility!: TaskVisibility;

  @ApiProperty({
    description:
      'Source through which the task entered the system (email, api, manual, sync).',
    enum: TaskSource,
    example: TaskSource.API,
  })
  @IsEnum(TaskSource)
  source!: TaskSource;

  @ApiProperty({
    description:
      'Domain-specific metadata. Must not duplicate core fields (type, category, severity, etc.).',
    type: 'object',
    additionalProperties: true,
    example: { asset_id: 'ASSET-123', location: 'Building A' },
  })
  @IsObject()
  metadata!: Record<string, unknown>;

  // -------------------------
  // Optional linkage fields
  // -------------------------

  @ApiPropertyOptional({
    description: 'Optional Case this Task belongs to (UUID).',
    format: 'uuid',
    nullable: true,
  })
  @IsOptional()
  @IsUUID()
  case_id?: string | null;

  @ApiPropertyOptional({
    description:
      'Domain-specific subtype (e.g. "plumbing", "harassment", "attendance").',
    nullable: true,
    example: 'plumbing',
  })
  @IsOptional()
  @IsString()
  subtype?: string | null;

  // -------------------------
  // Optional ownership fields
  // -------------------------

  @ApiPropertyOptional({
    description: 'User that created the task (UUID).',
    format: 'uuid',
    nullable: true,
  })
  @IsOptional()
  @IsUUID()
  created_by_user_id?: string | null;

  @ApiPropertyOptional({
    description: 'Person the work is for (UUID).',
    format: 'uuid',
    nullable: true,
  })
  @IsOptional()
  @IsUUID()
  requester_person_id?: string | null;

  @ApiPropertyOptional({
    description: 'Primary owning role (UUID).',
    format: 'uuid',
    nullable: true,
  })
  @IsOptional()
  @IsUUID()
  owner_role_id?: string | null;

  @ApiPropertyOptional({
    description: 'Primary owning user (UUID).',
    format: 'uuid',
    nullable: true,
  })
  @IsOptional()
  @IsUUID()
  owner_user_id?: string | null;

  @ApiPropertyOptional({
    description:
      'Denormalised routing role label, aligned with label system (e.g. "Ops.Maintenance").',
    nullable: true,
    example: 'Ops.Maintenance',
  })
  @IsOptional()
  @IsString()
  assignee_role?: string | null;

  // -------------------------
  // Optional scheduling fields
  // -------------------------

  @ApiPropertyOptional({
    description: 'Optional due date/time for the task (ISO 8601).',
    format: 'date-time',
    nullable: true,
  })
  @IsOptional()
  @IsDateString()
  due_at?: string | null;
}


=== FILE 36/48: apps/api/src/orgo/core/tasks/dto/update-task-status.dto.ts ===

import { ApiProperty, ApiPropertyOptional } from '@nestjs/swagger';
import {
  IsIn,
  IsNotEmpty,
  IsOptional,
  IsString,
  MaxLength,
} from 'class-validator';
import { Transform } from 'class-transformer';

/**
 * Canonical TASK_STATUS values (Doc 2 / Doc 5 / Doc 8).
 */
export const TASK_STATUS_VALUES = [
  'PENDING',
  'IN_PROGRESS',
  'ON_HOLD',
  'COMPLETED',
  'FAILED',
  'ESCALATED',
  'CANCELLED',
] as const;

export type TaskStatus = (typeof TASK_STATUS_VALUES)[number];

export class UpdateTaskStatusDto {
  @ApiProperty({
    description:
      'New status for the task. Uses the canonical TASK_STATUS enum; lower-case forms will be normalised.',
    enum: TASK_STATUS_VALUES,
    example: 'IN_PROGRESS',
  })
  @Transform(({ value }) =>
    typeof value === 'string' ? value.trim().toUpperCase() : value,
  )
  @IsString()
  @IsNotEmpty()
  @IsIn(TASK_STATUS_VALUES)
  status!: TaskStatus;

  @ApiPropertyOptional({
    description:
      'Optional human-readable reason explaining the status change; used for audit/task events.',
    maxLength: 2048,
    example: 'Work completed and verified on site.',
  })
  @IsOptional()
  @IsString()
  @MaxLength(2048)
  reason?: string;
}


=== FILE 37/48: apps/api/src/orgo/core/tasks/task-events.gateway.ts ===

import {
  ConnectedSocket,
  MessageBody,
  OnGatewayConnection,
  OnGatewayDisconnect,
  OnGatewayInit,
  SubscribeMessage,
  WebSocketGateway,
  WebSocketServer,
} from '@nestjs/websockets';
import { Logger } from '@nestjs/common';
import { Server, Socket } from 'socket.io';

/**
 * Canonical Task enums (aligned with Orgo v3 specs).
 */
export type TaskStatus =
  | 'PENDING'
  | 'IN_PROGRESS'
  | 'ON_HOLD'
  | 'COMPLETED'
  | 'FAILED'
  | 'ESCALATED'
  | 'CANCELLED';

export type TaskPriority = 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';

export type TaskSeverity = 'MINOR' | 'MODERATE' | 'MAJOR' | 'CRITICAL';

export type TaskVisibility = 'PUBLIC' | 'INTERNAL' | 'RESTRICTED' | 'ANONYMISED';

/**
 * Canonical Task JSON snapshot used in task events.
 * Field names match the Task JSON contract (API boundary) rather than DB column names.
 */
export interface TaskJsonSnapshot {
  task_id: string;
  organization_id: string;
  case_id?: string | null;

  source: 'email' | 'api' | 'manual' | 'sync';

  type: string;
  category: 'request' | 'incident' | 'update' | 'report' | 'distribution';
  subtype?: string | null;

  label: string;
  title: string;
  description: string;

  status: TaskStatus;
  priority: TaskPriority;
  severity: TaskSeverity;
  visibility: TaskVisibility;

  assignee_role?: string | null;
  created_by_user_id?: string | null;
  requester_person_id?: string | null;
  owner_role_id?: string | null;
  owner_user_id?: string | null;

  due_at?: string | null;
  reactivity_time?: string | null;
  reactivity_deadline_at?: string | null;
  escalation_level: number;
  closed_at?: string | null;

  metadata?: Record<string, unknown>;

  created_at: string;
  updated_at: string;
}

/**
 * Event types sent over the task event stream.
 */
export type TaskEventType =
  | 'TASK_CREATED'
  | 'TASK_UPDATED'
  | 'TASK_STATUS_CHANGED'
  | 'TASK_ESCALATED'
  | 'TASK_COMMENT_ADDED';

/**
 * Payload for a single task event delivered over WebSocket.
 *
 * Notes:
 * - `task` is a canonical Task JSON snapshot.
 * - `visibility` is duplicated from `task.visibility` for quick filtering.
 * - For RESTRICTED/ANONYMISED tasks, `recipient_user_ids` should be set so
 *   the gateway can restrict delivery to specific users.
 */
export interface TaskEventPayload {
  event_id: string;
  event_type: TaskEventType;
  organization_id: string;
  task_id: string;
  task: TaskJsonSnapshot;

  visibility: TaskVisibility;

  actor_user_id?: string | null;
  occurred_at: string; // ISO-8601 string (UTC)

  /**
   * Optional list of user IDs that are explicitly allowed to receive this event.
   * Used for RESTRICTED / ANONYMISED visibility.
   */
  recipient_user_ids?: string[];

  /**
   * Optional additional metadata about the event (non-PII).
   */
  meta?: Record<string, unknown>;
}

/**
 * Message name used by the gateway when pushing task events to clients.
 * Clients should subscribe to this message name.
 */
export const TASK_EVENTS_MESSAGE = 'task.events';

/**
 * Internal structure used for tracking a connected client.
 */
interface ConnectedClientInfo {
  organizationId: string;
  userId?: string;
}

/**
 * WebSocket gateway for streaming live Task events to web clients.
 *
 * Namespace:
 *   - `/task-events`
 *
 * Connection:
 *   - Clients SHOULD pass `organizationId` and (optionally) `userId` as query
 *     parameters in the WebSocket handshake:
 *
 *       io('/task-events', {
 *         query: { organizationId, userId },
 *       });
 *
 *   - `organizationId` is required; connections without it are rejected.
 *
 * Delivery rules:
 *   - PUBLIC / INTERNAL tasks → delivered to all clients in the organization room.
 *   - RESTRICTED / ANONYMISED tasks → delivered only to `recipient_user_ids`
 *     if provided; otherwise dropped (to avoid accidental leakage).
 */
@WebSocketGateway({
  namespace: '/task-events',
  cors: {
    origin: true,
    credentials: true,
  },
})
export class TaskEventsGateway
  implements OnGatewayInit, OnGatewayConnection, OnGatewayDisconnect
{
  @WebSocketServer()
  public server!: Server;

  private readonly logger = new Logger(TaskEventsGateway.name);

  /**
   * Map of socket.id → ConnectedClientInfo.
   */
  private readonly clients = new Map<string, ConnectedClientInfo>();

  /**
   * Reverse index of user_id → Set<socket.id>.
   * Used to target RESTRICTED / ANONYMISED events to specific users.
   */
  private readonly userIndex = new Map<string, Set<string>>();

  afterInit(): void {
    this.logger.log('TaskEventsGateway initialized');
  }

  async handleConnection(client: Socket): Promise<void> {
    const organizationId =
      this.extractString(client.handshake.query.organizationId) ??
      this.extractString(client.handshake.query.organization_id);

    const userId =
      this.extractString(client.handshake.query.userId) ??
      this.extractString(client.handshake.query.user_id);

    if (!organizationId) {
      this.logger.warn(
        `Rejecting connection ${client.id}: missing organizationId in handshake query`,
      );
      client.disconnect(true);
      return;
    }

    this.registerClient(client, {
      organizationId,
      userId,
    });

    this.logger.debug(
      `Client ${client.id} connected for org ${organizationId}` +
        (userId ? ` (user ${userId})` : ''),
    );
  }

  async handleDisconnect(client: Socket): Promise<void> {
    this.unregisterClient(client.id);
  }

  /**
   * Optional explicit identify message. This can be used to update the
   * organization/user binding after the initial handshake, for example
   * after a token-based authentication flow.
   *
   * Payload:
   *   { organizationId: string; userId?: string }
   */
  @SubscribeMessage('identify')
  handleIdentify(
    @MessageBody()
    data: { organizationId?: string; userId?: string },
    @ConnectedSocket() client: Socket,
  ): void {
    const current = this.clients.get(client.id);

    const organizationId = data.organizationId ?? current?.organizationId;
    const userId = data.userId ?? current?.userId;

    if (!organizationId) {
      this.logger.warn(
        `identify message from ${client.id} missing organizationId; ignoring`,
      );
      return;
    }

    this.registerClient(client, { organizationId, userId });

    this.logger.debug(
      `Client ${client.id} identified for org ${organizationId}` +
        (userId ? ` (user ${userId})` : ''),
    );
  }

  /**
   * Optional ping/pong to keep connections alive and for simple diagnostics.
   */
  @SubscribeMessage('ping')
  handlePing(@ConnectedSocket() client: Socket): { type: 'pong' } {
    this.logger.debug(`Received ping from ${client.id}`);
    return { type: 'pong' };
  }

  /**
   * Broadcast a Task event to the appropriate set of clients.
   *
   * This method is intended to be called from TaskService / domain services
   * whenever a relevant Task lifecycle event occurs.
   */
  public broadcastTaskEvent(event: TaskEventPayload): void {
    const {
      organization_id: organizationId,
      visibility,
      recipient_user_ids: recipientUserIds,
      event_type: eventType,
      task_id: taskId,
    } = event;

    if (!organizationId) {
      this.logger.warn(
        `Dropping task event without organization_id (task_id=${taskId}, type=${eventType})`,
      );
      return;
    }

    if (visibility === 'RESTRICTED' || visibility === 'ANONYMISED') {
      if (!recipientUserIds || recipientUserIds.length === 0) {
        this.logger.warn(
          `Dropping ${visibility} task event with no recipient_user_ids (task_id=${taskId}, type=${eventType})`,
        );
        return;
      }

      for (const userId of recipientUserIds) {
        this.emitToUser(userId, event);
      }

      return;
    }

    // PUBLIC / INTERNAL – broadcast to all clients in the organization room.
    const roomName = this.getOrganizationRoom(organizationId);
    this.server.to(roomName).emit(TASK_EVENTS_MESSAGE, event);
  }

  /**
   * Register or update a connected client and place it in the appropriate
   * organization room and user index.
   */
  private registerClient(client: Socket, info: ConnectedClientInfo): void {
    // Remove any previous registration first.
    this.unregisterClient(client.id);

    this.clients.set(client.id, info);

    // Join per-organization room.
    const roomName = this.getOrganizationRoom(info.organizationId);
    client.join(roomName);

    // Index by user, if available.
    if (info.userId) {
      let sockets = this.userIndex.get(info.userId);
      if (!sockets) {
        sockets = new Set<string>();
        this.userIndex.set(info.userId, sockets);
      }
      sockets.add(client.id);
    }
  }

  /**
   * Remove a client from all tracking structures.
   */
  private unregisterClient(clientId: string): void {
    const info = this.clients.get(clientId);
    if (!info) {
      return;
    }

    this.clients.delete(clientId);

    if (info.userId) {
      const sockets = this.userIndex.get(info.userId);
      if (sockets) {
        sockets.delete(clientId);
        if (sockets.size === 0) {
          this.userIndex.delete(info.userId);
        }
      }
    }

    this.logger.debug(
      `Client ${clientId} disconnected from org ${info.organizationId}` +
        (info.userId ? ` (user ${info.userId})` : ''),
    );
  }

  /**
   * Emit an event to all sockets associated with a given user ID.
   */
  private emitToUser(userId: string, event: TaskEventPayload): void {
    const sockets = this.userIndex.get(userId);
    if (!sockets || sockets.size === 0) {
      this.logger.debug(
        `No active sockets for user ${userId}; task event not delivered`,
      );
      return;
    }

    for (const socketId of sockets) {
      this.server.to(socketId).emit(TASK_EVENTS_MESSAGE, event);
    }
  }

  /**
   * Derive the room name for a given organization.
   */
  private getOrganizationRoom(organizationId: string): string {
    return `org:${organizationId}`;
  }

  /**
   * Helper to normalize a value from the WebSocket handshake query into a string.
   */
  private extractString(value: unknown): string | undefined {
    if (typeof value === 'string' && value.trim().length > 0) {
      return value.trim();
    }

    if (Array.isArray(value)) {
      const first = value[0];
      if (typeof first === 'string' && first.trim().length > 0) {
        return first.trim();
      }
    }

    return undefined;
  }
}


=== FILE 38/48: apps/api/src/orgo/core/tasks/task-events.service.ts ===

// apps/api/src/orgo/core/tasks/task-events.service.ts

import { Injectable } from '@nestjs/common';
import { Observable, Subject } from 'rxjs';
import { Prisma, TaskEvent as TaskEventModel } from '@prisma/client';

import { DatabaseService } from '../database/database.service';
import { LogService } from '../logging/log.service';

export type TaskEventType =
  | 'created'
  | 'status_changed'
  | 'priority_changed'
  | 'ownership_changed'
  | 'comment_added'
  | 'email_linked'
  | 'escalated'
  | 'deadline_updated'
  | 'metadata_updated';

export type TaskEventOrigin = 'ui' | 'api' | 'email' | 'system_rule';

export interface StandardResultError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

export interface StandardResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardResultError | null;
}

export interface TaskEventPayload {
  taskId: string;
  organizationId: string;
  eventType: TaskEventType;
  origin: TaskEventOrigin;
  oldValue?: Prisma.JsonValue | null;
  newValue?: Prisma.JsonValue | null;
  actorUserId?: string | null;
  actorRoleId?: string | null;
}

/**
 * Shape of messages pushed to the live event stream (for WebSocket gateway).
 * This is intentionally compact and UI‑oriented.
 */
export interface TaskEventStreamMessage {
  eventId: string;
  taskId: string;
  organizationId: string;
  eventType: TaskEventType;
  origin: TaskEventOrigin;
  oldValue: Prisma.JsonValue | null;
  newValue: Prisma.JsonValue | null;
  actorUserId: string | null;
  actorRoleId: string | null;
  createdAt: Date;
}

/**
 * TaskEventsService
 *
 * Responsibilities:
 * - Append append‑only rows into task_events.
 * - Provide convenience helpers for common event types.
 * - Expose an RxJS stream used by TaskEventsGateway for live updates.
 * - Emit structured log entries via LogService.
 */
@Injectable()
export class TaskEventsService {
  private readonly eventsSubject = new Subject<TaskEventStreamMessage>();

  constructor(
    private readonly database: DatabaseService,
    private readonly logService: LogService,
  ) {}

  /**
   * Observable stream of task events for WebSocket gateway or other subscribers.
   */
  get events$(): Observable<TaskEventStreamMessage> {
    return this.eventsSubject.asObservable();
  }

  /**
   * Low‑level primitive to append a TaskEvent row.
   * All convenience helpers delegate to this.
   */
  async appendEvent(
    payload: TaskEventPayload,
  ): Promise<StandardResult<TaskEventModel>> {
    const { taskId, organizationId, eventType, origin } = payload;

    if (!taskId || !organizationId || !eventType || !origin) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'TASK_EVENT_VALIDATION_ERROR',
          message:
            'taskId, organizationId, eventType and origin are required to append a task event.',
          details: { taskId, organizationId, eventType, origin },
        },
      };
    }

    try {
      const prisma = this.database.getPrismaClient();

      const created = await prisma.taskEvent.create({
        data: {
          taskId,
          organizationId,
          eventType,
          origin,
          oldValue:
            typeof payload.oldValue === 'undefined' ? null : payload.oldValue,
          newValue:
            typeof payload.newValue === 'undefined' ? null : payload.newValue,
          actorUserId:
            typeof payload.actorUserId === 'undefined'
              ? null
              : payload.actorUserId,
          actorRoleId:
            typeof payload.actorRoleId === 'undefined'
              ? null
              : payload.actorRoleId,
          // createdAt is assumed to be defaulted by the DB.
        },
      });

      const streamMessage: TaskEventStreamMessage = {
        eventId: created.id,
        taskId: created.taskId,
        organizationId: created.organizationId,
        eventType: created.eventType as TaskEventType,
        origin: created.origin as TaskEventOrigin,
        oldValue: created.oldValue,
        newValue: created.newValue,
        actorUserId: created.actorUserId,
        actorRoleId: created.actorRoleId,
        createdAt: created.createdAt,
      };

      this.eventsSubject.next(streamMessage);

      this.logService.logEvent({
        category: 'TASK',
        logLevel: 'INFO',
        message: `Task event recorded: ${created.eventType}`,
        identifier: `task_id:${created.taskId}`,
        metadata: {
          organizationId: created.organizationId,
          eventType: created.eventType,
          origin: created.origin,
          eventId: created.id,
        },
      });

      return {
        ok: true,
        data: created,
        error: null,
      };
    } catch (err) {
      this.logService.logEvent({
        category: 'SYSTEM',
        logLevel: 'ERROR',
        message: 'Failed to append task event',
        identifier: `task_id:${taskId}`,
        metadata: {
          eventType,
          origin,
          error:
            err instanceof Error ? err.message : 'Unknown error in appendEvent',
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'TASK_EVENT_PERSISTENCE_ERROR',
          message: 'Failed to persist task event.',
          details: {
            taskId,
            organizationId,
            eventType,
            origin,
          },
        },
      };
    }
  }

  /**
   * Fetch full event history for a task, ordered by createdAt ascending.
   */
  async getEventsForTask(
    taskId: string,
    organizationId: string,
  ): Promise<StandardResult<TaskEventModel[]>> {
    if (!taskId || !organizationId) {
      return {
        ok: false,
        data: null,
        error: {
          code: 'TASK_EVENT_VALIDATION_ERROR',
          message: 'taskId and organizationId are required.',
          details: { taskId, organizationId },
        },
      };
    }

    try {
      const prisma = this.database.getPrismaClient();

      const events = await prisma.taskEvent.findMany({
        where: {
          taskId,
          organizationId,
        },
        orderBy: {
          createdAt: 'asc',
        },
      });

      return {
        ok: true,
        data: events,
        error: null,
      };
    } catch (err) {
      this.logService.logEvent({
        category: 'SYSTEM',
        logLevel: 'ERROR',
        message: 'Failed to fetch task events',
        identifier: `task_id:${taskId}`,
        metadata: {
          error:
            err instanceof Error
              ? err.message
              : 'Unknown error in getEventsForTask',
        },
      });

      return {
        ok: false,
        data: null,
        error: {
          code: 'TASK_EVENT_QUERY_ERROR',
          message: 'Failed to fetch task events.',
          details: { taskId, organizationId },
        },
      };
    }
  }

  /**
   * Convenience: record `created` event.
   * Typically called immediately after Task creation.
   */
  async recordTaskCreated(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    actorUserId?: string | null;
    actorRoleId?: string | null;
    snapshot?: Prisma.JsonValue; // optional full Task snapshot
  }): Promise<StandardResult<TaskEventModel>> {
    const { snapshot, ...rest } = params;
    return this.appendEvent({
      ...rest,
      eventType: 'created',
      oldValue: null,
      newValue: snapshot ?? null,
    });
  }

  /**
   * Convenience: record `status_changed` event.
   */
  async recordStatusChanged(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    previousStatus: string;
    nextStatus: string;
    actorUserId?: string | null;
    actorRoleId?: string | null;
    reason?: string;
  }): Promise<StandardResult<TaskEventModel>> {
    const { previousStatus, nextStatus, reason, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'status_changed',
      oldValue: {
        status: previousStatus,
      },
      newValue: {
        status: nextStatus,
        reason: reason ?? null,
      },
    });
  }

  /**
   * Convenience: record `priority_changed` event.
   */
  async recordPriorityChanged(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    previousPriority: string;
    nextPriority: string;
    actorUserId?: string | null;
    actorRoleId?: string | null;
  }): Promise<StandardResult<TaskEventModel>> {
    const { previousPriority, nextPriority, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'priority_changed',
      oldValue: {
        priority: previousPriority,
      },
      newValue: {
        priority: nextPriority,
      },
    });
  }

  /**
   * Convenience: record `ownership_changed` event.
   * Used for assignments / reassignments.
   */
  async recordOwnershipChanged(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    previousOwnerRoleId?: string | null;
    previousOwnerUserId?: string | null;
    previousAssigneeRole?: string | null;
    nextOwnerRoleId?: string | null;
    nextOwnerUserId?: string | null;
    nextAssigneeRole?: string | null;
    actorUserId?: string | null;
    actorRoleId?: string | null;
    reason?: string;
  }): Promise<StandardResult<TaskEventModel>> {
    const {
      previousOwnerRoleId,
      previousOwnerUserId,
      previousAssigneeRole,
      nextOwnerRoleId,
      nextOwnerUserId,
      nextAssigneeRole,
      reason,
      ...base
    } = params;

    return this.appendEvent({
      ...base,
      eventType: 'ownership_changed',
      oldValue: {
        owner_role_id: previousOwnerRoleId ?? null,
        owner_user_id: previousOwnerUserId ?? null,
        assignee_role: previousAssigneeRole ?? null,
      },
      newValue: {
        owner_role_id: nextOwnerRoleId ?? null,
        owner_user_id: nextOwnerUserId ?? null,
        assignee_role: nextAssigneeRole ?? null,
        reason: reason ?? null,
      },
    });
  }

  /**
   * Convenience: record `comment_added` event.
   * Comment body itself lives in task_comments; this logs metadata.
   */
  async recordCommentAdded(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    commentId: string;
    visibility: string;
    actorUserId?: string | null;
    actorRoleId?: string | null;
  }): Promise<StandardResult<TaskEventModel>> {
    const { commentId, visibility, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'comment_added',
      oldValue: null,
      newValue: {
        comment_id: commentId,
        visibility,
      },
    });
  }

  /**
   * Convenience: record `email_linked` event.
   */
  async recordEmailLinked(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    emailMessageId: string;
    actorUserId?: string | null;
    actorRoleId?: string | null;
  }): Promise<StandardResult<TaskEventModel>> {
    const { emailMessageId, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'email_linked',
      oldValue: null,
      newValue: {
        email_message_id: emailMessageId,
      },
    });
  }

  /**
   * Convenience: record `escalated` event.
   */
  async recordEscalated(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    previousEscalationLevel: number;
    nextEscalationLevel: number;
    actorUserId?: string | null;
    actorRoleId?: string | null;
    reason: string;
  }): Promise<StandardResult<TaskEventModel>> {
    const {
      previousEscalationLevel,
      nextEscalationLevel,
      reason,
      ...base
    } = params;

    return this.appendEvent({
      ...base,
      eventType: 'escalated',
      oldValue: {
        escalation_level: previousEscalationLevel,
      },
      newValue: {
        escalation_level: nextEscalationLevel,
        reason,
      },
    });
  }

  /**
   * Convenience: record `deadline_updated` event.
   */
  async recordDeadlineUpdated(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    previousDeadlineAt: string | null;
    nextDeadlineAt: string | null;
    actorUserId?: string | null;
    actorRoleId?: string | null;
    reason?: string;
  }): Promise<StandardResult<TaskEventModel>> {
    const { previousDeadlineAt, nextDeadlineAt, reason, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'deadline_updated',
      oldValue: {
        reactivity_deadline_at: previousDeadlineAt,
      },
      newValue: {
        reactivity_deadline_at: nextDeadlineAt,
        reason: reason ?? null,
      },
    });
  }

  /**
   * Convenience: record `metadata_updated` event.
   * Accepts arbitrary old/new shape and leaves semantics to caller.
   */
  async recordMetadataUpdated(params: {
    taskId: string;
    organizationId: string;
    origin: TaskEventOrigin;
    oldMetadata: Prisma.JsonValue | null;
    newMetadata: Prisma.JsonValue | null;
    actorUserId?: string | null;
    actorRoleId?: string | null;
  }): Promise<StandardResult<TaskEventModel>> {
    const { oldMetadata, newMetadata, ...base } = params;

    return this.appendEvent({
      ...base,
      eventType: 'metadata_updated',
      oldValue: oldMetadata,
      newValue: newMetadata,
    });
  }
}


=== FILE 39/48: apps/api/src/orgo/core/tasks/task.controller.ts ===

// apps/api/src/orgo/core/tasks/task.controller.ts

import {
  BadRequestException,
  Body,
  Controller,
  Get,
  Param,
  Patch,
  Post,
  Query,
  Req,
} from '@nestjs/common';
import {
  ApiCreatedResponse,
  ApiOkResponse,
  ApiOperation,
  ApiTags,
} from '@nestjs/swagger';
import { Request } from 'express';

import { TaskService } from './task.service';
import { UpdateTaskStatusDto } from './dto/update-task-status.dto';

/**
 * Canonical Task enums (DB / Core-service level).
 * JSON contracts may use lower-case; service accepts both and normalizes.
 */
export type TaskStatus =
  | 'PENDING'
  | 'IN_PROGRESS'
  | 'ON_HOLD'
  | 'COMPLETED'
  | 'FAILED'
  | 'ESCALATED'
  | 'CANCELLED';

export type TaskPriority = 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';

export type TaskSeverity = 'MINOR' | 'MODERATE' | 'MAJOR' | 'CRITICAL';

export type TaskVisibility = 'PUBLIC' | 'INTERNAL' | 'RESTRICTED' | 'ANONYMISED';

export type TaskSource = 'email' | 'api' | 'manual' | 'sync';

/**
 * Task category codes (Doc 5 – Task logical view).
 */
export type TaskCategory =
  | 'request'
  | 'incident'
  | 'update'
  | 'report'
  | 'distribution';

/**
 * JSON-level variants for canonical enums (upper + lower-case tokens).
 */
export type TaskStatusJson = TaskStatus | Lowercase<TaskStatus>;
export type TaskPriorityJson = TaskPriority | Lowercase<TaskPriority>;
export type TaskSeverityJson = TaskSeverity | Lowercase<TaskSeverity>;
export type TaskVisibilityJson = TaskVisibility | Lowercase<TaskVisibility>;

/**
 * Standard result envelope for Core Services (locked for v3).
 */
export interface OrgoError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

export interface OrgoResult<T> {
  ok: boolean;
  data: T | null;
  error: OrgoError | null;
}

/**
 * Canonical Task JSON DTO (API boundary).
 * Mirrors Doc 2.10 + Doc 8.4.2.
 */
export interface TaskDto {
  task_id: string;
  organization_id: string;
  case_id: string | null;

  // Classification / routing
  source: TaskSource;
  type: string;
  category: TaskCategory;
  subtype: string | null;
  label: string;

  // Human-facing
  title: string;
  description: string;

  // Lifecycle / enums
  status: TaskStatusJson;
  priority: TaskPriorityJson;
  severity: TaskSeverityJson;
  visibility: TaskVisibilityJson;

  // Ownership / actors
  assignee_role: string | null;
  created_by_user_id: string | null;
  requester_person_id: string | null;
  owner_role_id: string | null;
  owner_user_id: string | null;

  // SLA / timing
  due_at: string | null;
  reactivity_time: string | null;
  reactivity_deadline_at: string | null;
  escalation_level: number;
  closed_at: string | null;

  // Arbitrary domain metadata
  metadata: Record<string, unknown>;

  // Audit
  created_at: string;
  updated_at: string;
}

/**
 * Query parameters for GET /api/v3/tasks.
 * Filters match the functional inventory (status, label, domain/type, assignee, severity, visibility).
 * Pagination fields are intentionally minimal and can be extended later.
 */
export class ListTasksQueryDto {
  /**
   * Tenant isolation key (organization_id).
   * In most real calls this should be required, but left optional at DTO level
   * to allow auth middleware / guards to inject it.
   */
  organization_id?: string;

  /**
   * Filter by canonical status (PENDING, IN_PROGRESS, etc.) or lower-case JSON form.
   */
  status?: TaskStatusJson;

  /**
   * Filter by canonical label code (e.g. "100.11.Ops.Maintenance").
   */
  label?: string;

  /**
   * Domain-level type (e.g. "maintenance", "hr_case", "education_support").
   */
  type?: string;

  /**
   * Denormalised routing role label, aligned with label system (e.g. "Ops.Maintenance").
   */
  assignee_role?: string;

  /**
   * Severity filter using JSON-level tokens (minor/moderate/major/critical).
   */
  severity?: TaskSeverityJson;

  /**
   * Visibility filter using JSON-level tokens (public/internal/restricted/anonymised).
   */
  visibility?: TaskVisibilityJson;

  /**
   * Priority filter using JSON-level tokens (low/medium/high/critical).
   */
  priority?: TaskPriorityJson;

  /**
   * Page number for pagination (1-based).
   */
  page?: number;

  /**
   * Page size for pagination.
   */
  page_size?: number;
}

/**
 * Request body for POST /api/v3/tasks (Create Task via API).
 * Required fields match Core Services spec for create_task.
 */
export class CreateTaskRequestDto {
  // Required core fields
  organization_id!: string;
  type!: string;
  category!: TaskCategory;
  title!: string;
  description!: string;
  priority!: TaskPriorityJson;
  severity!: TaskSeverityJson;
  visibility!: TaskVisibilityJson;
  label!: string;
  source!: TaskSource;
  metadata!: Record<string, unknown>;

  // Optional fields
  case_id?: string | null;
  subtype?: string | null;
  created_by_user_id?: string | null;
  requester_person_id?: string | null;
  owner_role_id?: string | null;
  owner_user_id?: string | null;
  assignee_role?: string | null;
  due_at?: string | null;
}

/**
 * TaskController – Public API interface for Tasks.
 *
 * Routes (locked by functional inventory):
 *  - GET    /api/v3/tasks           → listTasks
 *  - GET    /api/v3/tasks/:id       → getTask
 *  - POST   /api/v3/tasks           → createTask
 *  - PATCH  /api/v3/tasks/:id/status → updateTaskStatus
 */
@ApiTags('tasks')
@Controller('api/v3/tasks')
export class TaskController {
  constructor(private readonly taskService: TaskService) {}

  @Get()
  @ApiOperation({
    summary: 'Get Tasks (list)',
    description:
      'Returns a list of Tasks filtered by status, label, domain/type, assignee, severity, and visibility.',
  })
  @ApiOkResponse({
    description: 'List of Tasks wrapped in the standard ok/data/error envelope.',
    type: Object,
  })
  async listTasks(
    @Query() query: ListTasksQueryDto,
  ): Promise<OrgoResult<TaskDto[]>> {
    // Existing behaviour: delegate directly to TaskService.
    // Service is responsible for mapping query → internal filters and JSON DTOs.
    return this.taskService.listTasks(query as any);
  }

  @Get(':id')
  @ApiOperation({
    summary: 'Get single Task',
    description:
      'Returns a single Task by its task_id, using the canonical Task JSON schema.',
  })
  @ApiOkResponse({
    description: 'Single Task wrapped in the standard ok/data/error envelope.',
    type: Object,
  })
  async getTask(@Param('id') taskId: string): Promise<OrgoResult<TaskDto>> {
    return this.taskService.getTask(taskId as any);
  }

  @Post()
  @ApiOperation({
    summary: 'Create Task via API',
    description:
      'Creates a new Task using the canonical Task model and enums. Status, SLA fields and escalation_level are derived by Core Services.',
  })
  @ApiCreatedResponse({
    description: 'Created Task wrapped in the standard ok/data/error envelope.',
    type: Object,
  })
  async createTask(
    @Body() body: CreateTaskRequestDto,
  ): Promise<OrgoResult<TaskDto>> {
    return this.taskService.createTask(body as any);
  }

  @Patch(':id/status')
  @ApiOperation({
    summary: 'Update Task status',
    description:
      'Updates the status of a Task using the canonical TASK_STATUS enum and enforces lifecycle rules and tenant isolation.',
  })
  @ApiOkResponse({
    description: 'Updated Task wrapped in the standard ok/data/error envelope.',
    type: Object,
  })
  async updateTaskStatus(
    @Param('id') taskId: string,
    @Body() body: UpdateTaskStatusDto,
    @Req() req: Request,
  ): Promise<OrgoResult<TaskDto>> {
    const organizationId = this.getOrganizationIdFromRequest(req);

    // Derive actorUserId from auth context when available.
    const userFromReq = (req as any).user as { userId?: string } | undefined;
    const actorUserId =
      (req as any).userId ??
      (userFromReq && typeof userFromReq.userId === 'string'
        ? userFromReq.userId
        : undefined);

    return this.taskService.updateTaskStatus({
      organizationId,
      taskId,
      newStatus: body.status,
      reason: body.reason,
      actorUserId,
    } as any);
  }

  /**
   * Resolve the current organization identifier from the request.
   *
   * Priority:
   *  - request.user.organizationId (AuthGuard / JWT context)
   *  - request.organizationId (legacy context)
   *  - X-Org-Id / X-Organization-Id headers
   */
  private getOrganizationIdFromRequest(req: Request): string {
    const user = (req as any).user as { organizationId?: string } | undefined;
    const orgFromUser = user?.organizationId;

    const orgFromReq = (req as any).organizationId as string | undefined;

    const headerRaw =
      (req.headers['x-org-id'] as string | undefined) ||
      (req.headers['x-organization-id'] as string | undefined);
    const orgFromHeader = headerRaw?.trim() || undefined;

    const organizationId = orgFromUser ?? orgFromReq ?? orgFromHeader;

    if (!organizationId) {
      throw new BadRequestException(
        'Missing organization identifier (expected auth context or X-Org-Id / X-Organization-Id header).',
      );
    }

    return organizationId;
  }
}


=== FILE 40/48: apps/api/src/orgo/core/tasks/task.module.ts ===

import { Module } from '@nestjs/common';
import { PersistenceModule } from '../../../persistence/persistence.module';
import { TaskService } from './task.service';
import { TaskController } from './task.controller';

@Module({
  imports: [PersistenceModule],
  controllers: [TaskController],
  providers: [TaskService],
  exports: [TaskService],
})
export class TaskModule {}


=== FILE 41/48: apps/api/src/orgo/core/tasks/task.service.ts ===

import { Injectable, Logger } from '@nestjs/common';
import { PrismaService } from './././persistence/prisma/prisma.service';
import {
  OrgProfileService,
  ApplyDefaultsResult,
} from './././config/org-profile.service';

/**
 * Canonical Task enums (DB / Core-service level).
 * JSON contracts may use lower-case; service accepts both and normalizes.
 */
export type TaskStatus =
  | 'PENDING'
  | 'IN_PROGRESS'
  | 'ON_HOLD'
  | 'COMPLETED'
  | 'FAILED'
  | 'ESCALATED'
  | 'CANCELLED';

export type TaskPriority = 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';

export type TaskSeverity = 'MINOR' | 'MODERATE' | 'MAJOR' | 'CRITICAL';

export type TaskVisibility = 'PUBLIC' | 'INTERNAL' | 'RESTRICTED' | 'ANONYMISED';

export type TaskSource = 'email' | 'api' | 'manual' | 'sync';

/**
 * Task category codes (Doc 5 – Task logical view).
 */
export type TaskCategory =
  | 'request'
  | 'incident'
  | 'update'
  | 'report'
  | 'distribution';

export type TaskCommentVisibility =
  | 'internal_only'
  | 'requester_visible'
  | 'org_wide';

/**
 * Internal input types used by TaskService.
 * These are mapped from API DTOs and workflow actions.
 */

type PriorityInput = TaskPriority | string | null | undefined;
type SeverityInput = TaskSeverity | string | null | undefined;
type VisibilityInput = TaskVisibility | string | null | undefined;
type SourceInput = TaskSource | string | null | undefined;

export interface CreateTaskInput {
  organizationId: string;

  // Optional linkage to a Case (Doc 5 §8 – Task <-> Case).
  caseId?: string | null;

  // Classification
  type: string;
  category: TaskCategory;
  subtype?: string | null;
  label: string;

  // Core details
  title: string;
  description: string;

  // State / SLA inputs – may be partially overridden by OrgProfileService.
  priority?: PriorityInput;
  severity?: SeverityInput;
  visibility?: VisibilityInput;
  source: SourceInput;

  // Actors / routing
  createdByUserId?: string | null;
  requesterPersonId?: string | null;
  ownerRoleId?: string | null;
  ownerUserId?: string | null;
  assigneeRole?: string | null;

  // SLA / scheduling
  dueAt?: string | Date | null;

  /**
   * Optional SLA inputs. In most flows, the active organization profile
   * provides reactivity defaults. These fields act as overrides:
   *
   * - reactivitySeconds → explicit SLA in seconds
   * - reactivityTimeIso → ISO 8601 duration ("P1DT4H", "PT3600S")
   * - reactivityDeadlineAt → absolute override (wins over other fields)
   */
  reactivitySeconds?: number | null;
  reactivityTimeIso?: string | null;
  reactivityDeadlineAt?: string | Date | null;

  /**
   * Free-form metadata, normalized by MetadataService. Must not contain any of
   * the canonical Task fields (Doc 5 §9, Metadata rules).
   */
  metadata?: Record<string, unknown> | null;
}

export interface UpdateTaskStatusInput {
  organizationId: string;
  taskId: string;
  newStatus: TaskStatus | string;
  reason?: string | null;
  actorUserId?: string | null;
}

export interface EscalateTaskInput {
  organizationId: string;
  taskId: string;
  actorUserId?: string | null;
  escalationReason?: string | null;
}

export interface AssignTaskInput {
  organizationId: string;
  taskId: string;
  assigneeRole?: string | null;
  ownerUserId?: string | null;
  ownerRoleId?: string | null;
  actorUserId?: string | null;
  reason?: string | null;
}

export interface AddTaskCommentInput {
  organizationId: string;
  taskId: string;
  authorUserId?: string | null;
  visibility: TaskCommentVisibility;
  body: string;
}

/**
 * ListTasksInput – internal filter for multi-tenant Task listing.
 * Maps cleanly from ListTasksQueryDto (API) and web AdminTaskOverview filters.
 */
export interface ListTasksInput {
  organizationId: string;

  status?: string | string[]; // TaskStatus | "all" | lowercase
  label?: string; // canonical label code
  type?: string;
  assigneeRole?: string;
  severity?: string | string[];
  visibility?: string | string[];
  priority?: string | string[];

  page?: number;
  pageSize?: number;
}

/**
 * Canonical Task DTO used by Core Services and domain modules.
 * JSON contracts map this to snake_case (apps/web/src/orgo/types/task.ts).
 */
export interface TaskDto {
  taskId: string;
  organizationId: string;
  caseId: string | null;

  type: string;
  category: TaskCategory;
  subtype: string | null;

  label: string;
  title: string;
  description: string;

  status: TaskStatus;
  priority: TaskPriority;
  severity: TaskSeverity;

  visibility: TaskVisibility;
  source: TaskSource;

  createdByUserId: string | null;
  requesterPersonId: string | null;
  ownerRoleId: string | null;
  ownerUserId: string | null;
  assigneeRole: string | null;

  dueAt: string | null;

  /**
   * Canonical SLA fields.
   * - reactivityTime: ISO 8601 duration (Doc 5 §8.5 & Doc 8 JSON schema)
   * - reactivityDeadlineAt: derived deadline in org-local time (UTC timestamp)
   */
  reactivityTime: string | null;
  reactivityDeadlineAt: string | null;

  escalationLevel: number;
  closedAt: string | null;

  metadata: Record<string, unknown>;

  createdAt: string;
  updatedAt: string;
}

export interface TaskCommentDto {
  id: string;
  taskId: string;
  organizationId: string;
  authorUserId: string | null;
  visibility: TaskCommentVisibility;
  body: string;
  createdAt: string;
  updatedAt: string;
}

/**
 * ListTasksResult – internal service-level list response,
 * mapped by controllers to the web ListTasksResponse / AdminTaskOverviewResponse.
 */
export interface ListTasksResult {
  items: TaskDto[];
  total: number;
  /**
   * Optional cursor for offline/sync scenarios. For now we use a simple
   * page-based cursor encoded as a string; controllers can surface this as-is.
   */
  nextCursor: string | null;
}

/**
 * Standard result shape used across Core Services.
 */
export interface ServiceError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

export interface ServiceResult<T> {
  ok: boolean;
  data: T | null;
  error: ServiceError | null;
}

/**
 * Task lifecycle and allowed transitions (Doc 5 §8.5.2 – Task Status Lifecycle).
 */
const TASK_STATE_TRANSITIONS: Record<TaskStatus, TaskStatus[]> = {
  PENDING: ['IN_PROGRESS', 'CANCELLED'],
  IN_PROGRESS: ['ON_HOLD', 'COMPLETED', 'FAILED', 'ESCALATED'],
  ON_HOLD: ['IN_PROGRESS', 'CANCELLED'],
  COMPLETED: [],
  FAILED: [],
  ESCALATED: ['IN_PROGRESS', 'COMPLETED', 'FAILED'],
  CANCELLED: [],
};

const TERMINAL_STATUSES: Set<TaskStatus> = new Set([
  'COMPLETED',
  'FAILED',
  'CANCELLED',
]);

/**
 * Fallback SLA in seconds when neither the org-profile nor the caller
 * provides a reactivity window. 43 200s = 12h (Doc 5 §8.5.3).
 */
const DEFAULT_REACTIVITY_SECONDS = 43_200;

@Injectable()
export class TaskService {
  private readonly logger = new Logger(TaskService.name);

  constructor(
    private readonly prisma: PrismaService,
    private readonly orgProfileService: OrgProfileService,
  ) {}

  /**
   * Multi-tenant Task listing with simple filters and page-based pagination.
   * Controllers adapt this to the public JSON ListTasksResponse shape.
   */
  async listTasks(input: ListTasksInput): Promise<ServiceResult<ListTasksResult>> {
    if (!input.organizationId) {
      return this.fail<ListTasksResult>({
        code: 'TASK_VALIDATION_ERROR',
        message: 'organizationId is required to list tasks.',
      });
    }

    const page = input.page && input.page > 0 ? input.page : 1;
    const pageSizeRaw =
      input.pageSize && input.pageSize > 0 ? input.pageSize : 50;
    const pageSize = Math.min(pageSizeRaw, 500);
    const skip = (page - 1) * pageSize;

    const where: Record<string, any> = {
      organization_id: input.organizationId,
    };

    const normalizeFilterValues = <T>(
      raw: string | string[] | undefined,
      normalizer: (value: string) => T | null,
    ): T[] | null => {
      if (!raw) return null;
      const values = Array.isArray(raw) ? raw : [raw];
      const normalized: T[] = [];

      for (const value of values) {
        if (!value) continue;
        if (value === 'all') {
          // "all" means no filter; handled by skipping assigning predicate.
          return null;
        }
        const v = normalizer(String(value));
        if (v) {
          normalized.push(v);
        }
      }

      return normalized.length ? normalized : null;
    };

    const statusValues = normalizeFilterValues<TaskStatus>(
      input.status,
      (token) => this.normalizeStatus(token),
    );
    if (statusValues) {
      where.status = { in: statusValues };
    }

    const priorityValues = normalizeFilterValues<TaskPriority>(
      input.priority,
      (token) => this.normalizePriority(token),
    );
    if (priorityValues) {
      where.priority = { in: priorityValues };
    }

    const severityValues = normalizeFilterValues<TaskSeverity>(
      input.severity,
      (token) => this.normalizeSeverity(token),
    );
    if (severityValues) {
      where.severity = { in: severityValues };
    }

    const visibilityValues = normalizeFilterValues<TaskVisibility>(
      input.visibility,
      (token) => this.normalizeVisibility(token),
    );
    if (visibilityValues) {
      where.visibility = { in: visibilityValues };
    }

    if (input.label) {
      // Filter by canonical label code (exact match; prefix logic lives in Case listing).
      where.label = input.label;
    }

    if (input.type) {
      where.type = input.type;
    }

    if (input.assigneeRole) {
      where.assignee_role = input.assigneeRole;
    }

    try {
      const prismaAny = this.prisma as any;

      const [rows, total] = await Promise.all([
        prismaAny.task.findMany({
          where,
          orderBy: { created_at: 'desc' },
          skip,
          take: pageSize,
        }),
        prismaAny.task.count({ where }),
      ]);

      const items = rows.map((row: any) => this.mapTaskModelToDto(row));
      const reachedEnd = skip + items.length >= total;
      const nextCursor = reachedEnd ? null : String(page + 1);

      return this.ok<ListTasksResult>({
        items,
        total,
        nextCursor,
      });
    } catch (error) {
      this.logger.error(
        `Failed to list tasks for organization ${input.organizationId}: ${String(
          error,
        )}`,
      );
      return this.fail<ListTasksResult>({
        code: 'TASK_LIST_FAILED',
        message: 'Failed to list tasks.',
        details: { organizationId: input.organizationId },
      });
    }
  }

  /**
   * Convenience wrapper for API layer. In Core Services and domain modules,
   * prefer getTaskById(organizationId, taskId) to keep explicit tenancy.
   *
   * The API layer is expected to enforce organization scoping before calling.
   */
  async getTask(taskId: string): Promise<ServiceResult<TaskDto>> {
    if (!taskId) {
      return this.fail<TaskDto>({
        code: 'TASK_VALIDATION_ERROR',
        message: 'taskId is required.',
      });
    }

    try {
      const prismaAny = this.prisma as any;
      const model = await prismaAny.task.findUnique({
        where: { id: taskId },
      });

      if (!model) {
        return this.fail<TaskDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${taskId} not found.`,
        });
      }

      const dto = this.mapTaskModelToDto(model);
      return this.ok(dto);
    } catch (error) {
      this.logger.error(`Failed to fetch task ${taskId}: ${String(error)}`);
      return this.fail<TaskDto>({
        code: 'TASK_FETCH_FAILED',
        message: 'Failed to fetch task.',
        details: { taskId },
      });
    }
  }

  /**
   * Task creation entry point used by API, workflows, email router and domain modules.
   * Enforces Task spec and uses OrgProfileService for SLA defaults where available.
   */
  async createTask(input: CreateTaskInput): Promise<ServiceResult<TaskDto>> {
    const validationError = this.validateCreateTaskInput(input);
    if (validationError) {
      return this.fail<TaskDto>({
        code: 'TASK_VALIDATION_ERROR',
        message: validationError,
      });
    }

    const now = new Date();

    try {
      const {
        priority,
        visibility,
        severity,
        reactivitySeconds,
        reactivityTimeIso,
        reactivityDeadlineAt,
      } = await this.computeSlaAndClassificationForCreate(input, now);

      const prismaAny = this.prisma as any;

      const created = await prismaAny.task.create({
        data: {
          organization_id: input.organizationId,
          case_id: input.caseId ?? null,

          type: input.type,
          category: input.category,
          subtype: input.subtype ?? null,

          label: input.label,
          title: input.title,
          description: input.description,

          status: 'PENDING',
          priority,
          severity,
          visibility,
          source: this.normalizeSource(input.source) ?? 'manual',

          created_by_user_id: input.createdByUserId ?? null,
          requester_person_id: input.requesterPersonId ?? null,
          owner_role_id: input.ownerRoleId ?? null,
          owner_user_id: input.ownerUserId ?? null,
          assignee_role: input.assigneeRole ?? null,

          due_at: input.dueAt ? new Date(input.dueAt) : null,

          reactivity_time: reactivityTimeIso ?? null,
          reactivity_deadline_at: reactivityDeadlineAt,
          escalation_level: 0,
          closed_at: null,

          metadata: input.metadata ?? {},
        },
      });

      const dto = this.mapTaskModelToDto(created);
      await this.recordTaskEvent('task_created', dto.taskId, dto.organizationId, {
        category: dto.category,
        label: dto.label,
        priority: dto.priority,
        severity: dto.severity,
      });

      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to create task for organization ${input.organizationId}: ${String(
          error,
        )}`,
      );
      return this.fail<TaskDto>({
        code: 'TASK_CREATE_FAILED',
        message: 'Failed to create task.',
        details: { organizationId: input.organizationId },
      });
    }
  }

  async updateTaskStatus(
    input: UpdateTaskStatusInput,
  ): Promise<ServiceResult<TaskDto>> {
    const newStatusNormalized = this.normalizeStatus(
      input.newStatus as string,
    );

    if (!newStatusNormalized) {
      return this.fail<TaskDto>({
        code: 'TASK_VALIDATION_ERROR',
        message: `Invalid new task status: ${input.newStatus}`,
      });
    }

    try {
      const taskModel = await this.getTaskModelForOrg(
        input.organizationId,
        input.taskId,
      );

      if (!taskModel) {
        return this.fail<TaskDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${input.taskId} not found in organization ${input.organizationId}.`,
        });
      }

      const currentStatus =
        this.normalizeStatus(taskModel.status) ?? 'PENDING';

      if (currentStatus === newStatusNormalized) {
        const dto = this.mapTaskModelToDto(taskModel);
        return this.ok(dto);
      }

      if (!this.isTransitionAllowed(currentStatus, newStatusNormalized)) {
        return this.fail<TaskDto>({
          code: 'TASK_INVALID_TRANSITION',
          message: `Transition from ${currentStatus} to ${newStatusNormalized} is not allowed.`,
          details: {
            from: currentStatus,
            to: newStatusNormalized,
          },
        });
      }

      const now = new Date();
      const data: any = {
        status: newStatusNormalized,
        updated_at: now,
      };

      const wasTerminal = TERMINAL_STATUSES.has(currentStatus);
      const isNowTerminal = TERMINAL_STATUSES.has(newStatusNormalized);

      if (!wasTerminal && isNowTerminal) {
        data.closed_at = now;
      } else if (wasTerminal && !isNowTerminal) {
        data.closed_at = null;
      }

      const prismaAny = this.prisma as any;
      const updated = await prismaAny.task.update({
        where: { id: input.taskId },
        data,
      });

      const dto = this.mapTaskModelToDto(updated);

      await this.recordTaskEvent(
        'task_status_changed',
        dto.taskId,
        dto.organizationId,
        {
          previousStatus: currentStatus,
          nextStatus: newStatusNormalized,
          reason: input.reason,
          actorUserId: input.actorUserId,
        },
      );

      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to update status for task ${input.taskId}: ${String(error)}`,
      );
      return this.fail<TaskDto>({
        code: 'TASK_STATUS_UPDATE_FAILED',
        message: 'Failed to update task status.',
        details: {
          taskId: input.taskId,
          organizationId: input.organizationId,
        },
      });
    }
  }

  async escalateTask(
    input: EscalateTaskInput,
  ): Promise<ServiceResult<TaskDto>> {
    try {
      const taskModel = await this.getTaskModelForOrg(
        input.organizationId,
        input.taskId,
      );

      if (!taskModel) {
        return this.fail<TaskDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${input.taskId} not found in organization ${input.organizationId}.`,
        });
      }

      const currentStatus =
        this.normalizeStatus(taskModel.status) ?? 'PENDING';

      if (
        !['PENDING', 'IN_PROGRESS', 'ON_HOLD', 'ESCALATED'].includes(
          currentStatus,
        )
      ) {
        return this.fail<TaskDto>({
          code: 'TASK_CANNOT_ESCALATE',
          message: `Task in status ${currentStatus} cannot be escalated.`,
        });
      }

      const now = new Date();
      const nextEscalationLevel =
        typeof taskModel.escalation_level === 'number'
          ? taskModel.escalation_level + 1
          : 1;

      const prismaAny = this.prisma as any;
      const updated = await prismaAny.task.update({
        where: { id: input.taskId },
        data: {
          status: 'ESCALATED',
          escalation_level: nextEscalationLevel,
          updated_at: now,
        },
      });

      const dto = this.mapTaskModelToDto(updated);

      await this.recordTaskEvent('task_escalated', dto.taskId, dto.organizationId, {
        previousStatus: currentStatus,
        nextStatus: 'ESCALATED',
        previousEscalationLevel: taskModel.escalation_level ?? 0,
        newEscalationLevel: nextEscalationLevel,
        reason: input.escalationReason,
        actorUserId: input.actorUserId,
      });

      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to escalate task ${input.taskId}: ${String(error)}`,
      );
      return this.fail<TaskDto>({
        code: 'TASK_ESCALATION_FAILED',
        message: 'Failed to escalate task.',
        details: {
          taskId: input.taskId,
          organizationId: input.organizationId,
        },
      });
    }
  }

  async assignTask(input: AssignTaskInput): Promise<ServiceResult<TaskDto>> {
    try {
      const taskModel = await this.getTaskModelForOrg(
        input.organizationId,
        input.taskId,
      );

      if (!taskModel) {
        return this.fail<TaskDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${input.taskId} not found in organization ${input.organizationId}.`,
        });
      }

      const prismaAny = this.prisma as any;
      const updated = await prismaAny.task.update({
        where: { id: input.taskId },
        data: {
          assignee_role: input.assigneeRole ?? null,
          owner_user_id: input.ownerUserId ?? null,
          owner_role_id: input.ownerRoleId ?? null,
          updated_at: new Date(),
        },
      });

      const dto = this.mapTaskModelToDto(updated);

      await this.recordTaskEvent(
        'task_ownership_changed',
        dto.taskId,
        dto.organizationId,
        {
          previousOwnerUserId: taskModel.owner_user_id ?? null,
          newOwnerUserId: input.ownerUserId ?? null,
          previousOwnerRoleId: taskModel.owner_role_id ?? null,
          newOwnerRoleId: input.ownerRoleId ?? null,
          previousAssigneeRole: taskModel.assignee_role ?? null,
          newAssigneeRole: input.assigneeRole ?? null,
          actorUserId: input.actorUserId,
          reason: input.reason,
        },
      );

      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to assign task ${input.taskId}: ${String(error)}`,
      );
      return this.fail<TaskDto>({
        code: 'TASK_ASSIGN_FAILED',
        message: 'Failed to assign task.',
        details: {
          taskId: input.taskId,
          organizationId: input.organizationId,
        },
      });
    }
  }

  async addComment(
    input: AddTaskCommentInput,
  ): Promise<ServiceResult<TaskCommentDto>> {
    if (!input.body || !input.body.trim()) {
      return this.fail<TaskCommentDto>({
        code: 'TASK_VALIDATION_ERROR',
        message: 'Comment body must not be empty.',
      });
    }

    if (
      !['internal_only', 'requester_visible', 'org_wide'].includes(
        input.visibility,
      )
    ) {
      return this.fail<TaskCommentDto>({
        code: 'TASK_VALIDATION_ERROR',
        message: `Invalid comment visibility: ${input.visibility}`,
      });
    }

    try {
      const taskModel = await this.getTaskModelForOrg(
        input.organizationId,
        input.taskId,
      );

      if (!taskModel) {
        return this.fail<TaskCommentDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${input.taskId} not found in organization ${input.organizationId}.`,
        });
      }

      const prismaAny = this.prisma as any;
      const created = await prismaAny.task_comment.create({
        data: {
          task_id: input.taskId,
          author_user_id: input.authorUserId ?? null,
          visibility: input.visibility,
          body: input.body.trim(),
        },
      });

      const dto: TaskCommentDto = {
        id: String(created.id),
        taskId: String(created.task_id),
        organizationId: String(taskModel.organization_id),
        authorUserId: created.author_user_id ?? null,
        visibility: created.visibility,
        body: created.body,
        createdAt: created.created_at.toISOString(),
        updatedAt: created.updated_at.toISOString(),
      };

      await this.recordTaskEvent(
        'task_comment_added',
        dto.taskId,
        dto.organizationId,
        {
          commentId: dto.id,
          visibility: dto.visibility,
          authorUserId: dto.authorUserId,
        },
      );

      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to add comment to task ${input.taskId}: ${String(error)}`,
      );
      return this.fail<TaskCommentDto>({
        code: 'TASK_COMMENT_FAILED',
        message: 'Failed to add comment to task.',
        details: {
          taskId: input.taskId,
          organizationId: input.organizationId,
        },
      });
    }
  }

  /**
   * Multi-tenant Task fetch used by domain modules and workflows.
   */
  async getTaskById(
    organizationId: string,
    taskId: string,
  ): Promise<ServiceResult<TaskDto>> {
    try {
      const model = await this.getTaskModelForOrg(organizationId, taskId);

      if (!model) {
        return this.fail<TaskDto>({
          code: 'TASK_NOT_FOUND',
          message: `Task with id ${taskId} not found in organization ${organizationId}.`,
        });
      }

      const dto = this.mapTaskModelToDto(model);
      return this.ok(dto);
    } catch (error) {
      this.logger.error(
        `Failed to fetch task ${taskId} for organization ${organizationId}: ${String(
          error,
        )}`,
      );
      return this.fail<TaskDto>({
        code: 'TASK_FETCH_FAILED',
        message: 'Failed to fetch task.',
        details: { taskId, organizationId },
      });
    }
  }

  // ---------------------------------------------------------------------------
  // SLA / Org profile integration helpers
  // ---------------------------------------------------------------------------

  private async computeSlaAndClassificationForCreate(
    input: CreateTaskInput,
    now: Date,
  ): Promise<{
    priority: TaskPriority;
    severity: TaskSeverity;
    visibility: TaskVisibility;
    reactivitySeconds: number | null;
    reactivityTimeIso: string | null;
    reactivityDeadlineAt: Date | null;
  }> {
    const normalizedPriority = this.normalizePriority(input.priority);
    const normalizedVisibility = this.normalizeVisibility(input.visibility);
    const normalizedSeverity =
      this.normalizeSeverity(input.severity) ?? 'MINOR';

    const requestedSeconds =
      typeof input.reactivitySeconds === 'number' && input.reactivitySeconds > 0
        ? input.reactivitySeconds
        : input.reactivityTimeIso
        ? this.parseIsoDurationToSeconds(input.reactivityTimeIso)
        : null;

    let profileDefaults: ApplyDefaultsResult | null = null;

    try {
      profileDefaults = await this.orgProfileService.applyDefaults({
        organizationId: input.organizationId,
        kind: 'task',
        existingPriority: normalizedPriority ?? undefined,
        existingVisibility: normalizedVisibility ?? undefined,
        requestedReactivitySeconds: requestedSeconds ?? undefined,
      });
    } catch (error) {
      this.logger.warn(
        `OrgProfileService.applyDefaults failed for org ${input.organizationId}: ${String(
          error,
        )}`,
      );
    }

    const priority: TaskPriority =
      (profileDefaults?.priority as TaskPriority | undefined) ??
      normalizedPriority ??
      'MEDIUM';

    const visibility: TaskVisibility =
      (profileDefaults?.visibility as TaskVisibility | undefined) ??
      normalizedVisibility ??
      'INTERNAL';

    const reactivitySeconds =
      profileDefaults?.reactivitySeconds ??
      requestedSeconds ??
      DEFAULT_REACTIVITY_SECONDS;

    const reactivityTimeIso =
      profileDefaults?.reactivityTimeIso ??
      input.reactivityTimeIso ??
      (reactivitySeconds != null
        ? this.secondsToIsoDuration(reactivitySeconds)
        : null);

    let reactivityDeadlineAt: Date | null = null;

    if (input.reactivityDeadlineAt) {
      reactivityDeadlineAt = this.toDateOrNull(input.reactivityDeadlineAt);
    } else if (reactivitySeconds != null) {
      reactivityDeadlineAt = new Date(now.getTime() + reactivitySeconds * 1000);
    }

    return {
      priority,
      severity: normalizedSeverity,
      visibility,
      reactivitySeconds,
      reactivityTimeIso,
      reactivityDeadlineAt,
    };
  }

  private parseIsoDurationToSeconds(
    isoDuration: string | null | undefined,
  ): number | null {
    if (!isoDuration) return null;

    const isoPattern =
      /^P(?:(\d+)D)?(?:T(?:(\d+)H)?(?:(\d+)M)?(?:(\d+(?:\.\d+)?)S)?)?$/;
    const match = isoDuration.match(isoPattern);
    if (!match) {
      return null;
    }

    const days = match[1] ? parseInt(match[1], 10) : 0;
    const hours = match[2] ? parseInt(match[2], 10) : 0;
    const minutes = match[3] ? parseInt(match[3], 10) : 0;
    const seconds = match[4] ? parseFloat(match[4]) : 0;

    return days * 86400 + hours * 3600 + minutes * 60 + seconds;
  }

  private secondsToIsoDuration(seconds: number): string {
    if (!Number.isFinite(seconds) || seconds <= 0) {
      return 'PT0S';
    }

    const total = Math.floor(seconds);
    const days = Math.floor(total / 86400);
    let remaining = total - days * 86400;
    const hours = Math.floor(remaining / 3600);
    remaining -= hours * 3600;
    const minutes = Math.floor(remaining / 60);
    const secs = remaining - minutes * 60;

    let result = 'P';
    if (days > 0) {
      result += `${days}D`;
    }

    if (hours || minutes || secs || days === 0) {
      result += 'T';
    }

    if (hours) {
      result += `${hours}H`;
    }
    if (minutes) {
      result += `${minutes}M`;
    }
    if (secs || (!days && !hours && !minutes)) {
      result += `${secs}S`;
    }

    return result;
  }

  private toDateOrNull(value: string | Date | null): Date | null {
    if (!value) return null;
    if (value instanceof Date) return value;
    const asDate = new Date(value);
    return Number.isNaN(asDate.getTime()) ? null : asDate;
  }

  // ---------------------------------------------------------------------------
  // Validation & normalization helpers
  // ---------------------------------------------------------------------------

  private validateCreateTaskInput(input: CreateTaskInput): string | null {
    const requiredStringFields: (keyof CreateTaskInput)[] = [
      'organizationId',
      'type',
      'category',
      'title',
      'description',
      'label',
      'source',
    ];

    for (const field of requiredStringFields) {
      const value = input[field];
      if (typeof value !== 'string' || value.trim().length === 0) {
        return `Field "${field}" is required and must be a non-empty string.`;
      }
    }

    if (!this.normalizeSource(input.source)) {
      return 'Invalid task source.';
    }

    if (input.priority !== undefined && !this.normalizePriority(input.priority)) {
      return 'Invalid task priority.';
    }

    if (input.severity !== undefined && !this.normalizeSeverity(input.severity)) {
      return 'Invalid task severity.';
    }

    if (
      input.visibility !== undefined &&
      !this.normalizeVisibility(input.visibility)
    ) {
      return 'Invalid task visibility.';
    }

    if (!input.category) {
      return 'Task category is required.';
    }

    return null;
  }

  private normalizeStatus(input: string): TaskStatus | null {
    if (!input) return null;
    const upper = input.toUpperCase() as TaskStatus;
    if (upper in TASK_STATE_TRANSITIONS || TERMINAL_STATUSES.has(upper)) {
      return upper;
    }
    return null;
  }

  private normalizePriority(input: PriorityInput): TaskPriority | null {
    if (!input) return null;
    const upper = String(input).toUpperCase() as TaskPriority;
    if (['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'].includes(upper)) {
      return upper;
    }
    return null;
  }

  private normalizeSeverity(input: SeverityInput): TaskSeverity | null {
    if (!input) return null;
    const upper = String(input).toUpperCase() as TaskSeverity;
    if (['MINOR', 'MODERATE', 'MAJOR', 'CRITICAL'].includes(upper)) {
      return upper;
    }
    return null;
  }

  private normalizeVisibility(input: VisibilityInput): TaskVisibility | null {
    if (!input) return null;
    const upper = String(input).toUpperCase() as TaskVisibility;
    if (['PUBLIC', 'INTERNAL', 'RESTRICTED', 'ANONYMISED'].includes(upper)) {
      return upper;
    }
    return null;
  }

  private normalizeSource(input: SourceInput): TaskSource | null {
    if (!input) return null;
    const lower = String(input).toLowerCase() as TaskSource;
    if (['email', 'api', 'manual', 'sync'].includes(lower)) {
      return lower;
    }
    return null;
  }

  private isTransitionAllowed(from: TaskStatus, to: TaskStatus): boolean {
    const allowed = TASK_STATE_TRANSITIONS[from] ?? [];
    return allowed.includes(to);
  }

  private async getTaskModelForOrg(
    organizationId: string,
    taskId: string,
  ): Promise<any | null> {
    const prismaAny = this.prisma as any;
    const model = await prismaAny.task.findUnique({
      where: { id: taskId },
    });

    if (!model) {
      return null;
    }

    const orgId =
      model.organization_id ?? model.organizationId ?? model.org_id;
    if (orgId !== organizationId) {
      this.logger.warn(
        `Attempt to access task ${taskId} from wrong organization ${organizationId}`,
      );
      return null;
    }

    return model;
  }

  private mapTaskModelToDto(model: any): TaskDto {
    const get = (...keys: string[]) => {
      for (const key of keys) {
        if (key in model && model[key] !== undefined) {
          return model[key];
        }
      }
      return undefined;
    };

    const id = get('id', 'task_id');
    const organizationId = get('organization_id', 'organizationId');
    const caseId = get('case_id', 'caseId') ?? null;

    const status = this.normalizeStatus(get('status')) ?? 'PENDING';
    const priority =
      this.normalizePriority(get('priority')) ?? 'MEDIUM';
    const severity =
      this.normalizeSeverity(get('severity')) ?? 'MINOR';
    const visibility =
      this.normalizeVisibility(get('visibility')) ?? 'INTERNAL';
    const source = this.normalizeSource(get('source')) ?? 'manual';

    const escalationLevel = get('escalation_level', 'escalationLevel');
    const meta = get('metadata') ?? {};

    const reactivityTimeRaw = get('reactivity_time', 'reactivityTime');

    const toIso = (value: any | null | undefined): string | null => {
      if (!value) return null;
      if (value instanceof Date) return value.toISOString();
      const asDate = new Date(value);
      return Number.isNaN(asDate.getTime()) ? null : asDate.toISOString();
    };

    const reactivityTime: string | null =
      typeof reactivityTimeRaw === 'string'
        ? reactivityTimeRaw
        : typeof reactivityTimeRaw === 'number'
        ? this.secondsToIsoDuration(reactivityTimeRaw)
        : null;

    return {
      taskId: String(id),
      organizationId: String(organizationId),
      caseId: caseId ? String(caseId) : null,

      type: String(get('type') ?? ''),
      category: (get('category') as TaskCategory) ?? 'request',
      subtype: get('subtype') ?? null,

      label: String(get('label') ?? ''),
      title: String(get('title') ?? ''),
      description: String(get('description') ?? ''),

      status,
      priority,
      severity,

      visibility,
      source,

      createdByUserId: get('created_by_user_id', 'createdByUserId') ?? null,
      requesterPersonId:
        get('requester_person_id', 'requesterPersonId') ?? null,
      ownerRoleId: get('owner_role_id', 'ownerRoleId') ?? null,
      ownerUserId: get('owner_user_id', 'ownerUserId') ?? null,
      assigneeRole: get('assignee_role', 'assigneeRole') ?? null,

      dueAt: toIso(get('due_at', 'dueAt')),
      reactivityTime,
      reactivityDeadlineAt: toIso(
        get('reactivity_deadline_at', 'reactivityDeadlineAt'),
      ),
      escalationLevel:
        typeof escalationLevel === 'number' ? escalationLevel : 0,
      closedAt: toIso(get('closed_at', 'closedAt')),

      metadata: typeof meta === 'object' && meta !== null ? meta : {},

      createdAt:
        toIso(get('created_at', 'createdAt')) ?? new Date().toISOString(),
      updatedAt:
        toIso(get('updated_at', 'updatedAt')) ?? new Date().toISOString(),
    };
  }

  private async recordTaskEvent(
    type:
      | 'task_created'
      | 'task_status_changed'
      | 'task_escalated'
      | 'task_ownership_changed'
      | 'task_comment_added',
    taskId: string,
    organizationId: string,
    metadata?: Record<string, any>,
  ): Promise<void> {
    // For now we only log via NestJS Logger.
    // Later this can be wired into TaskEventsService + task_events table.
    this.logger.log(
      JSON.stringify({
        type,
        taskId,
        organizationId,
        metadata: metadata ?? {},
      }),
      'TaskEvent',
    );
  }

  private ok<T>(data: T): ServiceResult<T> {
    return { ok: true, data, error: null };
  }

  private fail<T>(error: ServiceError): ServiceResult<T> {
    return { ok: false, data: null, error };
  }
}


=== FILE 42/48: apps/api/src/orgo/core/validation/config-validation.service.ts ===

import { Injectable, Logger } from '@nestjs/common';

type OrgoEnvironment = 'dev' | 'staging' | 'prod' | 'offline';

const ORGO_ENVIRONMENTS: OrgoEnvironment[] = [
  'dev',
  'staging',
  'prod',
  'offline',
];

export interface ConfigMetadata {
  config_name: string;
  version: string;
  environment: OrgoEnvironment;
  last_updated: string;
  owner?: string;
  organization_id?: string;
  // Allow additional metadata keys without forcing a strict schema here
  // (domain modules and other services may extend this).
  [key: string]: unknown;
}

export interface ConfigValidationErrorDetail {
  /**
   * JSON-style path to the offending value, e.g. "metadata.version" or "smtp.host".
   * Empty string ("") refers to the root object.
   */
  path: string;
  message: string;
}

export interface StandardError {
  code: string;
  message: string;
  details?: {
    errors?: ConfigValidationErrorDetail[];
    [key: string]: unknown;
  };
}

export interface ValidationResult<T> {
  ok: boolean;
  data: T | null;
  error: StandardError | null;
}

/**
 * Represents one config entry in a bundle (e.g., email_config, database_connection).
 */
export interface ConfigBundleItem<TConfig = any> {
  name: string;
  config: TConfig;
  requiredKeys: string[];
}

/**
 * ConfigValidatorService (validation_core)
 *
 * Cross-cutting configuration validation utilities used by Core Services and modules.
 * Implements the standard result shape and metadata/env/version checks.
 */
@Injectable()
export class ConfigValidatorService {
  private readonly logger = new Logger(ConfigValidatorService.name);

  /**
   * Validates a single configuration object against:
   * - Common metadata rules (Doc 2 §3.2, Doc 5 §10.2).
   * - Presence and basic non-null checks for required keys.
   *
   * Returns the standard result shape:
   *   { ok: true, data: config, error: null } on success
   *   { ok: false, data: null, error: { code: "CONFIG_VALIDATION_ERROR", ... } } on failure
   */
  validateConfig<T extends Record<string, any>>(
    config: T | null | undefined,
    requiredKeys: string[] = [],
  ): ValidationResult<T> {
    const errors: ConfigValidationErrorDetail[] = [];

    if (!config || typeof config !== 'object' || Array.isArray(config)) {
      errors.push({
        path: '',
        message: 'Config must be a non-null object.',
      });

      return this.buildFailure<T>(
        'Configuration is not a valid object.',
        errors,
      );
    }

    this.validateMetadata(config as Record<string, any>, errors);
    this.validateRequiredKeys(config as Record<string, any>, requiredKeys, errors);

    if (errors.length > 0) {
      return this.buildFailure<T>(
        'One or more configuration validation errors occurred.',
        errors,
      );
    }

    return {
      ok: true,
      data: config as T,
      error: null,
    };
  }

  /**
   * Validates a bundle (set) of configuration objects.
   *
   * Each item is validated independently using validateConfig; any error in any
   * item produces a single CONFIG_VALIDATION_ERROR result containing all errors
   * with namespaced paths ("<configName>.<path>").
   *
   * On success, returns only the items that validated successfully in `data`.
   */
  validateConfigBundle(
    items: ConfigBundleItem[],
  ): ValidationResult<ConfigBundleItem[]> {
    const errors: ConfigValidationErrorDetail[] = [];
    const validItems: ConfigBundleItem[] = [];

    for (const item of items) {
      const result = this.validateConfig(item.config, item.requiredKeys);

      if (!result.ok && result.error && result.error.details?.errors) {
        for (const err of result.error.details.errors) {
          errors.push({
            path: item.name
              ? `${item.name}${err.path ? `.${err.path}` : ''}`
              : err.path,
            message: err.message,
          });
        }
      } else if (result.ok) {
        validItems.push(item);
      }
    }

    if (errors.length > 0) {
      return this.buildFailure<ConfigBundleItem[]>(
        'One or more configuration bundle validation errors occurred.',
        errors,
      );
    }

    return {
      ok: true,
      data: validItems,
      error: null,
    };
  }

  /**
   * Validates common metadata for all YAML/JSON configs under /config.
   *
   * Enforces:
   * - metadata exists and is an object
   * - metadata.config_name is non-empty
   * - metadata.environment ∈ ENVIRONMENT = { dev, staging, prod, offline }
   * - metadata.version matches ^3\.[0-9]+$ (Orgo v3 configs)
   * - metadata.last_updated is a valid YYYY-MM-DD date
   * - metadata.organization_id is "default" or a slug-like identifier
   */
  private validateMetadata(
    config: Record<string, any>,
    errors: ConfigValidationErrorDetail[],
  ): void {
    const meta = config.metadata;

    if (!meta || typeof meta !== 'object' || Array.isArray(meta)) {
      errors.push({
        path: 'metadata',
        message: 'Metadata object is required on all configuration files.',
      });
      return;
    }

    const {
      config_name: configName,
      environment,
      version,
      last_updated: lastUpdated,
      organization_id: organizationId,
    } = meta as Record<string, any>;

    if (typeof configName !== 'string' || configName.trim().length === 0) {
      errors.push({
        path: 'metadata.config_name',
        message: 'metadata.config_name must be a non-empty string.',
      });
    }

    if (
      typeof environment !== 'string' ||
      !ORGO_ENVIRONMENTS.includes(environment as OrgoEnvironment)
    ) {
      errors.push({
        path: 'metadata.environment',
        message: `metadata.environment must be one of: ${ORGO_ENVIRONMENTS.join(
          ', ',
        )}.`,
      });
    }

    if (typeof version !== 'string' || !/^3\.\d+$/.test(version)) {
      errors.push({
        path: 'metadata.version',
        message:
          'metadata.version must match the pattern ^3\\.[0-9]+$ for Orgo v3 configs.',
      });
    }

    if (typeof lastUpdated !== 'string' || !this.isValidIsoDate(lastUpdated)) {
      errors.push({
        path: 'metadata.last_updated',
        message:
          'metadata.last_updated must be a valid date string in YYYY-MM-DD format.',
      });
    }

    if (organizationId !== undefined) {
      if (
        typeof organizationId !== 'string' ||
        organizationId.trim().length === 0
      ) {
        errors.push({
          path: 'metadata.organization_id',
          message:
            'metadata.organization_id, if provided, must be a non-empty string.',
        });
      } else if (
        organizationId !== 'default' &&
        !/^[a-zA-Z0-9_-]+$/.test(organizationId)
      ) {
        errors.push({
          path: 'metadata.organization_id',
          message:
            'metadata.organization_id must be "default" or a slug/identifier containing only letters, numbers, underscore or dash.',
        });
      }
    }
  }

  /**
   * Ensures required top-level keys exist and are not null/undefined/empty-string.
   */
  private validateRequiredKeys(
    config: Record<string, any>,
    requiredKeys: string[],
    errors: ConfigValidationErrorDetail[],
  ): void {
    for (const key of requiredKeys) {
      if (!(key in config)) {
        errors.push({
          path: key,
          message: `Missing required configuration key "${key}".`,
        });
        continue;
      }

      const value = config[key];

      if (
        value === null ||
        value === undefined ||
        (typeof value === 'string' && value.trim().length === 0)
      ) {
        errors.push({
          path: key,
          message: `Configuration key "${key}" must not be null, undefined or an empty string.`,
        });
      }
    }
  }

  /**
   * Basic YYYY-MM-DD validator using a regex + Date.parse.
   */
  private isValidIsoDate(value: string): boolean {
    if (!/^\d{4}-\d{2}-\d{2}$/.test(value)) {
      return false;
    }

    const timestamp = Date.parse(value);
    return Number.isFinite(timestamp);
  }

  /**
   * Builds a CONFIG_VALIDATION_ERROR result and logs it using Nest's Logger.
   */
  private buildFailure<T>(
    message: string,
    errors: ConfigValidationErrorDetail[],
  ): ValidationResult<T> {
    const error: StandardError = {
      code: 'CONFIG_VALIDATION_ERROR',
      message,
      details: {
        errors,
      },
    };

    this.logger.error(
      `[CONFIG_VALIDATION_ERROR] ${message}`,
      errors.map((e) => `${e.path || '<root>'}: ${e.message}`).join('; '),
    );

    return {
      ok: false,
      data: null,
      error,
    };
  }
}


=== FILE 43/48: apps/api/src/orgo/core/validation/metadata.service.ts ===

import { Injectable, Logger } from '@nestjs/common';

export type MetadataEntity = 'task' | 'case';

export interface NormalizeMetadataResult {
  /**
   * Sanitized metadata object that is safe to persist in tasks.metadata / cases.metadata.
   */
  metadata: Record<string, unknown>;
  /**
   * Top-level keys that were removed during normalization.
   */
  removedKeys: string[];
  /**
   * Human-readable explanations of normalization steps that dropped or changed values.
   */
  warnings: string[];
}

/**
 * Keys that must never be accepted from external payloads because they can
 * mutate Object.prototype or otherwise cause prototype pollution.
 */
const PROTOTYPE_POLLUTION_KEYS = new Set<string>(['__proto__', 'constructor', 'prototype']);

/**
 * Canonical Task fields and common aliases that must not appear inside tasks.metadata.
 * Based on the canonical Task JSON contract and DB schema.
 */
const TASK_RESERVED_METADATA_KEYS = new Set<string>([
  // Identifiers
  'task_id',
  'id',
  'taskId',
  'organization_id',
  'organizationId',
  'org_id',
  'orgId',
  'case_id',
  'caseId',

  // Timestamps
  'created_at',
  'createdAt',
  'updated_at',
  'updatedAt',

  // Classification
  'type',
  'category',
  'subtype',
  'label',

  // Core state
  'status',
  'priority',
  'severity',
  'visibility',
  'source',

  // Actors / routing
  'title',
  'description',
  'created_by_user_id',
  'createdByUserId',
  'requester_person_id',
  'requesterPersonId',
  'owner_role_id',
  'ownerRoleId',
  'owner_user_id',
  'ownerUserId',
  'assignee_role',
  'assigneeRole',

  // SLA / escalation
  'due_at',
  'dueAt',
  'reactivity_time',
  'reactivityTime',
  'reactivity_deadline_at',
  'reactivityDeadlineAt',
  'escalation_level',
  'escalationLevel',
  'closed_at',
  'closedAt',

  // Nested metadata container itself
  'metadata',
]);

/**
 * Canonical Case fields and common aliases that must not appear inside cases.metadata.
 * Based on the canonical Case JSON contract and DB schema.
 */
const CASE_RESERVED_METADATA_KEYS = new Set<string>([
  // Identifiers
  'case_id',
  'id',
  'caseId',
  'organization_id',
  'organizationId',
  'org_id',
  'orgId',

  // Source
  'source_type',
  'sourceType',
  'source_reference',
  'sourceReference',

  // Core fields
  'label',
  'title',
  'description',
  'status',
  'severity',

  // SLA / routing
  'reactivity_time',
  'reactivityTime',
  'origin_vertical_level',
  'originVerticalLevel',
  'origin_role',
  'originRole',

  // Collections
  'tags',
  'location',

  // Nested metadata container itself
  'metadata',

  // Timestamps
  'created_at',
  'createdAt',
  'updated_at',
  'updatedAt',
]);

@Injectable()
export class MetadataService {
  private readonly logger = new Logger(MetadataService.name);

  /**
   * Normalizes free-form metadata to a JSON-safe, canonical shape and strips
   * out any fields that would conflict with canonical Task/Case fields
   * or introduce unsafe keys.
   *
   * Default entity is "task" to match the primary use in Core Services.
   */
  normalizeMetadata(
    raw: unknown,
    entity: MetadataEntity = 'task',
  ): NormalizeMetadataResult {
    const removedKeys: string[] = [];
    const warnings: string[] = [];

    if (raw == null) {
      // Nothing to normalize.
      return { metadata: {}, removedKeys, warnings };
    }

    if (Array.isArray(raw) || typeof raw !== 'object') {
      warnings.push(
        `Expected metadata to be an object for ${entity}, received ${
          Array.isArray(raw) ? 'array' : typeof raw
        }; dropping value.`,
      );
      this.logDiagnostics(entity, removedKeys, warnings);
      return { metadata: {}, removedKeys, warnings };
    }

    const input = raw as Record<string, unknown>;
    const metadata = this.normalizeMetadataObject(input, entity, 0, removedKeys, warnings);

    this.logDiagnostics(entity, removedKeys, warnings);
    return { metadata, removedKeys, warnings };
  }

  private normalizeMetadataObject(
    input: Record<string, unknown>,
    entity: MetadataEntity,
    depth: number,
    removedKeys: string[],
    warnings: string[],
  ): Record<string, unknown> {
    const result: Record<string, unknown> = {};
    const reservedKeys = this.getReservedKeys(entity);

    for (const [key, value] of Object.entries(input)) {
      if (!key) {
        removedKeys.push(key);
        warnings.push('Removed empty metadata key.');
        continue;
      }

      if (this.isPrototypePollutionKey(key)) {
        removedKeys.push(key);
        warnings.push(
          `Removed unsafe metadata key "${key}" to prevent prototype pollution.`,
        );
        continue;
      }

      // Only enforce canonical field conflicts at the top level of metadata.
      if (depth === 0 && reservedKeys.has(key)) {
        removedKeys.push(key);
        warnings.push(
          `Removed metadata key "${key}" because it conflicts with a canonical ${entity} field.`,
        );
        continue;
      }

      const normalizedValue = this.normalizeMetadataValue(
        value,
        entity,
        depth + 1,
        removedKeys,
        warnings,
      );

      if (normalizedValue !== undefined) {
        result[key] = normalizedValue;
      }
    }

    return result;
  }

  private normalizeMetadataValue(
    value: unknown,
    entity: MetadataEntity,
    depth: number,
    removedKeys: string[],
    warnings: string[],
  ): unknown {
    if (value === undefined) {
      // undefined is not valid JSON; drop it.
      return undefined;
    }

    if (value === null) {
      return null;
    }

    const valueType = typeof value;

    if (valueType === 'string' || valueType === 'number' || valueType === 'boolean') {
      return value;
    }

    if (value instanceof Date) {
      return value.toISOString();
    }

    if (Array.isArray(value)) {
      const normalizedArray: unknown[] = [];

      for (const item of value) {
        const normalizedItem = this.normalizeMetadataValue(
          item,
          entity,
          depth + 1,
          removedKeys,
          warnings,
        );

        if (normalizedItem !== undefined) {
          normalizedArray.push(normalizedItem);
        }
      }

      return normalizedArray;
    }

    if (valueType === 'object') {
      return this.normalizeMetadataObject(
        value as Record<string, unknown>,
        entity,
        depth,
        removedKeys,
        warnings,
      );
    }

    // Drop functions, symbols, bigint, etc.
    warnings.push(
      `Dropping non-serializable metadata value of type "${typeof value}" at depth ${depth}.`,
    );
    return undefined;
  }

  private getReservedKeys(entity: MetadataEntity): ReadonlySet<string> {
    return entity === 'case' ? CASE_RESERVED_METADATA_KEYS : TASK_RESERVED_METADATA_KEYS;
  }

  private isPrototypePollutionKey(key: string): boolean {
    return PROTOTYPE_POLLUTION_KEYS.has(key);
  }

  private logDiagnostics(
    entity: MetadataEntity,
    removedKeys: string[],
    warnings: string[],
  ): void {
    if (!removedKeys.length && !warnings.length) {
      return;
    }

    const summaryParts: string[] = [];

    if (removedKeys.length) {
      summaryParts.push(`removedKeys=[${removedKeys.join(', ')}]`);
    }

    if (warnings.length) {
      summaryParts.push(`warnings=${warnings.length}`);
    }

    this.logger.debug(
      `Metadata normalization for ${entity}: ${summaryParts.join(' ')}.`,
    );

    for (const warning of warnings) {
      this.logger.debug(`Metadata normalization warning: ${warning}`);
    }
  }
}


=== FILE 44/48: apps/api/src/orgo/core/validation/payload-validation.pipe.ts ===

// apps/api/src/orgo/core/validation/payload-validation.pipe.ts

import {
  ArgumentMetadata,
  BadRequestException,
  Injectable,
  Logger,
  PipeTransform,
} from '@nestjs/common';
import * as Joi from 'joi';

type ObjectSchema = Joi.ObjectSchema;

export type LogicalPayloadType =
  | 'task'
  | 'case'
  | 'email'
  | 'workflow_rule'
  | 'notification'
  | 'config'
  | 'generic';

export interface PayloadValidationOptions {
  /**
   * Logical payload type to drive default schemas and enum normalisation.
   * If a custom schema is provided, this is only used for error codes and enum mapping.
   */
  logicalType?: LogicalPayloadType;

  /**
   * Allow unknown keys when validating with Joi.
   * Defaults to true (unknown keys are allowed).
   */
  allowUnknown?: boolean;

  /**
   * Strip unknown keys from the validated payload.
   * Defaults to true (unknown keys are removed).
   */
  stripUnknown?: boolean;

  /**
   * Optional custom error code to emit instead of the default type‑specific one.
   */
  customErrorCode?: string;
}

/**
 * Canonical enum values (service‑side) – aligned with Docs 2, 5 and 8.
 * JSON inputs may use lower‑case variants; this pipe normalises to these tokens.
 */
const TASK_STATUS_VALUES = [
  'PENDING',
  'IN_PROGRESS',
  'ON_HOLD',
  'COMPLETED',
  'FAILED',
  'ESCALATED',
  'CANCELLED',
] as const;

const TASK_PRIORITY_VALUES = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'] as const;

const TASK_SEVERITY_VALUES = ['MINOR', 'MODERATE', 'MAJOR', 'CRITICAL'] as const;

const VISIBILITY_VALUES = ['PUBLIC', 'INTERNAL', 'RESTRICTED', 'ANONYMISED'] as const;

const CASE_STATUS_VALUES = [
  'open',
  'in_progress',
  'resolved',
  'archived',
] as const;

const TASK_SOURCE_VALUES = ['email', 'api', 'manual', 'sync'] as const;

const ENVIRONMENT_VALUES = ['dev', 'staging', 'prod', 'offline'] as const;

/**
 * Default Joi schema for canonical Task JSON payloads
 * (Doc 5 – Task Handler, Doc 8 – Task JSON schema).
 *
 * This is intentionally focused on core fields; domain‑specific metadata
 * lives under `metadata` and is validated separately if needed.
 */
const TASK_PAYLOAD_SCHEMA: ObjectSchema = Joi.object({
  task_id: Joi.string().optional(), // usually set by the system
  organization_id: Joi.string().required(),
  case_id: Joi.string().optional().allow(null),

  source: Joi.string()
    .valid(...TASK_SOURCE_VALUES)
    .required(),

  type: Joi.string().required(), // e.g. "maintenance", "hr_case"
  category: Joi.string()
    .valid('request', 'incident', 'update', 'report', 'distribution')
    .required(),
  subtype: Joi.string().optional().allow(null),

  label: Joi.string().required(), // "<BASE>.<CATEGORY><SUBCATEGORY>.<HORIZONTAL_ROLE>"
  title: Joi.string().max(512).required(),
  description: Joi.string().required(),

  status: Joi.string()
    .valid(...TASK_STATUS_VALUES)
    .optional(), // default = PENDING inside the Task handler

  priority: Joi.string()
    .valid(...TASK_PRIORITY_VALUES)
    .required(),
  severity: Joi.string()
    .valid(...TASK_SEVERITY_VALUES)
    .required(),
  visibility: Joi.string()
    .valid(...VISIBILITY_VALUES)
    .required(),

  assignee_role: Joi.string().optional().allow(null),
  created_by_user_id: Joi.string().optional().allow(null),
  requester_person_id: Joi.string().optional().allow(null),
  owner_role_id: Joi.string().optional().allow(null),
  owner_user_id: Joi.string().optional().allow(null),

  due_at: Joi.string().optional().allow(null),
  reactivity_time: Joi.string().optional().allow(null),
  reactivity_deadline_at: Joi.string().optional().allow(null),
  escalation_level: Joi.number().integer().min(0).optional(),
  closed_at: Joi.string().optional().allow(null),

  metadata: Joi.object().default({}),
});

/**
 * Default Joi schema for canonical Case JSON payloads
 * (Doc 8 – Case JSON schema).
 */
const CASE_PAYLOAD_SCHEMA: ObjectSchema = Joi.object({
  case_id: Joi.string().optional(), // usually set by the system
  organization_id: Joi.string().required(),

  source_type: Joi.string()
    .valid(...TASK_SOURCE_VALUES)
    .required(),
  source_reference: Joi.string().optional().allow(null),

  label: Joi.string().required(),
  title: Joi.string().max(512).required(),
  description: Joi.string().required(),

  status: Joi.string()
    .valid(...CASE_STATUS_VALUES)
    .optional(), // default = "open" in the Case service

  // Uses the same severity enum as Tasks, but normalised to uppercase internally.
  severity: Joi.string()
    .valid(...TASK_SEVERITY_VALUES)
    .required(),

  reactivity_time: Joi.string().optional().allow(null),
  origin_vertical_level: Joi.number().integer().optional().allow(null),
  origin_role: Joi.string().optional().allow(null),

  tags: Joi.array().items(Joi.string()).optional().allow(null),
  location: Joi.object().optional().allow(null),
  metadata: Joi.object().required(),

  created_at: Joi.string().optional().allow(null),
  updated_at: Joi.string().optional().allow(null),
});

@Injectable()
export class PayloadValidationPipe implements PipeTransform {
  private readonly logger = new Logger(PayloadValidationPipe.name);

  constructor(
    private readonly schema?: ObjectSchema,
    private readonly options: PayloadValidationOptions = {},
  ) {}

  /**
   * Factory for Task payload validation.
   */
  static forTaskPayload(
    options: Omit<PayloadValidationOptions, 'logicalType'> = {},
  ): PayloadValidationPipe {
    return new PayloadValidationPipe(TASK_PAYLOAD_SCHEMA, {
      logicalType: 'task',
      ...options,
    });
  }

  /**
   * Factory for Case payload validation.
   */
  static forCasePayload(
    options: Omit<PayloadValidationOptions, 'logicalType'> = {},
  ): PayloadValidationPipe {
    return new PayloadValidationPipe(CASE_PAYLOAD_SCHEMA, {
      logicalType: 'case',
      ...options,
    });
  }

  transform(value: unknown, metadata: ArgumentMetadata): any {
    // Only validate request bodies by default; params/query can use other pipes.
    if (metadata.type && metadata.type !== 'body') {
      return value;
    }

    if (value === null || value === undefined) {
      throw this.buildException('Request body must be a JSON object', []);
    }

    if (typeof value !== 'object') {
      throw this.buildException('Request body must be a JSON object', []);
    }

    const logicalType = this.options.logicalType ?? 'generic';

    // Clone & normalise enums and other canonical fields.
    const normalised = this.normalisePayload(
      Array.isArray(value) ? [...value] : { ...(value as Record<string, any>) },
    );

    const schemaToUse = this.schema ?? this.getDefaultSchema(logicalType);

    if (!schemaToUse) {
      // No schema configured – still return the normalised payload.
      return normalised;
    }

    const allowUnknown =
      this.options.allowUnknown !== undefined ? this.options.allowUnknown : true;
    const stripUnknown =
      this.options.stripUnknown !== undefined ? this.options.stripUnknown : true;

    const { error, value: validated } = schemaToUse.validate(normalised, {
      abortEarly: false,
      allowUnknown,
      stripUnknown,
    });

    if (error) {
      this.logger.error(
        `Payload validation failed for type "${logicalType}": ${error.message}`,
      );
      throw this.buildException('Payload validation failed', error.details);
    }

    return validated;
  }

  /**
   * Returns a default schema for a given logical payload type
   * when no explicit schema is provided in the constructor.
   */
  private getDefaultSchema(type: LogicalPayloadType): ObjectSchema | undefined {
    switch (type) {
      case 'task':
        return TASK_PAYLOAD_SCHEMA;
      case 'case':
        return CASE_PAYLOAD_SCHEMA;
      default:
        return undefined;
    }
  }

  /**
   * Normalise canonical enums and structurally relevant fields
   * according to Docs 2, 5 and 8.
   *
   * It is safe to call recursively on nested objects/arrays.
   */
  private normalisePayload<T = any>(payload: T): T {
    if (payload === null || payload === undefined) {
      return payload;
    }

    if (Array.isArray(payload)) {
      return payload.map((item) => this.normalisePayload(item)) as unknown as T;
    }

    if (typeof payload !== 'object') {
      return payload;
    }

    const obj = payload as Record<string, any>;

    for (const key of Object.keys(obj)) {
      const value = obj[key];

      if (value === null || value === undefined) {
        continue;
      }

      if (Array.isArray(value) || typeof value === 'object') {
        obj[key] = this.normalisePayload(value);
        continue;
      }

      if (typeof value === 'string') {
        obj[key] = this.normaliseScalarByKey(key, value);
      }
    }

    return obj as T;
  }

  /**
   * Field‑aware normalisation for scalar string values.
   * Handles enum casing, environment values and label trimming.
   */
  private normaliseScalarByKey(key: string, raw: string): string {
    const value = raw.trim();

    switch (key) {
      case 'status': {
        const upper = value.toUpperCase();
        if (TASK_STATUS_VALUES.includes(upper as any)) {
          return upper;
        }
        const lower = value.toLowerCase();
        if (CASE_STATUS_VALUES.includes(lower as any)) {
          return lower;
        }
        return value;
      }

      case 'priority': {
        const upper = value.toUpperCase();
        if (TASK_PRIORITY_VALUES.includes(upper as any)) {
          return upper;
        }
        return value;
      }

      case 'severity': {
        const upper = value.toUpperCase();
        if (TASK_SEVERITY_VALUES.includes(upper as any)) {
          return upper;
        }
        return value;
      }

      case 'visibility': {
        const upper = value.toUpperCase();
        if (VISIBILITY_VALUES.includes(upper as any)) {
          return upper;
        }
        return value;
      }

      case 'environment': {
        const lower = value.toLowerCase();
        if (ENVIRONMENT_VALUES.includes(lower as any)) {
          return lower;
        }
        return value;
      }

      case 'source':
      case 'source_type': {
        const lower = value.toLowerCase();
        if (TASK_SOURCE_VALUES.includes(lower as any)) {
          return lower;
        }
        return value;
      }

      case 'label': {
        // Canonical labels must be whitespace‑trimmed; we do not alter structure here.
        return value;
      }

      default:
        return value;
    }
  }

  /**
   * Build a BadRequestException using the standard result shape
   * (`ok` / `data` / `error`) expected by Core Services.
   */
  private buildException(message: string, details: Joi.ValidationErrorItem[]): BadRequestException {
    const logicalType = this.options.logicalType ?? 'generic';

    const defaultErrorCode = (() => {
      switch (logicalType) {
        case 'task':
          return 'TASK_VALIDATION_ERROR';
        case 'case':
          return 'CASE_VALIDATION_ERROR';
        case 'email':
          return 'EMAIL_VALIDATION_ERROR';
        case 'workflow_rule':
          return 'WORKFLOW_RULE_VALIDATION_ERROR';
        case 'notification':
          return 'NOTIFICATION_PAYLOAD_VALIDATION_ERROR';
        case 'config':
          return 'CONFIG_VALIDATION_ERROR';
        default:
          return 'PAYLOAD_VALIDATION_ERROR';
      }
    })();

    const errorCode = this.options.customErrorCode ?? defaultErrorCode;

    const formattedDetails = details.map((d) => ({
      path: d.path.join('.'),
      message: d.message,
      type: d.type,
      context: d.context,
    }));

    const responseBody = {
      ok: false,
      data: null,
      error: {
        code: errorCode,
        message,
        details: formattedDetails,
      },
    };

    return new BadRequestException(responseBody);
  }
}


=== FILE 45/48: apps/api/src/orgo/core/workflow/escalation.service.ts ===

// apps/api/src/orgo/core/workflow/escalation.service.ts

import { Injectable } from '@nestjs/common';

import { PrismaService } from '../../../persistence/prisma/prisma.service';
import { TaskService, TaskDto } from '../tasks/task.service';
import {
  NotifierService,
  NotifiableTask,
  TaskNotificationEventType,
} from '../notifications/notification.service';
import { LogService } from '../logging/log.service';
import { FN_ESCALATION_EVALUATE } from '../functional-ids';
import { FeatureFlagService } from '../../config/feature-flag.service';
import { OrgProfileService } from '../../config/org-profile.service';
import {
  AlertingService,
  EscalationDelayAlertInput,
} from '../alerts/alerting.service';

/**
 * Standard result shape for core services (aligned with other Orgo core services).
 */
export interface Result<T> {
  ok: boolean;
  data?: T;
  error?: {
    code: string;
    message: string;
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    details?: any;
  };
}

/**
 * Options for running escalation evaluation.
 *
 * This is designed to be called periodically by the background job
 * `orgo.workflow.check-escalations` (Docs 3, 5, 8).
 */
export interface EvaluateEscalationsOptions {
  /**
   * Optional tenant scope. When omitted, the scan is global across all orgs.
   */
  organizationId?: string;

  /**
   * Evaluation point-in-time. Defaults to current UTC time.
   * All comparisons against `reactivity_deadline_at` and `next_fire_at`
   * use this timestamp.
   */
  now?: Date;

  /**
   * Safety limits for batch size. Defaults are intentionally conservative.
   */
  limitTasks?: number;
  limitInstances?: number;

  /**
   * When true and organizationId + environment are provided, escalation-delay
   * alert thresholds are evaluated and AlertingService is invoked with
   * the derived metrics (Docs 5 & 6).
   */
  evaluateAlerts?: boolean;

  /**
   * Logical environment passed down to AlertingService when alerts are
   * evaluated. This mirrors the Environment type used by AlertingService.
   */
  environment?: EscalationDelayAlertInput['environment'];
}

/**
 * Result summary for a single evaluation run.
 *
 * This is intentionally compact but carries enough information
 * for logging, observability, and alerting/inights.
 */
export interface EscalationEvaluationResult {
  // Core counters
  processedTasks: number;
  escalatedTasks: number;
  processedInstances: number;
  advancedInstances: number;

  // SLA / alert-friendly metrics (aligned with EscalationDelayAlertInput)
  overdueUnresolvedCount: number;
  overdueCriticalCount: number;
  /**
   * Max delay (in seconds) beyond `reactivity_deadline_at` among
   * overdue unresolved tasks in this batch.
   */
  maxDelaySeconds: number;

  /**
   * Optional profile code used for this evaluation (if org-scoped).
   */
  profileCode?: string;

  /**
   * Whether an escalation-delay alert was actually triggered
   * during this evaluation (if alerts were enabled).
   */
  alertTriggered?: boolean;
}

/**
 * Canonical unresolved Task statuses, aligned with Doc 8
 * and the TASK_STATUS enum:
 *   - PENDING
 *   - IN_PROGRESS
 *   - ON_HOLD
 *   - ESCALATED
 *
 * Completed/terminal statuses (COMPLETED, FAILED, CANCELLED) are excluded.
 */
const UNRESOLVED_STATUSES = ['PENDING', 'IN_PROGRESS', 'ON_HOLD', 'ESCALATED'] as const;
type UnresolvedStatus = (typeof UNRESOLVED_STATUSES)[number];

/**
 * Shape of an escalation policy definition stored as JSON
 * and hydrated into EscalationInstance.policy.definition.
 *
 * This mirrors the high-level EscalationPolicyDefinition described
 * in Docs 3, 5, and 8.
 */
// eslint-disable-next-line @typescript-eslint/no-explicit-any
export interface EscalationStepActionDefinition {
  type: 'notify_role' | 'notify_user' | 'auto_reassign' | 'update_metadata';
  /**
   * Target role ID for notify_role / auto_reassign actions.
   */
  targetRoleId?: string | null;
  /**
   * Target user ID for notify_user / auto_reassign actions.
   */
  targetUserId?: string | null;
  /**
   * Optional notification channel hint (email, in_app, sms, etc.).
   * Actual routing is handled by NotificationRecipientResolver.
   */
  channel?: string | null;
  /**
   * Arbitrary structured payload attached to the action.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  payload?: any;
}

export interface EscalationStepDefinition {
  /**
   * Human-readable label for this step (e.g. "Escalate to department head").
   */
  label?: string;
  /**
   * Seconds to wait after the previous step before firing this one.
   * If omitted, falls back to policy.default_wait_seconds.
   */
  wait_seconds?: number;
  /**
   * Actions to execute when this step fires.
   */
  actions?: EscalationStepActionDefinition[];
}

export interface EscalationPolicyDefinition {
  /**
   * Default waiting time between steps when a step-specific wait_seconds
   * is not set.
   */
  default_wait_seconds?: number;
  /**
   * Ordered list of escalation steps for this policy.
   */
  steps?: EscalationStepDefinition[];
}

@Injectable()
export class EscalationService {
  constructor(
    private readonly prisma: PrismaService,
    private readonly taskService: TaskService,
    private readonly notifier: NotifierService,
    private readonly logService: LogService,
    private readonly featureFlagService: FeatureFlagService,
    private readonly orgProfileService: OrgProfileService,
    private readonly alertingService: AlertingService,
  ) {}

  /**
   * Convenience wrapper for org-scoped evaluation.
   *
   * Typical usage in the job `orgo.workflow.check-escalations`:
   *   await escalationService.evaluateEscalationsForOrg(orgId, { now });
   */
  async evaluateEscalationsForOrg(
    organizationId: string,
    options: Omit<EvaluateEscalationsOptions, 'organizationId'> = {},
  ): Promise<Result<EscalationEvaluationResult>> {
    return this.evaluateEscalations({
      ...options,
      organizationId,
    });
  }

  /**
   * Main entry point for escalation evaluation.
   *
   * Responsibilities (Docs 3, 5, 8):
   * - Scan Tasks whose `reactivity_deadline_at` has passed and status is unresolved.
   * - For each overdue Task, trigger TaskService.escalateTask (which bumps
   *   escalation_level and status to ESCALATED).
   * - Emit ESCALATED Task notifications via NotifierService.
   * - Advance active EscalationInstances according to their policy definition
   *   (multi-step escalation flows).
   * - Compute SLA-friendly metrics (overdue counts, maxDelaySeconds) which
   *   can feed into AlertingService and Insights.
   * - Respect feature flags for FN_ESCALATION_EVALUATE.
   */
  async evaluateEscalations(
    options: EvaluateEscalationsOptions = {},
  ): Promise<Result<EscalationEvaluationResult>> {
    const now = options.now ?? new Date();
    const limitTasks = options.limitTasks ?? 500;
    const limitInstances = options.limitInstances ?? 500;
    const organizationId = options.organizationId ?? null;

    try {
      // -----------------------------------------------------------------------
      // Feature flag check (per FN_ESCALATION_EVALUATE)
      // -----------------------------------------------------------------------
      const disabledByFlag = await this.isEscalationEvaluationDisabled(
        organizationId,
      );
      if (disabledByFlag) {
        const result: EscalationEvaluationResult = {
          processedTasks: 0,
          escalatedTasks: 0,
          processedInstances: 0,
          advancedInstances: 0,
          overdueUnresolvedCount: 0,
          overdueCriticalCount: 0,
          maxDelaySeconds: 0,
          alertTriggered: false,
        };

        await this.logService.logEvent({
          category: 'WORKFLOW',
          level: 'INFO',
          message:
            'Escalation evaluation skipped; feature flag FN_ESCALATION_EVALUATE disabled.',
          identifier: FN_ESCALATION_EVALUATE,
          metadata: {
            organizationId,
            result,
          },
        });

        return { ok: true, data: result };
      }

      // -----------------------------------------------------------------------
      // Load org profile for SLA context (reactivity_seconds, etc.)
      // -----------------------------------------------------------------------
      let profileCode: string | undefined;
      if (organizationId) {
        try {
          const resolvedProfile = await this.orgProfileService.loadProfile(
            organizationId,
          );
          profileCode = resolvedProfile.profileCode;
        } catch (profileError: unknown) {
          // Fail soft: escalations must still run even if profile lookup fails.
          const message =
            profileError instanceof Error
              ? profileError.message
              : String(profileError ?? '');
          await this.logService.logEvent({
            category: 'CONFIG',
            level: 'WARN',
            message:
              'Failed to load organization profile during escalation evaluation. Continuing with defaults.',
            identifier: FN_ESCALATION_EVALUATE,
            metadata: {
              organizationId,
              error: message,
            },
          });
        }
      }

      // -----------------------------------------------------------------------
      // 1) Reactivity deadline-based escalations (Tasks)
      // -----------------------------------------------------------------------
      const overdueTasks = await this.findOverdueTasks(
        now,
        organizationId ?? undefined,
        limitTasks,
      );

      let escalatedTasks = 0;
      let overdueCriticalCount = 0;
      let maxDelaySeconds = 0;

      for (const task of overdueTasks) {
        // SLA metrics for Alerts/Insights: delay beyond reactivity_deadline_at.
        const deadline =
          task.reactivity_deadline_at ??
          (task.reactivityDeadlineAt
            ? new Date(task.reactivityDeadlineAt)
            : null);

        if (deadline instanceof Date && deadline.getTime() <= now.getTime()) {
          const delaySeconds = Math.max(
            0,
            Math.floor((now.getTime() - deadline.getTime()) / 1000),
          );
          if (delaySeconds > maxDelaySeconds) {
            maxDelaySeconds = delaySeconds;
          }
        }

        if (task.severity === 'CRITICAL') {
          overdueCriticalCount += 1;
        }

        const escalated = await this.handleOverdueTask(task, now);
        if (escalated) {
          escalatedTasks += 1;
        }
      }

      const overdueUnresolvedCount = overdueTasks.length;

      // -----------------------------------------------------------------------
      // 2) Multi-step EscalationInstances (policy-driven flows)
      // -----------------------------------------------------------------------
      const dueInstances = await this.findDueEscalationInstances(
        now,
        organizationId ?? undefined,
        limitInstances,
      );

      let advancedInstances = 0;

      for (const instance of dueInstances) {
        const advanced = await this.handleEscalationInstance(instance, now);
        if (advanced) {
          advancedInstances += 1;
        }
      }

      const baseResult: EscalationEvaluationResult = {
        processedTasks: overdueTasks.length,
        escalatedTasks,
        processedInstances: dueInstances.length,
        advancedInstances,
        overdueUnresolvedCount,
        overdueCriticalCount,
        maxDelaySeconds,
        profileCode,
        alertTriggered: false,
      };

      // -----------------------------------------------------------------------
      // 3) Optional escalation-delay alert trigger
      // -----------------------------------------------------------------------
      if (
        organizationId &&
        options.evaluateAlerts &&
        options.environment &&
        overdueUnresolvedCount > 0
      ) {
        const alertInput: EscalationDelayAlertInput = {
          organizationId,
          profileKey: profileCode ?? 'default',
          environment: options.environment,
          overdueUnresolvedCount,
          overdueCriticalCount,
          maxDelaySeconds,
        };

        const alertResult =
          await this.alertingService.triggerEscalationDelayAlert(alertInput);

        baseResult.alertTriggered = !!(
          alertResult.ok && alertResult.data?.triggered
        );
      }

      // -----------------------------------------------------------------------
      // 4) Structured logging for Insights / observability
      // -----------------------------------------------------------------------
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'INFO',
        message: 'Escalation evaluation completed.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          organizationId,
          result: baseResult,
        },
      });

      return { ok: true, data: baseResult };
    } catch (error: unknown) {
      const message =
        error instanceof Error ? error.message : String(error ?? '');

      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'ERROR',
        message: 'Escalation evaluation failed.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          organizationId,
          error: message,
        },
      });

      return {
        ok: false,
        error: {
          code: 'ESCALATION_EVALUATION_ERROR',
          message,
          details: {
            organizationId,
          },
        },
      };
    }
  }

  /**
   * Scan Tasks where:
   *   - status ∈ UNRESOLVED_STATUSES
   *   - reactivity_deadline_at <= now
   *   - (optionally) organization_id = organizationId
   *
   * All field names use the Prisma/DB `snake_case` schema (Docs 1, 3, 5).
   */
  private async findOverdueTasks(
    now: Date,
    organizationId?: string,
    limit = 500,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ): Promise<any[]> {
    const prismaAny = this.prisma as any;

    if (!prismaAny.task || typeof prismaAny.task.findMany !== 'function') {
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'WARN',
        message:
          'Prisma model "task" not available; skipping overdue task scan.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          now: now.toISOString(),
          organizationId: organizationId ?? null,
        },
      });
      return [];
    }

    const where: Record<string, unknown> = {
      reactivity_deadline_at: {
        lte: now,
      },
      status: {
        in: UNRESOLVED_STATUSES as UnresolvedStatus[],
      },
    };

    if (organizationId) {
      where.organization_id = organizationId;
    }

    const tasks = await prismaAny.task.findMany({
      where,
      orderBy: [
        { reactivity_deadline_at: 'asc' },
        { created_at: 'asc' },
      ],
      take: limit,
    });

    return tasks;
  }

  /**
   * Handle a single overdue Task by:
   *   - Calling TaskService.escalateTask (increments escalation_level, sets status ESCALATED).
   *   - Emitting an ESCALATED Task notification via NotifierService.
   *
   * This method uses `reactivity_deadline_at` as the canonical SLA anchor
   * (Docs 5 & 8) and does not recompute SLA from raw profile values.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async handleOverdueTask(task: any, now: Date): Promise<boolean> {
    const organizationId: string | null =
      task.organizationId ?? task.organization_id ?? null;

    const deadline =
      task.reactivity_deadline_at ??
      (task.reactivityDeadlineAt
        ? new Date(task.reactivityDeadlineAt)
        : null);

    if (!deadline || !(deadline instanceof Date)) {
      // Should not happen because findOverdueTasks already filters, but be defensive.
      return false;
    }

    if (deadline.getTime() > now.getTime()) {
      // Not actually overdue at the precise evaluation time.
      return false;
    }

    const escalateResult = await this.taskService.escalateTask({
      organizationId: organizationId ?? '',
      taskId: task.id ?? task.taskId,
      reason: 'Reactivity deadline exceeded',
      actorUserId: null, // System-driven escalation.
    });

    if (!escalateResult.ok || !escalateResult.data) {
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'WARN',
        message: 'Task escalation failed during escalation evaluation.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          organizationId,
          taskId: task.id ?? null,
          error: escalateResult.error ?? null,
        },
      });
      return false;
    }

    // Translate TaskDto into NotifiableTask and emit ESCALATED notification.
    const escalatedTask = escalateResult.data;
    const notifiable = this.toNotifiableTask(escalatedTask, {
      escalation: {
        triggered_at: now.toISOString(),
        reason: 'Reactivity deadline exceeded',
      },
    });

    await this.notifier.sendTaskNotification(
      notifiable,
      'ESCALATED' as TaskNotificationEventType,
    );

    return true;
  }

  /**
   * Find EscalationInstances that are due to fire at or before `now`.
   *
   * Uses `next_fire_at` and `status ∈ {scheduled, in_progress}`.
   * Optionally scopes by organization via the linked Task's organization_id.
   */
  private async findDueEscalationInstances(
    now: Date,
    organizationId?: string,
    limit = 500,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ): Promise<any[]> {
    const prismaAny = this.prisma as any;

    if (
      !prismaAny.escalationInstance ||
      typeof prismaAny.escalationInstance.findMany !== 'function'
    ) {
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'WARN',
        message:
          'Prisma model "escalationInstance" not available; skipping escalation instance scan.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          now: now.toISOString(),
          organizationId: organizationId ?? null,
        },
      });
      return [];
    }

    const where: Record<string, unknown> = {
      status: {
        in: ['scheduled', 'in_progress'],
      },
      next_fire_at: {
        lte: now,
      },
    };

    if (organizationId) {
      // Scope by the owning Task's organization.
      where.task = {
        organization_id: organizationId,
      };
    }

    const instances = await prismaAny.escalationInstance.findMany({
      where,
      include: {
        task: true,
        policy: true,
      },
      orderBy: [
        { next_fire_at: 'asc' },
        { started_at: 'asc' },
      ],
      take: limit,
    });

    return instances;
  }

  /**
   * Process a single EscalationInstance:
   *   - Resolve its EscalationPolicyDefinition.
   *   - Execute the current step's actions.
   *   - Advance to the next step or mark the instance as completed.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async handleEscalationInstance(
    instance: any,
    now: Date,
  ): Promise<boolean> {
    const policy = instance.policy;

    if (!policy?.definition) {
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'WARN',
        message:
          'EscalationInstance has no policy definition; marking as completed.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          instanceId: instance.id,
        },
      });

      await this.markInstanceCompleted(instance, now);
      return false;
    }

    let definition: EscalationPolicyDefinition;

    try {
      // policy.definition is stored as JSON; tolerate both string and object.
      definition =
        typeof policy.definition === 'string'
          ? (JSON.parse(policy.definition) as EscalationPolicyDefinition)
          : (policy.definition as EscalationPolicyDefinition);
    } catch (parseError: unknown) {
      const message =
        parseError instanceof Error ? parseError.message : String(parseError);

      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'ERROR',
        message:
          'Failed to parse escalation policy definition; marking instance as completed.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          instanceId: instance.id,
          error: message,
        },
      });

      await this.markInstanceCompleted(instance, now);
      return false;
    }

    const steps = definition.steps ?? [];
    if (!steps.length) {
      await this.markInstanceCompleted(instance, now);
      return false;
    }

    const currentIndex: number =
      typeof instance.current_step_index === 'number'
        ? instance.current_step_index
        : 0;

    const currentStep = steps[currentIndex];
    if (!currentStep) {
      await this.markInstanceCompleted(instance, now);
      return false;
    }

    const actions = currentStep.actions ?? [];
    for (const action of actions) {
      await this.executeEscalationAction(instance, action, currentIndex, now);
    }

    const nextIndex = currentIndex + 1;
    const nextStep = steps[nextIndex];

    if (!nextStep) {
      await this.markInstanceCompleted(instance, now);
      return true;
    }

    const waitSeconds =
      typeof nextStep.wait_seconds === 'number' && nextStep.wait_seconds > 0
        ? nextStep.wait_seconds
        : typeof definition.default_wait_seconds === 'number' &&
          definition.default_wait_seconds > 0
        ? definition.default_wait_seconds
        : 60;

    const nextFireAt = new Date(now.getTime() + waitSeconds * 1000);

    const prismaAny = this.prisma as any;
    await prismaAny.escalationInstance.update({
      where: { id: instance.id },
      data: {
        current_step_index: nextIndex,
        next_fire_at: nextFireAt,
        updated_at: now,
      },
    });

    return true;
  }

  /**
   * Mark an EscalationInstance as completed.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async markInstanceCompleted(instance: any, now: Date): Promise<void> {
    const prismaAny = this.prisma as any;

    if (
      !prismaAny.escalationInstance ||
      typeof prismaAny.escalationInstance.update !== 'function'
    ) {
      return;
    }

    await prismaAny.escalationInstance.update({
      where: { id: instance.id },
      data: {
        status: 'completed',
        completed_at: now,
        next_fire_at: null,
        updated_at: now,
      },
    });
  }

  /**
   * Execute a single escalation step action for an instance.
   *
   * Actions are intentionally conservative and side-effect-free beyond:
   *   - Task notifications (notify_role / notify_user).
   *   - Auto-reassignment via TaskService.assignTask.
   *   - Metadata updates on the Task row.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private async executeEscalationAction(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    instance: any,
    action: EscalationStepActionDefinition,
    stepIndex: number,
    now: Date,
  ): Promise<void> {
    const task = instance.task;
    if (!task) {
      await this.logService.logEvent({
        category: 'WORKFLOW',
        level: 'WARN',
        message:
          'EscalationInstance has no linked task; skipping escalation action.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          instanceId: instance.id,
          action,
        },
      });
      return;
    }

    const organizationId: string | null =
      task.organizationId ?? task.organization_id ?? null;

    switch (action.type) {
      case 'notify_role':
      case 'notify_user': {
        const notifiable = this.toNotifiableTaskFromModel(task, {
          escalation: {
            instance_id: instance.id,
            step_index: stepIndex,
            target_role_id: action.targetRoleId ?? null,
            target_user_id: action.targetUserId ?? null,
            channel: action.channel ?? null,
            payload: action.payload ?? {},
            fired_at: now.toISOString(),
          },
        });

        await this.notifier.sendTaskNotification(
          notifiable,
          'ESCALATED' as TaskNotificationEventType,
        );
        break;
      }

      case 'auto_reassign': {
        if (!organizationId) {
          await this.logService.logEvent({
            category: 'WORKFLOW',
            level: 'WARN',
            message:
              'auto_reassign escalation action skipped; missing organizationId on task.',
            identifier: FN_ESCALATION_EVALUATE,
            metadata: {
              instanceId: instance.id,
              taskId: task.id ?? null,
              action,
            },
          });
          break;
        }

        const assignResult = await this.taskService.assignTask({
          organizationId,
          taskId: task.id ?? task.taskId,
          targetRoleId: action.targetRoleId ?? null,
          targetUserId: action.targetUserId ?? null,
          reason: 'Escalation auto-reassign',
          actorUserId: null,
        });

        if (!assignResult.ok) {
          await this.logService.logEvent({
            category: 'WORKFLOW',
            level: 'WARN',
            message:
              'auto_reassign escalation action failed via TaskService.assignTask.',
            identifier: FN_ESCALATION_EVALUATE,
            metadata: {
              instanceId: instance.id,
              taskId: task.id ?? null,
              error: assignResult.error ?? null,
            },
          });
        }
        break;
      }

      case 'update_metadata': {
        const prismaAny = this.prisma as any;

        if (!prismaAny.task || typeof prismaAny.task.update !== 'function') {
          break;
        }

        const existingMetadata =
          task.metadata && typeof task.metadata === 'object'
            ? task.metadata
            : {};

        const mergedMetadata = {
          ...existingMetadata,
          ...(action.payload ?? {}),
          escalation: {
            ...(existingMetadata?.escalation ?? {}),
            instance_id: instance.id,
            step_index: stepIndex,
            updated_at: now.toISOString(),
          },
        };

        await prismaAny.task.update({
          where: { id: task.id ?? task.taskId },
          data: {
            metadata: mergedMetadata,
            updated_at: now,
          },
        });
        break;
      }

      default:
        // Future-proof: ignore unknown action types safely.
        await this.logService.logEvent({
          category: 'WORKFLOW',
          level: 'WARN',
          message:
            'Unknown escalation action type encountered; skipping action.',
          identifier: FN_ESCALATION_EVALUATE,
          metadata: {
            instanceId: instance.id,
            taskId: task.id ?? null,
            action,
          },
        });
        break;
    }
  }

  /**
   * Determine whether escalation evaluation is disabled by feature flags
   * for the given organization.
   *
   * Uses FeatureFlagService with FN_ESCALATION_EVALUATE as the code.
   * If the flag is not defined or evaluation fails, we default to
   * "enabled" to avoid silently disabling core SLA behaviour.
   */
  private async isEscalationEvaluationDisabled(
    organizationId: string | null,
  ): Promise<boolean> {
    try {
      const code = FN_ESCALATION_EVALUATE;

      // First check whether a flag is explicitly defined.
      const existingFlag = await this.featureFlagService.getFlag(
        code,
        organizationId ?? undefined,
      );

      if (!existingFlag) {
        // No explicit flag configured → default to enabled.
        return false;
      }

      const enabled = this.featureFlagService.isFeatureEnabled(code, {
        organizationId: organizationId ?? undefined,
      });

      return !enabled;
    } catch (error: unknown) {
      const message =
        error instanceof Error ? error.message : String(error ?? '');

      await this.logService.logEvent({
        category: 'CONFIG',
        level: 'ERROR',
        message:
          'Feature flag evaluation for FN_ESCALATION_EVALUATE failed; proceeding with escalations enabled.',
        identifier: FN_ESCALATION_EVALUATE,
        metadata: {
          organizationId,
          error: message,
        },
      });

      // Fail-open: do not disable escalations on feature-flag errors.
      return false;
    }
  }

  /**
   * Helper: map TaskDto to NotifiableTask, optionally merging extra metadata.
   */
  private toNotifiableTask(
    task: TaskDto,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    extraMetadata?: any,
  ): NotifiableTask {
    const baseMetadata =
      (task.metadata && typeof task.metadata === 'object'
        ? task.metadata
        : {}) ?? {};

    const mergedMetadata =
      extraMetadata && typeof extraMetadata === 'object'
        ? { ...baseMetadata, ...extraMetadata }
        : baseMetadata;

    return {
      taskId: task.taskId,
      organizationId: task.organizationId,
      title: task.title,
      description: task.description ?? undefined,
      label: task.label ?? undefined,
      status: task.status,
      priority: task.priority,
      severity: task.severity,
      visibility: task.visibility,
      source: task.source,
      ownerRoleId: task.ownerRoleId ?? null,
      ownerUserId: task.ownerUserId ?? null,
      assigneeRole: task.assigneeRole ?? null,
      createdByUserId: task.createdByUserId ?? null,
      requesterPersonId: task.requesterPersonId ?? null,
      metadata: mergedMetadata,
    };
  }

  /**
   * Helper: map a raw Prisma Task model to NotifiableTask, for cases where
   * we operate directly on DB models (e.g. EscalationInstance.task includes).
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private toNotifiableTaskFromModel(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    taskModel: any,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    extraMetadata?: any,
  ): NotifiableTask {
    const baseMetadata =
      taskModel.metadata && typeof taskModel.metadata === 'object'
        ? taskModel.metadata
        : {};

    const mergedMetadata =
      extraMetadata && typeof extraMetadata === 'object'
        ? { ...baseMetadata, ...extraMetadata }
        : baseMetadata;

    const taskId = taskModel.taskId ?? taskModel.id;
    const organizationId =
      taskModel.organizationId ?? taskModel.organization_id;

    return {
      taskId,
      organizationId,
      title: taskModel.title,
      description: taskModel.description ?? undefined,
      label: taskModel.label ?? undefined,
      status: taskModel.status,
      priority: taskModel.priority,
      severity: taskModel.severity,
      visibility: taskModel.visibility,
      source: taskModel.source,
      ownerRoleId: taskModel.ownerRoleId ?? taskModel.owner_role_id ?? null,
      ownerUserId: taskModel.ownerUserId ?? taskModel.owner_user_id ?? null,
      assigneeRole:
        taskModel.assigneeRole ?? taskModel.assignee_role ?? null,
      createdByUserId:
        taskModel.createdByUserId ?? taskModel.created_by_user_id ?? null,
      requesterPersonId:
        taskModel.requesterPersonId ??
        taskModel.requester_person_id ??
        null,
      metadata: mergedMetadata,
    };
  }
}


=== FILE 46/48: apps/api/src/orgo/core/workflow/workflow-engine.service.ts ===

// apps/api/src/orgo/core/workflow/workflow-engine.service.ts

import { Injectable, Logger, OnModuleInit, Optional } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import * as fs from 'fs';
import * as path from 'path';
import * as yaml from 'js-yaml';

import { LogCategory, LogLevel, LogService } from '../logging/log.service';
import {
  FN_WORKFLOW_EXECUTE,
  FN_WORKFLOW_SIMULATE,
  FN_WORKFLOW_VALIDATE_RULES,
} from '../functional-ids';
import { FeatureFlagService } from '../../config/feature-flag.service';

const fsPromises = fs.promises;

const TASK_CATEGORIES = [
  'request',
  'incident',
  'update',
  'report',
  'distribution',
] as const;
type TaskCategory = (typeof TASK_CATEGORIES)[number];

const TASK_SEVERITIES = ['MINOR', 'MODERATE', 'MAJOR', 'CRITICAL'] as const;
type TaskSeverity = (typeof TASK_SEVERITIES)[number];

const WORKFLOW_EVENT_SOURCES = ['EMAIL', 'API', 'SYSTEM', 'TIMER'] as const;
export type WorkflowEventSource = (typeof WORKFLOW_EVENT_SOURCES)[number];

const WORKFLOW_ACTION_TYPES = [
  'CREATE_TASK',
  'UPDATE_TASK',
  'ROUTE',
  'ESCALATE',
  'ATTACH_TEMPLATE',
  'SET_METADATA',
  'NOTIFY',
] as const;
type WorkflowActionType = (typeof WORKFLOW_ACTION_TYPES)[number];

export type WorkflowExecutionMode = 'execute' | 'simulate';

/**
 * Public execute context used by the WorkflowController.
 * The controller's DTO is structurally compatible with this interface.
 *
 * This is intentionally minimal; domain-specific context lives under `context`.
 */
export interface WorkflowExecuteContext {
  workflowId: string;
  organizationId: string;
  source: WorkflowEventSource;
  /**
   * Arbitrary domain context (task/case/signal/email, hints, etc.).
   * The engine will derive a canonical WorkflowContext from this.
   */
  context?: Record<string, unknown>;
  /**
   * Optional hint; when true callers should prefer `simulate()`.
   * Kept for structural compatibility with controller DTOs.
   */
  dryRun?: boolean;
}

export interface WorkflowMatchCriteria {
  source?: WorkflowEventSource;
  /**
   * Domain-level type, e.g. "maintenance", "hr_case" (maps to Task.type)
   */
  type?: string;
  /**
   * Global Task.category (request | incident | update | report | distribution)
   */
  category?: TaskCategory;
  /**
   * Canonical severity enum (MINOR | MODERATE | MAJOR | CRITICAL)
   */
  severity?: TaskSeverity;
  /**
   * Numeric base of canonical label (e.g. 10, 100, 1000, 11, 101, ...)
   */
  labelBase?: number;
  /**
   * String prefix for label matching (e.g. "100.94.")
   */
  labelPrefix?: string;
  /**
   * At least one of these must appear in searchable text (case-insensitive)
   */
  keywordsAny?: string[];
  /**
   * All of these must appear in searchable text (case-insensitive)
   */
  keywordsAll?: string[];
  /**
   * Reserved for future metadata-based matching
   */
  metadata?: Record<string, unknown>;
}

export interface WorkflowAction {
  /**
   * Action type (CREATE_TASK, UPDATE_TASK, ROUTE, ESCALATE, ATTACH_TEMPLATE, SET_METADATA, NOTIFY)
   */
  type: WorkflowActionType | string;
  /**
   * Other keys depend on action type (set, to_role, channel, template_id, etc.)
   */
  [key: string]: any;
}

export interface WorkflowRule {
  id: string;
  version: string;
  description?: string;
  /**
   * Matching criteria; any unspecified field is treated as "no constraint"
   */
  match: WorkflowMatchCriteria;
  /**
   * Ordered list of actions to emit when rule matches
   */
  actions: WorkflowAction[];
  /**
   * Disabled rules are ignored at runtime
   */
  enabled: boolean;
  /**
   * Source file on disk (for debugging and validation reporting)
   */
  sourceFile?: string;
}

/**
 * Canonical, flattened view of a workflow context used for rule matching.
 * This is derived from Signals, Tasks/Cases, Emails or generic API payloads.
 */
export interface WorkflowContext {
  organizationId: string;
  /**
   * Workflow event source: EMAIL | API | SYSTEM | TIMER
   * (This is distinct from task_source_enum: email | api | manual | sync.)
   */
  source: WorkflowEventSource;

  /**
   * Domain-level type (Task.type), e.g. "maintenance", "hr_case"
   */
  type?: string;

  /**
   * Global Task.category (request | incident | update | report | distribution)
   */
  category?: string;

  /**
   * Severity string; normalised against TASK_SEVERITY (MINOR | MODERATE | MAJOR | CRITICAL)
   */
  severity?: string;

  /**
   * Canonical label for Case/Task, e.g. "100.94.Operations.Safety"
   */
  label?: string;

  /**
   * Human title / summary (Task.title / Case.title / email subject)
   */
  title?: string;

  /**
   * Human description/body (Task.description / Case.description)
   */
  description?: string;

  /**
   * Parsed email subject (for EMAIL sources)
   */
  emailSubject?: string;

  /**
   * Parsed plain-text email body (for EMAIL sources)
   */
  emailTextBody?: string;

  /**
   * Arbitrary metadata associated with the event/context
   */
  metadata?: Record<string, unknown>;

  /**
   * Raw payload for the event (email envelope, API body, etc.)
   */
  payload?: Record<string, unknown>;
}

export interface ResolvedWorkflowAction {
  ruleId: string;
  ruleVersion: string;
  actionIndex: number;
  action: WorkflowAction;
}

/**
 * Metadata describing how a particular workflow evaluation was performed.
 * This is optional and can be safely ignored by existing callers.
 */
export interface WorkflowExecutionMetadata {
  /**
   * Optional workflow identifier from the caller (WorkflowExecuteContext.workflowId).
   */
  workflowId?: string;
  /**
   * execute | simulate
   */
  mode?: WorkflowExecutionMode;
  /**
   * When the ruleset was loaded (approximate "ruleset version").
   */
  rulesLoadedAt?: string;
  /**
   * Whether the workflow feature flag was enabled for this org (if evaluated).
   */
  featureFlagEnabled?: boolean;
  /**
   * Evaluation duration in milliseconds.
   */
  durationMs?: number;
  /**
   * Number of rules currently loaded and how many matched this context.
   */
  totalRuleCount?: number;
  matchedRuleCount?: number;
  /**
   * Number of actions emitted.
   */
  actionCount?: number;
}

export interface WorkflowExecutionResultData {
  context: WorkflowContext;
  matchedRules: WorkflowRule[];
  actions: ResolvedWorkflowAction[];
  /**
   * Optional execution metadata for observability and API clients.
   */
  metadata?: WorkflowExecutionMetadata;
}

export interface WorkflowRuleValidationError {
  ruleId: string;
  sourceFile?: string;
  message: string;
  /**
   * JSONPath-like hint into the rule, e.g. "match.category", "actions[0].type"
   */
  path?: string;
}

export interface WorkflowEngineError {
  code: string;
  message: string;
  details?: Record<string, unknown>;
}

/**
 * Standard result shape (ok / data / error), aligned with Doc 5 §2.4.
 */
export interface WorkflowEngineResult<T> {
  ok: boolean;
  data: T | null;
  error: WorkflowEngineError | null;
}

/**
 * WorkflowEngineService (workflow_engine)
 *
 * Core service that:
 * - Loads workflow rule definitions from the filesystem.
 * - Validates rule structure and canonical enum usage.
 * - Evaluates rules against a WorkflowContext and emits an ordered list of actions.
 *
 * Side effects (creating tasks, routing, notifications, etc.) are performed by callers
 * using the returned actions; this service is intentionally pure and idempotent.
 */
@Injectable()
export class WorkflowEngineService implements OnModuleInit {
  private readonly logger = new Logger(WorkflowEngineService.name);
  private readonly rulesDirectory: string;

  private rules: WorkflowRule[] = [];
  private loadedAt: Date | null = null;

  private static readonly WORKFLOW_FLAG_CODE = 'orgo.workflow.new_router';

  constructor(
    private readonly configService: ConfigService,
    private readonly logService: LogService,
    @Optional()
    private readonly featureFlagService?: FeatureFlagService,
  ) {
    // Allow override via env; default to ../../config/workflows relative to apps/api
    const envDir =
      this.configService.get<string>('WORKFLOW_RULES_DIR') ??
      this.configService.get<string>('ORGO_WORKFLOW_RULES_DIR');

    const defaultDir = path.resolve(
      process.cwd(),
      '..',
      '..',
      'config',
      'workflows',
    );

    this.rulesDirectory = envDir || defaultDir;
  }

  async onModuleInit(): Promise<void> {
    await this.reloadRules();
  }

  /**
   * Reload rules from disk and validate them.
   * Intended for startup and for administrative hot-reload.
   */
  async reloadRules(): Promise<void> {
    try {
      const rules = await this.loadRulesFromDisk();
      this.rules = rules;
      this.loadedAt = new Date();

      const validation = this.internalValidateRules(rules);

      if (!validation.valid) {
        this.logger.error(
          `Workflow rules loaded with ${validation.ruleErrors.length} validation error(s).`,
        );
        for (const err of validation.ruleErrors) {
          this.logger.error(
            `[${err.ruleId}] ${err.message}` +
              (err.path ? ` (path: ${err.path})` : '') +
              (err.sourceFile ? ` [${err.sourceFile}]` : ''),
          );
        }
      } else {
        this.logger.log(
          `Workflow rules loaded successfully (${rules.length} rule(s)) from ${this.rulesDirectory}.`,
        );
      }
    } catch (error: any) {
      this.logger.error(
        `Failed to load workflow rules from ${this.rulesDirectory}: ${
          error?.message ?? error
        }`,
        error?.stack,
      );
      this.rules = [];
      this.loadedAt = null;
    }
  }

  /**
   * Public execution entrypoint for legacy callers (signals, email router, etc.)
   * that already build a canonical WorkflowContext.
   */
  async executeWorkflow(
    context: WorkflowContext,
  ): Promise<WorkflowEngineResult<WorkflowExecutionResultData>>;

  /**
   * Public execution entrypoint for API/controller callers that send a
   * WorkflowExecuteContext (Doc 5 §6.4).
   */
  async executeWorkflow(
    executeContext: WorkflowExecuteContext,
  ): Promise<WorkflowEngineResult<WorkflowExecutionResultData>>;

  async executeWorkflow(
    input: WorkflowContext | WorkflowExecuteContext,
  ): Promise<WorkflowEngineResult<WorkflowExecutionResultData>> {
    const isExecuteContext = this.isExecuteContext(input);
    const workflowId = isExecuteContext ? input.workflowId : undefined;
    const context = this.toWorkflowContext(input);

    return this.evaluateRules(context, {
      mode: 'execute',
      workflowId,
      rawContext: isExecuteContext ? input.context ?? {} : undefined,
    });
  }

  /**
   * Simulation / dry-run entrypoint (Doc 5 §6.3).
   *
   * This uses the same rule evaluation semantics as executeWorkflow but is
   * explicitly marked as mode="simulate" in the result metadata and logs.
   * No side effects are performed by this service; callers must ensure they
   * do not apply downstream actions in a simulation.
   */
  async simulate(
    executeContext: WorkflowExecuteContext,
  ): Promise<WorkflowEngineResult<WorkflowExecutionResultData>> {
    const context = this.toWorkflowContext(executeContext);

    return this.evaluateRules(context, {
      mode: 'simulate',
      workflowId: executeContext.workflowId,
      rawContext: executeContext.context ?? {},
    });
  }

  /**
   * Validate currently loaded rules and return structured errors.
   * Does not reload from disk by itself.
   */
  async validateWorkflowRules(): Promise<
    WorkflowEngineResult<{
      valid: boolean;
      ruleErrors: WorkflowRuleValidationError[];
    }>
  > {
    try {
      if (!this.loadedAt) {
        await this.reloadRules();
      }

      const validation = this.internalValidateRules(this.rules);

      await this.logWorkflowEvent(
        LogLevel.INFO,
        FN_WORKFLOW_VALIDATE_RULES,
        'Workflow rule validation completed',
        {
          ruleCount: this.rules.length,
          errorCount: validation.ruleErrors.length,
          valid: validation.valid,
        },
      );

      return {
        ok: true,
        data: validation,
        error: null,
      };
    } catch (error: any) {
      this.logger.error(
        `Workflow rule validation failed: ${error?.message ?? error}`,
        error?.stack,
      );

      await this.logWorkflowEvent(
        LogLevel.ERROR,
        FN_WORKFLOW_VALIDATE_RULES,
        'Workflow rule validation failed',
        {
          error:
            error instanceof Error
              ? { name: error.name, message: error.message }
              : String(error),
        },
      );

      return {
        ok: false,
        data: null,
        error: {
          code: 'WORKFLOW_VALIDATION_ERROR',
          message: 'Workflow rule validation failed',
          details: {
            error: String(error?.message ?? error),
          },
        },
      };
    }
  }

  /**
   * Alias matching Doc 5 notation; kept thin over validateWorkflowRules.
   */
  async validateWorkflow(): Promise<
    WorkflowEngineResult<{
      valid: boolean;
      ruleErrors: WorkflowRuleValidationError[];
    }>
  > {
    return this.validateWorkflowRules();
  }

  /**
   * Core evaluation routine shared by executeWorkflow and simulate.
   * This is a pure rules engine: it does not perform side effects.
   */
  private async evaluateRules(
    context: WorkflowContext,
    options: {
      mode: WorkflowExecutionMode;
      workflowId?: string;
      rawContext?: Record<string, unknown>;
    },
  ): Promise<WorkflowEngineResult<WorkflowExecutionResultData>> {
    const startedAt = Date.now();
    const { mode, workflowId } = options;

    try {
      if (!this.loadedAt) {
        await this.reloadRules();
      }

      const matchedRules: WorkflowRule[] = [];
      const resolvedActions: ResolvedWorkflowAction[] = [];

      for (const rule of this.rules) {
        if (!rule.enabled) {
          continue;
        }
        if (!this.ruleMatches(rule, context)) {
          continue;
        }

        matchedRules.push(rule);

        rule.actions.forEach((action, index) => {
          resolvedActions.push({
            ruleId: rule.id,
            ruleVersion: rule.version,
            actionIndex: index,
            action,
          });
        });
      }

      const durationMs = Date.now() - startedAt;
      const featureFlagEnabled = await this.isWorkflowFlagEnabled(
        context.organizationId,
      );

      this.logger.debug(
        `Workflow ${mode} for org=${context.organizationId}, source=${
          context.source
        }` +
          ` matched ${matchedRules.length} rule(s), produced ${
            resolvedActions.length
          } action(s) in ${durationMs}ms.`,
      );

      await this.logWorkflowEvent(
        LogLevel.INFO,
        mode === 'simulate' ? FN_WORKFLOW_SIMULATE : FN_WORKFLOW_EXECUTE,
        mode === 'simulate'
          ? 'Workflow simulation completed'
          : 'Workflow execution completed',
        {
          workflowId: workflowId ?? null,
          organizationId: context.organizationId,
          source: context.source,
          matchedRuleCount: matchedRules.length,
          actionCount: resolvedActions.length,
          durationMs,
          featureFlagEnabled,
        },
      );

      const metadata: WorkflowExecutionMetadata = {
        workflowId,
        mode,
        rulesLoadedAt: this.loadedAt?.toISOString(),
        featureFlagEnabled,
        durationMs,
        totalRuleCount: this.rules.length,
        matchedRuleCount: matchedRules.length,
        actionCount: resolvedActions.length,
      };

      return {
        ok: true,
        data: {
          context,
          matchedRules,
          actions: resolvedActions,
          metadata,
        },
        error: null,
      };
    } catch (error: any) {
      this.logger.error(
        `Workflow ${mode} failed: ${error?.message ?? error}`,
        error?.stack,
      );

      await this.logWorkflowEvent(
        LogLevel.ERROR,
        mode === 'simulate' ? FN_WORKFLOW_SIMULATE : FN_WORKFLOW_EXECUTE,
        mode === 'simulate'
          ? 'Workflow simulation failed'
          : 'Workflow execution failed',
        {
          workflowId: workflowId ?? null,
          organizationId: context.organizationId,
          source: context.source,
          error:
            error instanceof Error
              ? { name: error.name, message: error.message }
              : String(error),
        },
      );

      return {
        ok: false,
        data: null,
        error: {
          code:
            mode === 'simulate'
              ? 'WORKFLOW_SIMULATION_ERROR'
              : 'WORKFLOW_EXECUTION_ERROR',
          message:
            mode === 'simulate'
              ? 'Workflow simulation failed'
              : 'Workflow execution failed',
          details: {
            workflowId: workflowId ?? null,
            error: String(error?.message ?? error),
          },
        },
      };
    }
  }

  /**
   * Load workflow rule files from disk and normalise them to WorkflowRule objects.
   * Supports .yaml/.yml (YAML) and .json files. Files may contain a single rule
   * object or an array of rule objects.
   */
  private async loadRulesFromDisk(): Promise<WorkflowRule[]> {
    const rules: WorkflowRule[] = [];

    try {
      const dirEntries = await fsPromises.readdir(this.rulesDirectory, {
        withFileTypes: true,
      });

      const files = dirEntries.filter(
        (entry) =>
          entry.isFile() &&
          (entry.name.endsWith('.yaml') ||
            entry.name.endsWith('.yml') ||
            entry.name.endsWith('.json')),
      );

      let ruleIndex = 0;

      for (const entry of files) {
        const fullPath = path.join(this.rulesDirectory, entry.name);
        const rawContent = await fsPromises.readFile(fullPath, 'utf8');

        if (!rawContent.trim()) {
          continue;
        }

        let parsed: unknown;

        try {
          if (entry.name.endsWith('.json')) {
            parsed = JSON.parse(rawContent);
          } else {
            parsed = yaml.load(rawContent);
          }
        } catch (parseError: any) {
          this.logger.error(
            `Failed to parse workflow file ${fullPath}: ${
              parseError?.message ?? parseError
            }`,
          );
          continue;
        }

        const rawRules = Array.isArray(parsed) ? parsed : [parsed];

        for (const rawRule of rawRules) {
          if (!rawRule || typeof rawRule !== 'object') {
            continue;
          }

          const normalised = this.normaliseRawRule(
            rawRule as Record<string, unknown>,
            fullPath,
            ruleIndex++,
          );

          rules.push(normalised);
        }
      }
    } catch (error: any) {
      const code = (error as NodeJS.ErrnoException).code;
      if (code === 'ENOENT') {
        this.logger.warn(
          `Workflow rules directory does not exist: ${this.rulesDirectory}. No workflow rules loaded.`,
        );
        return [];
      }
      throw error;
    }

    return rules;
  }

  /**
   * Normalise a raw rule object (as parsed from YAML/JSON) into a WorkflowRule.
   */
  private normaliseRawRule(
    raw: Record<string, unknown>,
    sourceFile: string,
    index: number,
  ): WorkflowRule {
    const rawId = typeof raw.id === 'string' ? raw.id.trim() : '';
    const id = rawId || `${path.basename(sourceFile)}#${index}`;

    const rawVersion = typeof raw.version === 'string' ? raw.version.trim() : '';
    const version = rawVersion || '0.0.0';

    const description =
      typeof raw.description === 'string' ? raw.description.trim() : undefined;

    const enabled = typeof raw.enabled === 'boolean' ? raw.enabled : true;

    const rawMatch = (raw.match ?? {}) as Record<string, unknown>;
    const match = this.normaliseMatchCriteria(rawMatch);

    const rawActions = Array.isArray(raw.actions)
      ? (raw.actions as unknown[])
      : [];
    const actions = rawActions.map((a) => this.normaliseAction(a));

    return {
      id,
      version,
      description,
      enabled,
      match,
      actions,
      sourceFile,
    };
  }

  private normaliseMatchCriteria(
    raw: Record<string, unknown>,
  ): WorkflowMatchCriteria {
    const source = this.normaliseEventSource(raw.source);

    const type =
      typeof raw.type === 'string' && raw.type.trim().length > 0
        ? raw.type.trim()
        : undefined;

    const category = this.normaliseCategory(raw.category);
    const severity = this.normaliseSeverity(raw.severity);
    const labelBase = this.normaliseLabelBase(raw.label_base ?? raw.labelBase);

    const labelPrefix =
      typeof (raw.label_prefix ?? raw.labelPrefix) === 'string'
        ? String(raw.label_prefix ?? raw.labelPrefix)
        : undefined;

    const keywordsAny = this.normaliseStringArray(
      (raw.keywords_any ?? raw.keywordsAny) as unknown,
    );
    const keywordsAll = this.normaliseStringArray(
      (raw.keywords_all ?? raw.keywordsAll) as unknown,
    );

    const metadata =
      raw.metadata && typeof raw.metadata === 'object'
        ? (raw.metadata as Record<string, unknown>)
        : undefined;

    return {
      source,
      type,
      category,
      severity,
      labelBase,
      labelPrefix,
      keywordsAny,
      keywordsAll,
      metadata,
    };
  }

  private normaliseAction(raw: unknown): WorkflowAction {
    if (!raw || typeof raw !== 'object') {
      return { type: 'UNKNOWN' };
    }

    const obj = raw as Record<string, unknown>;
    const rawType = typeof obj.type === 'string' ? obj.type : 'UNKNOWN';
    const type = rawType.toUpperCase();

    return {
      ...obj,
      type,
    };
  }

  private normaliseStringArray(value: unknown): string[] | undefined {
    if (!Array.isArray(value)) {
      return undefined;
    }

    const result = value
      .map((v) => (typeof v === 'string' ? v.trim() : ''))
      .filter((v) => v.length > 0);

    return result.length > 0 ? result : undefined;
  }

  private normaliseLabelBase(value: unknown): number | undefined {
    if (typeof value === 'number' && Number.isFinite(value)) {
      return value;
    }

    const asString =
      typeof value === 'string' && value.trim().length > 0
        ? value.trim()
        : undefined;

    if (!asString) {
      return undefined;
    }

    const parsed = Number.parseInt(asString, 10);
    return Number.isFinite(parsed) ? parsed : undefined;
  }

  private normaliseEventSource(value: unknown): WorkflowEventSource | undefined {
    if (typeof value !== 'string') {
      return undefined;
    }

    const upper = value.toUpperCase();
    const match = WORKFLOW_EVENT_SOURCES.find(
      (s) => s.toUpperCase() === upper,
    );

    return match;
  }

  private normaliseCategory(value: unknown): TaskCategory | undefined {
    if (typeof value !== 'string') {
      return undefined;
    }

    const lower = value.toLowerCase();
    const match = TASK_CATEGORIES.find((c) => c.toLowerCase() === lower);

    return match;
  }

  private normaliseSeverity(value: unknown): TaskSeverity | undefined {
    if (typeof value !== 'string') {
      return undefined;
    }

    const upper = value.toUpperCase();
    const match = TASK_SEVERITIES.find((s) => s === upper);

    return match;
  }

  /**
   * Core matching logic for a single rule against a given context.
   */
  private ruleMatches(rule: WorkflowRule, context: WorkflowContext): boolean {
    const { match } = rule;

    if (match.source) {
      const ctxSource = this.normaliseEventSource(context.source);
      if (!ctxSource || ctxSource !== match.source) {
        return false;
      }
    }

    if (match.type) {
      if (!context.type || context.type !== match.type) {
        return false;
      }
    }

    if (match.category) {
      const ctxCategory = this.normaliseCategory(context.category);
      if (!ctxCategory || ctxCategory !== match.category) {
        return false;
      }
    }

    if (match.severity) {
      const ctxSeverity = this.normaliseSeverity(context.severity);
      if (!ctxSeverity || ctxSeverity !== match.severity) {
        return false;
      }
    }

    if (typeof match.labelBase === 'number') {
      const ctxLabelBase = this.extractLabelBase(context.label);
      if (ctxLabelBase === undefined || ctxLabelBase !== match.labelBase) {
        return false;
      }
    }

    if (match.labelPrefix) {
      if (!context.label || !context.label.startsWith(match.labelPrefix)) {
        return false;
      }
    }

    const haystack = this.buildSearchableText(context);

    if (match.keywordsAny && match.keywordsAny.length > 0) {
      const anyMatched = match.keywordsAny.some((kw) =>
        haystack.includes(kw.toLowerCase()),
      );
      if (!anyMatched) {
        return false;
      }
    }

    if (match.keywordsAll && match.keywordsAll.length > 0) {
      const allMatched = match.keywordsAll.every((kw) =>
        haystack.includes(kw.toLowerCase()),
      );
      if (!allMatched) {
        return false;
      }
    }

    // metadata-based matching can be added here in future without changing the public API.
    return true;
  }

  private extractLabelBase(label: string | undefined): number | undefined {
    if (!label) {
      return undefined;
    }

    const [basePart] = label.split('.', 1);
    const parsed = Number.parseInt(basePart, 10);

    return Number.isFinite(parsed) ? parsed : undefined;
  }

  /**
   * Build a lowercase concatenated text representation used for keyword matching.
   */
  private buildSearchableText(context: WorkflowContext): string {
    const parts: string[] = [];

    if (context.title) {
      parts.push(context.title);
    }

    if (context.description) {
      parts.push(context.description);
    }

    if (context.emailSubject) {
      parts.push(context.emailSubject);
    }

    if (context.emailTextBody) {
      parts.push(context.emailTextBody);
    }

    if (context.metadata) {
      try {
        parts.push(JSON.stringify(context.metadata));
      } catch {
        // ignore serialization errors
      }
    }

    if (context.payload) {
      try {
        parts.push(JSON.stringify(context.payload));
      } catch {
        // ignore serialization errors
      }
    }

    return parts.join(' ').toLowerCase();
  }

  /**
   * Internal validator for WorkflowRule objects.
   */
  private internalValidateRules(
    rules: WorkflowRule[],
  ): { valid: boolean; ruleErrors: WorkflowRuleValidationError[] } {
    const errors: WorkflowRuleValidationError[] = [];

    for (const rule of rules) {
      if (!rule.id || rule.id.trim().length === 0) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: 'Rule id is required',
          path: 'id',
        });
      }

      if (!rule.version || rule.version.trim().length === 0) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: 'Rule version is required',
          path: 'version',
        });
      }

      if (!rule.actions || rule.actions.length === 0) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: 'Rule must have at least one action',
          path: 'actions',
        });
      }

      if (rule.match.category && !TASK_CATEGORIES.includes(rule.match.category)) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: `Invalid category '${rule.match.category}'`,
          path: 'match.category',
        });
      }

      if (rule.match.severity && !TASK_SEVERITIES.includes(rule.match.severity)) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: `Invalid severity '${rule.match.severity}'`,
          path: 'match.severity',
        });
      }

      if (
        rule.match.source &&
        !WORKFLOW_EVENT_SOURCES.includes(rule.match.source)
      ) {
        errors.push({
          ruleId: rule.id,
          sourceFile: rule.sourceFile,
          message: `Invalid source '${rule.match.source}'`,
          path: 'match.source',
        });
      }

      rule.actions.forEach((action, index) => {
        const type = typeof action.type === 'string' ? action.type : 'UNKNOWN';

        if (!WORKFLOW_ACTION_TYPES.includes(type as WorkflowActionType)) {
          errors.push({
            ruleId: rule.id,
            sourceFile: rule.sourceFile,
            message: `Unknown action type '${type}'`,
            path: `actions[${index}].type`,
          });
        }

        if (type === 'CREATE_TASK') {
          if (typeof action.set !== 'object' || action.set === null) {
            errors.push({
              ruleId: rule.id,
              sourceFile: rule.sourceFile,
              message:
                'CREATE_TASK action must have a non-empty "set" object',
              path: `actions[${index}].set`,
            });
          }
        }

        if (type === 'ROUTE') {
          if (
            typeof action.to_role !== 'string' &&
            typeof (action as any).toRole !== 'string'
          ) {
            errors.push({
              ruleId: rule.id,
              sourceFile: rule.sourceFile,
              message:
                'ROUTE action must specify "to_role" (or "toRole") as a string',
              path: `actions[${index}].to_role`,
            });
          }
        }

        if (type === 'NOTIFY') {
          if (typeof action.channel !== 'string') {
            errors.push({
              ruleId: rule.id,
              sourceFile: rule.sourceFile,
              message: 'NOTIFY action must specify "channel" as a string',
              path: `actions[${index}].channel`,
            });
          }
        }
      });
    }

    return {
      valid: errors.length === 0,
      ruleErrors: errors,
    };
  }

  /**
   * Detect whether the input is a WorkflowExecuteContext (controller-style) or
   * a canonical WorkflowContext (internal callers).
   */
  private isExecuteContext(
    input: WorkflowContext | WorkflowExecuteContext,
  ): input is WorkflowExecuteContext {
    return (input as WorkflowExecuteContext).workflowId !== undefined;
  }

  /**
   * Convert either a WorkflowContext (pass-through) or a WorkflowExecuteContext
   * (controller DTO) into a canonical WorkflowContext for rule evaluation.
   *
   * This performs best-effort extraction of type/category/severity/label/title
   * from the nested context, following the Case/Task/Signal schemas in Docs 1–3.
   */
  private toWorkflowContext(
    input: WorkflowContext | WorkflowExecuteContext,
  ): WorkflowContext {
    if (!this.isExecuteContext(input)) {
      // Already a canonical WorkflowContext (used by SignalIngestService, EmailRouter, etc.).
      return input;
    }

    const exec = input;
    const context: WorkflowContext = {
      organizationId: exec.organizationId,
      source: exec.source,
    };

    const raw = exec.context ?? {};
    if (raw && typeof raw === 'object') {
      const anyCtx = raw as Record<string, any>;

      const primaryCandidate =
        (anyCtx.task && typeof anyCtx.task === 'object'
          ? (anyCtx.task as Record<string, any>)
          : null) ??
        (anyCtx.case && typeof anyCtx.case === 'object'
          ? (anyCtx.case as Record<string, any>)
          : null) ??
        (anyCtx.signal && typeof anyCtx.signal === 'object'
          ? (anyCtx.signal as Record<string, any>)
          : null) ??
        null;

      const from = (obj: Record<string, any> | null, key: string): string | undefined => {
        if (!obj) {
          return undefined;
        }
        const value = obj[key];
        if (value == null) {
          return undefined;
        }
        const asString =
          typeof value === 'string' || typeof value === 'number'
            ? String(value)
            : undefined;
        return asString && asString.trim().length > 0 ? asString : undefined;
      };

      const fromCtx = (key: string): string | undefined =>
        from(anyCtx, key) ?? undefined;

      context.type =
        fromCtx('type') ?? from(primaryCandidate, 'type') ?? context.type;

      context.category =
        fromCtx('category') ??
        from(primaryCandidate, 'category') ??
        context.category;

      context.severity =
        fromCtx('severity') ??
        from(primaryCandidate, 'severity') ??
        context.severity;

      context.label =
        fromCtx('label') ?? from(primaryCandidate, 'label') ?? context.label;

      context.title =
        fromCtx('title') ?? from(primaryCandidate, 'title') ?? context.title;

      context.description =
        fromCtx('description') ??
        from(primaryCandidate, 'description') ??
        context.description;

      // Email-specific hints
      context.emailSubject =
        fromCtx('emailSubject') ??
        fromCtx('subject') ??
        from(primaryCandidate, 'subject') ??
        context.emailSubject;

      context.emailTextBody =
        fromCtx('emailTextBody') ??
        fromCtx('textBody') ??
        fromCtx('body') ??
        context.emailTextBody;

      const metadataRaw =
        anyCtx.metadata && typeof anyCtx.metadata === 'object'
          ? (anyCtx.metadata as Record<string, unknown>)
          : undefined;

      context.metadata = metadataRaw;
      context.payload = {
        ...(anyCtx as Record<string, unknown>),
      };
    }

    return context;
  }

  /**
   * Evaluate the workflow feature flag for the given organization, if
   * FeatureFlagService is available. Fail-open to `true` on errors.
   */
  private async isWorkflowFlagEnabled(organizationId: string): Promise<boolean> {
    if (!this.featureFlagService) {
      // If feature flags are not wired, keep engine enabled.
      return true;
    }

    try {
      return await this.featureFlagService.isFeatureEnabled(
        WorkflowEngineService.WORKFLOW_FLAG_CODE,
        {
          organizationId,
          context: {
            service: 'workflow_engine',
          },
        },
      );
    } catch (error) {
      this.logger.warn(
        `Feature flag evaluation failed for org=${organizationId}: ${
          error instanceof Error ? error.message : String(error)
        }`,
      );
      // Fail-open: do not block workflows because of feature flag issues.
      return true;
    }
  }

  /**
   * Safe wrapper around LogService.logEvent to avoid cascading failures.
   */
  private async logWorkflowEvent(
    level: LogLevel,
    functionId: string,
    message: string,
    metadata: Record<string, unknown>,
  ): Promise<void> {
    if (!this.logService) {
      return;
    }

    try {
      await this.logService.logEvent({
        category: LogCategory.WORKFLOW,
        level,
        message,
        identifier: functionId,
        metadata: {
          functionId,
          ...metadata,
        },
      });
    } catch (error) {
      this.logger.warn(
        `Failed to emit workflow log event: ${
          error instanceof Error ? error.message : String(error)
        }`,
      );
    }
  }
}


=== FILE 47/48: apps/api/src/orgo/core/workflow/workflow.controller.ts ===

import {
  Body,
  Controller,
  HttpCode,
  HttpStatus,
  Param,
  Post,
} from '@nestjs/common';
import {
  ApiBadRequestResponse,
  ApiBody,
  ApiOkResponse,
  ApiOperation,
  ApiParam,
  ApiTags,
} from '@nestjs/swagger';
import { WorkflowEngineService } from './workflow-engine.service';

/**
 * Standard result shape used across Core Services.
 * Mirrors the spec in Core Services doc (ok / data / error).
 */
export interface StandardResult<TData> {
  ok: boolean;
  data: TData | null;
  error: {
    code: string;
    message: string;
    // Extra details (validation errors, offending fields, etc.)
    details?: Record<string, unknown>;
  } | null;
}

/**
 * Allowed workflow event sources (NOT the task_source_enum).
 * Matches spec: EMAIL | API | SYSTEM | TIMER.
 */
export type WorkflowExecutionSource = 'EMAIL' | 'API' | 'SYSTEM' | 'TIMER';

/**
 * Context passed to the workflow engine from the controller.
 * This is the “logical context” described in the Core Services spec:
 * includes organization_id, source and any additional data needed
 * to evaluate rules (task/case references, signal payloads, etc.).
 */
export interface WorkflowExecuteContext {
  workflowId: string;
  organizationId: string;
  source: WorkflowExecutionSource;
  /**
   * Arbitrary context for the workflow:
   * - task / case JSON
   * - signal payload
   * - email envelope
   * - domain-specific hints
   */
  context?: Record<string, unknown>;
}

/**
 * Body of POST /api/v3/workflows/:workflowId/execute.
 * `workflowId` itself is taken from the route param; the body supplies
 * the organization, source and arbitrary context.
 */
export interface ExecuteWorkflowDto {
  /**
   * Tenant identifier; all workflow evaluation is scoped to an organization.
   */
  organizationId: string;

  /**
   * Workflow event source (EMAIL | API | SYSTEM | TIMER).
   * This is the workflow-engine source, not the DB task_source_enum.
   */
  source: WorkflowExecutionSource;

  /**
   * Optional free-form context object consumed by the workflow engine.
   * This may include task/case JSON, signal payloads, domain hints, etc.
   */
  context?: Record<string, unknown>;

  /**
   * When true, the workflow engine is invoked in “dry run” mode
   * (simulation) and must not persist side-effects.
   */
  dryRun?: boolean;
}

/**
 * Controller responsible for public Workflow API endpoints.
 *
 * Interface mapping (from Orgo v3 specs):
 * - Trigger workflow execution → WorkflowController.execute
 *   POST /api/v3/workflows/:id/execute
 */
@ApiTags('workflows')
@Controller('api/v3/workflows')
export class WorkflowController {
  constructor(
    private readonly workflowEngineService: WorkflowEngineService,
  ) {}

  /**
   * Manually trigger a workflow execution for a given workflow ID.
   *
   * Route:
   *   POST /api/v3/workflows/:workflowId/execute
   *
   * Behaviour:
   *   - When dryRun = true: calls WorkflowEngineService.simulate(...)
   *     and returns the preview of actions without side-effects.
   *   - When dryRun = false or omitted: calls
   *     WorkflowEngineService.executeWorkflow(...) and returns its result.
   *
   * Both service calls are expected to return the standard
   * { ok, data, error } result shape.
   */
  @Post(':workflowId/execute')
  @HttpCode(HttpStatus.OK)
  @ApiOperation({
    summary: 'Trigger workflow execution',
    description:
      'Manually executes a workflow definition for the given workflowId within an organization. ' +
      'Set dryRun=true to simulate without applying side-effects.',
  })
  @ApiParam({
    name: 'workflowId',
    type: String,
    description:
      'Identifier of the workflow definition to execute (as defined in workflow config).',
  })
  @ApiBody({
    description: 'Workflow execution context',
    schema: {
      type: 'object',
      required: ['organizationId', 'source'],
      properties: {
        organizationId: {
          type: 'string',
          format: 'uuid',
          description: 'Tenant / organization identifier.',
        },
        source: {
          type: 'string',
          enum: ['EMAIL', 'API', 'SYSTEM', 'TIMER'],
          description: 'Workflow event source (not the DB task_source_enum).',
        },
        context: {
          type: 'object',
          additionalProperties: true,
          nullable: true,
          description:
            'Arbitrary context object (task/case JSON, signal payload, domain hints, etc.).',
        },
        dryRun: {
          type: 'boolean',
          nullable: true,
          default: false,
          description:
            'When true, runs the workflow in simulation mode without side-effects.',
        },
      },
    },
  })
  @ApiOkResponse({
    description:
      'Workflow executed successfully. Payload shape follows the standard { ok, data, error } result format.',
  })
  @ApiBadRequestResponse({
    description:
      'Invalid input, unknown workflow, or violation of workflow validation rules. ' +
      'Error payload uses the standard { ok: false, error: { code, message, details } } shape.',
  })
  async execute(
    @Param('workflowId') workflowId: string,
    @Body() body: ExecuteWorkflowDto,
  ): Promise<StandardResult<unknown>> {
    const { organizationId, source, context, dryRun = false } = body;

    const execContext: WorkflowExecuteContext = {
      workflowId,
      organizationId,
      source,
      context,
    };

    if (dryRun) {
      // Simulation / dry-run path (no side-effects).
      return this.workflowEngineService.simulate(execContext);
    }

    // Normal execution path (caller applies side-effects according
    // to the workflow engine’s returned actions).
    return this.workflowEngineService.executeWorkflow(execContext);
  }
}


=== FILE 48/48: apps/api/src/orgo/core/workflow/workflow.module.ts ===

import { Module, forwardRef } from '@nestjs/common';
import { PersistenceModule } from '../../../persistence/persistence.module';
import { TaskModule } from '../tasks/task.module';
import { WorkflowEngineService } from './workflow-engine.service';
import { EscalationService } from './escalation.service';
import { WorkflowController } from './workflow.controller';

@Module({
  imports: [
    PersistenceModule,
    forwardRef(() => TaskModule),
  ],
  controllers: [WorkflowController],
  providers: [WorkflowEngineService, EscalationService],
  exports: [WorkflowEngineService, EscalationService],
})
export class WorkflowModule {}


